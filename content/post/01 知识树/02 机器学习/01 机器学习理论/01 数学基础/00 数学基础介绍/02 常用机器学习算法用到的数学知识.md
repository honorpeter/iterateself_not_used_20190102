---
title: 02 常用机器学习算法用到的数学知识
toc: true
date: 2018-09-24
---
# 需要补充的

- 很赞，一直想总结的。后续进行更新和补充。
- 在每个机器学习算法的前面标注以下知识前提。


# 常用机器学习算法用到的数学知识





| 算法或理论     | 用到的数学知识点                                                                                     |
| -------------- | ---------------------------------------------------------------------------------------------------- |
| 贝叶斯分类器   | 随机变量，贝叶斯公式，随机变量独立性，正态分布，最大似然估计                                         |
| 决策树         | 概率，熵，Gini系数                                                                                   |
| KNN算法        | 距离函数                                                                                             |
| 主成分分析     | 协方差矩阵，散布矩阵，拉格朗日乘数法，特征值与特征向量                                               |
| 流形学习       | 流形，最优化，测地线，测地距离，图，特征值与特征向量                                                 |
| 线性判别分析   | 散度矩阵，逆矩阵，拉格朗日乘数法，特征值与特征向量                                                   |
| 支持向量机     | 点到平面的距离，Slater条件，强对偶，拉格朗日对偶，KKT条件，凸优化，核函数，Mercer条件                |
| logistic回归   | 概率，随机变量，最大似然估计，梯度下降法，凸优化，牛顿法                                             |
| 随机森林       | 抽样，方差                                                                                           |
| AdaBoost算法   | 概率，随机变量，极值定理，数学期望，牛顿法                                                           |
| 隐马尔可夫模型 | 概率，离散型随机变量，条件概率，随机变量独立性，拉格朗日乘数法，最大似然估计                         |
| 条件随机场     | 条件概率，数学期望，最大似然估计                                                                     |
| 高斯混合模型   | 正态分布，最大似然估计，Jensen不等式                                                                 |
| 人工神经网络   | 梯度下降法，链式法则                                                                                 |
| 卷积神经网络   | 梯度下降法，链式法则                                                                                 |
| 循环神经网络   | 梯度下降法，链式法则                                                                                 |
| 生成对抗网络   | 梯度下降法，链式法则，极值定理，Kullback-Leibler散度，Jensen-Shannon散度，测地距离，条件分布，互信息 |
| K-means算法    | 距离函数                                                                                             |
| 强化学习       | 数学期望，贝尔曼方程                                                                                 |
| 贝叶斯网络     | 条件概率，贝叶斯公式，图                                                                             |
| VC维           | Hoeffding不等式                                                                                      |



出现频率最高的是：

最优化方法：

- 拉格朗日乘数法
- 梯度下降法
- 牛顿法
- 凸优化


然后就是概率论的一些知识：

- 随机变量
- 贝叶斯公式
- 正态分布
- 最大似然估计

然后就是线性代数：
- 特征值和特征向量，比如主成分分析、流行学习、线性判别分析 等等。
- 微积分的也用的比较多，比如链式法则。

除了这些主体的知识，还有一些知识会用到：

- 流行学中用到了微分几何的知识，比如流行、测力线、测力距离等。
- 支持向量机里面会用到 Mercer 条件，这属于泛函分析和实变函数的范畴
- 人工神经网络的理论证明，外轮逼近定理，会用到泛函分析和实变函数的知识，用来证明这样的一个复合函数可以用来逼近任何一个函数。<span style="color:red;">这个外轮逼近定理不知道是不是叫这个名字，听起来好像是，要总结一下。感觉还是挺厉害的。</span>
- 离散数学里面的图论和数也会用到，不过用到的时候都比较简单。




# 相关资料

- [SIGAI 机器学习](http://sigai.cn/index.php?r=front/viewcourse&id=13)
