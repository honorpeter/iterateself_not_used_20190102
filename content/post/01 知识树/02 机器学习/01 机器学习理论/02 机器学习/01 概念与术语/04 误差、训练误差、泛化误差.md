---
title: 04 误差、训练误差、泛化误差
toc: true
date: 2018-07-30 15:32:22
---
# 经验误差与过拟合


TODO

* **并没有很详细的说，看看后面要怎么整合，或者拆分**

## 误差

### 错误率与精度的概念

比如说有 m 个样本，其中有 a 个样本分类错误。那么：

* 错误率 (error rate)：分类错误的样本数占样本总数的比例：$E=a/m$
* 精度   ( accuracy )：精度= 1-错误率：  $1- a/m$


### 误差、经验误差、泛化误差

更一般的：

* 误差：学习器的实际预测输出与样本的真实输出之间的差异。<span style="color:red;">这里所说的“误差”均指误差期望，什么意思？</span>
* 训练误差 (training error) 或 经验误差 (empirical error)：学习器在训练集上的误差
* 泛化误差 (generalization error) ：在新样本上的误差

显然，我们希望得到泛化误差小的学习器。

然而，我们事先并不知道新样本是什么样，因此我们实际能做的只能是努力使经验误差最小化。<span style="color:red;">也就是能做的就是减少训练误差</span>

在很多情况下，我们是可以学到一个经验误差很小、在训练集上表现很好的学习器的。甚至这个学习器可以对所有训练样本都分类正确，即分类错误率为零，分类精度为 100% 的学习器，那么这个是不是我们想要的学习器呢？遗憾的是，这样的学习器在多数情况下都不好。

那么为什么呢？ 这就牵涉出过拟合了：





# REF

1. 《机器学习》周志华
