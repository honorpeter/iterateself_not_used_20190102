---
title: 01 基础知识
toc: true
date: 2018-07-30 10:57:57
---
# 基础知识

TODO

- 这一章还没有整理，要结合 pdf 整理下。

## 什么是计算学习理论？


计算学习理论 (computational learning theory) 研究的是关于通过 “计算 ” 来进行 “学习” 的理论，即关于机器学习的理论基础。

其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。<span style="color:red;">嗯利害，关于计算学习有更系统的书吗？想系统总结下。</span>



给定样例集 \(D=\{(x_1,y_1),(x_2,y_2),\cdots ,(x_m,y_m)\}，\(x_i\in \mathcal{X}\) ，本章主要讨论二分类问题，若无特别说明，\(y_i\in \mathcal{Y}=\{-1,+1\}\) 。假设 \(X\) 中的所有样本服从一 个隐含未知的分布 \(\mathcal{D}\) ， \(D\) 中所有样本都是独立地从这个分布上采样而得，即独立同分布(independent and identically distributed，简称 i.i.d. ) 样本。**如果没有这个独立同分布的条件会怎样？**

令 \(h\) 为从 \(\mathcal{X}\) 到 \(\mathcal{Y}\) 的一个映射，其泛化误差为：


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/fljIe55lIA.png?imageslim)

y) , (12.1)

>1 m

E(h; D) = - 53(心)一讲). (12.2)

i=l

由于p是r的独立同分布采样，因此的经验误差的期望等于其泛化误 差.在上下文明确时，我们将五(Zi;P)和S(h;D)分别简记为五㈨和E(h).令 e为E{h)的上限，即E{h) e;我们通常用e表示预先设定的学得模型所应满 足的误差要求,亦称“误差参数”.

本章后面部分将研究经验误差与泛化误差之间的逼近程度.若Zi在数据集 D上的经验误差为0,则称h与D 一致，否则称其与D不一致.对任意两个映 射如，如e疋4 乂可通过其“不合”(disagreement)来度量它们之间的差别：

= Px^h^x) 如(®)) • (12.3)

我们会用到几个常用不等式：

• Jensen不等式：对任意凸函数/(re),有

/(E⑷)(，⑷)•

(12.4)

Hoeffding不等式[Hoeffding, 1963]:若列,扔,…，为m个独立随机变 量，且满足0 < % < 1,则对任意e〉0,有

(I m 1 m \

P ( rn 52 _ W E(^)e I exp(-2me2),

e ] 2exp(—2me2).

2=1

171 2=1

lib i "Cz

2=1 2=1

(12.5)

(12.6)

McDiarmid 不等式[McDiarmid, 1989]:若 吻,...,xm 为 m 个独立随 机变量，且对任意1 < < < m，函数/满足 SUp \f ，. • •，— f (*^1，• • •，1)怎i+1, • • • , *^m) | , ①1 ,•••，況m, 则对任意e〉0,有 P (/ (以，…，a;m) - E (/ (町，…，xm)) > e) exp (^^)，(12.7) e) 2exp ^^^2^ - (12.8)







## 相关资料

1. 《机器学习》周志华
