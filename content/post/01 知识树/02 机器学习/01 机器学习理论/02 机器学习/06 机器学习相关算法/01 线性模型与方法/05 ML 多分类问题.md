---
title: 05 ML 多分类问题
toc: true
date: 2018-07-30 21:23:49
---

# ML 多分类问题

TODO

- MvM 没有看，还是要看的。


现实中常遇到多分类学习任务。

有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题的。<span style="color:red;">那些可以推广到多分类问题的？怎么利用二分类问题来解决多分类问题的？</span>


## 多分类学习的基本解决思路是拆解法

不失一般性，考虑个 N 个类别 $C_1,C_2,\cdots C_N$，多分类学习的基本思路是 “拆解法”，即将多分类任务拆为若干个二分类任务求解。

具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器。在测试时，对这些分类器的预测结果进行集成，以获得最终的多分类结果。这里的关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成。本节主要介绍拆分策略。<span style="color:red;">到底是怎么进行拆分的？又是怎么进行集成的？为什么之前的 kaggle 案例课程里面我对于这个关键的问题没有怎么注意到呢？他们是怎么在实际中进行解决的？</span>

最经典的拆分策略有三种：

- “一对一” (One vs. One，简称 OvO )
- “一对其余” (One vs. Rest，简称 OvR )
- “多对多” (Many vs. Many，简称 MvM )

<span style="color:red;">奇怪，为什么我上了 kaggle 实战课却对于这种拆分没有什么印象呢？还是说 sklearn 已经把这种拆分封装进 `fit` 里面了？</span>

## OvO

给定数据集 $D=\{(x_1,y_1),(x_2,y_2),\cdots (x_m,y_m)\}$，$y_i\in \{C_1,C_2,\cdots ,C_N\}$。

OvO 将这 $N$ 个类别两两配对，从而产生 $N(N— 1)/2$ 个二分类任务，例如 OvO 将为了区分类别 $C_i$ 和 $C_j$ 而训练一个分类器，这个分类器把 $D$ 中的 $C_i$ 类样例作为正例，$C_j$ 类样例作为反例。<span style="color:blue;">那么不属于这两个类别的样例呢？输出什么？ OvO 的每个分类器仅用到两个类的样例进行训练。不属于这两个类别的不会参加训练。</span>在测试阶段，新样本将同时提交给所有分类器，于是我们将得到 $N(N—1)/2$ 个分类结果，最终结果可通过投票产生：<span style="color:red;">是的是的，好主意。</span>

图 3.4 给出了一个示意图：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/7503AgaL97.png?imageslim)

<span style="color:blue;">上面这个图没看明白，如果这是一个 $C_3$ 输入了 $f_5$ 分类器，怎么会得到 $C_2$ 呢？嗯，是这样的，因为 OvO 的每个分类器仅用到两个类的样例进行训练。</span>

## OvR

OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练个分类器。在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果，如图 3.4 所示。若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。 <span style="color:red;">预测置信度是什么？怎么得到？</span>

容易看出，OvR 只需训练 $N$ 个分类器，而 OvO 需训练 $N(N— 1)/2$ 个分类器，因此，OvO 的存储开销和测试时间开销通常比 OvR 更大。但在训练时, OvR的每个分类器均使用全部训练样例，而 OvO 的每个分类器仅用到两个类的样例，<span style="color:red;">嗯，才知道 OvO 的每个分类器仅用到两个类的样例进行训练。嗯，这我就知道了上面 图3.4 为什么这么说了。</span>因此，在类别很多时，OvO 的训练时间开销通常比 OvR 更小。<span style="color:red;">好吧。</span>**至于预测性能，则取决于具体的数据分布，在多数情形下两者差不多。**<span style="color:red;">好吧。</span>

## MvM

<span style="color:red;">这个没怎么看，还是要看的。</span>

MvM 是每次将若干个类作为正类，若干个其他类作为反类。显然，OvO 和 OvR 是 MvM 的特例。MvM的正、反类构造必须有特殊的设计，不能随意选取。这里我们介绍一种最常用的 MvM 技术：“纠错输出码”(Error Correcting Output Codes，简称 ECOC)。<span style="color:red;">嗯，想知道是怎么特殊设计的。</span>

ECOC 是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性。

ECOC工作过程主要分为两步:

- 编码：对 $N$ 个类别做 $M$ 次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集。这样一共产生 $M$ 个训练集，可训练出 $M$ 个分类器.
- 解码：$M$ 个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。

<span style="color:red;">没太看懂，$N$ 与 $M$ 之间的大小关系有限定吗？</span>

类别划分通过“编码矩阵”(coding matrix)指定。编码矩阵有多种形式，常见的主要有二元码和三元码。前者将每个类别分别指定为正类和反类，后者在正、反类之外，还可指定“停用类”。

图 3.5 给出了一个示意图，在图3.5(a)中，分类器 $f_2$ 将 $C_1$ 类和 $C_3$ 类的样例作为正例，$C_2$ 类和 $C_4$ 类的样例作为反例；在图3.5(b)中，分类器  $f_4$ 将 $C_1$ 类和 $C_4$ 类的样例作为正例，$C_3$ 类的样例作为反例。在解码阶段，各分类器的预测结果联合起来形成了测试示例的编码，该编码与各类所对应的编码 进行比较，将距离最小的编码所对应的类别作为预测结果.例如在图3.5(a)中，基于欧氏距离，预测结果将是 $C_3$。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/dfJ5aKdcb6.png?imageslim)


为什么称为“纠错输出码”呢？这是因为在测试阶段，ECOC编码对分类 器的错误有一定的容忍和修正能力。例如图3.5(a)中对测试示例的正确预测编码是(―1,+1,+1,—1,+1)，假设在预测时某个分类器出错了，例如 $f_2$ 出错从而导致了错误编码 (-1,-1,+1,-1,+1)，但基于这个编码仍能产生正确的最终分类结果 $C_3$ . —般来说，对同一个学习任务，ECOC编码越长，纠错能力越强.然 而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会増大；另一 方面，对有限类别数，可能的组合数目是有限的，码长超过一定范围后就失去了 意义。

对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠 错能力越强.因此，在码长较小时可根据这个原则计算出理论最优编码.然而， 码长稍大一些就难以有效地确定最优编码，事实上这是NP难问题。不过，通常 我们并不需获得理论最优编码，因为非最优编码在实践中往往已能产生足够好的分类器.另一方面，并不是编码的理论性质越好,分类性能就越好，因为机器学习问题涉及很多因素，例如将多个类拆解为两个“类别子集”，不同拆解方式所形成的两个类别子集的区分难度往往不同，即其导致的二分类问题的难度不同；于是，一个理论纠错性质很好、但导致的二分类问题较难的编码，与另一个理论纠错性质差一些、但导致的二分类问题较简单的编码，最终产生的模型性能孰强孰弱很难说。



## REF

1. 《机器学习》周志华
