---
title: 06 层次聚类
toc: true
date: 2018-06-29 08:50:16
---




层次聚类

层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构.数据集的划分可采用“自底向上”的聚合策略，也可采 用“自顶向下”的分拆策略.

AGNES是一种采用自底向上聚合策略的层次聚类算法.它先将数据集中的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直至达到预设的聚类簇个数.这里的关键是如何计算聚类簇之间的距离.实际上，每个簇是一个样本集合，因此，只需 采用关于集合的某种距离即可.例如，给定聚类簇 $C_i$ 与 $C_j$ ，可通过下面的式子来计算距离：

![mark](http://images.iterate.site/blog/image/180629/55emgImIlK.png?imageslim)


显然，最小距离由两个簇的最近样本决定，最大距离由两个簇的最远样本决定， 而平均距离则由两个簇的所有样本共同决定.当聚类簇距离由 dmin、dmax 或 davg计算时，AGNES算法被相应地称为“单链接” (single-linkage)、 “全链 接”(complete-linkage)或 “均链接”(average-linkage)算法.

![mark](http://images.iterate.site/blog/image/180629/0b48DbGH86.png?imageslim)

AGNES算法描述如图 9.11 所示.
- 在第14行，算法先对仅含一个样本的初始聚类簇和相应的距离矩阵进行初始化；
- 然后在第11-23行，AGNES不断合 并距离最近的聚类簇，并对合并得到的聚类簇的距离矩阵进行更新；
- 上述过程不断重复，直至达到预设的聚类簇数.


以西瓜数据集4.0为例，令 AGNES 算法一直执行到所有样本出现在同一 个簇中，即 $k= 1$，则可得到图 9.12 所示的“树状图”(dendrogram),其中每层 链接一组聚类簇.


![mark](http://images.iterate.site/blog/image/180629/E8If9i73Li.png?imageslim)

在树状图的特定层次上进行分割，则可得到相应的簇划分结果.例如，以图 9.12中所示虚线分割树状图，将得到包含7个聚类簇的结果：

![mark](http://images.iterate.site/blog/image/180629/BLKjBJH06f.png?imageslim)

将分割层逐步提升，则可得到聚类簇逐渐减少的聚类结果.例如图9.13显示出了从图9.12中产生7至4个聚类簇的划分结果.


![mark](http://images.iterate.site/blog/image/180629/AG8mEDbCIg.png?imageslim)





# COMMENT


9.7阅读材料
聚类也许是机器学习中“新算法”出现最多、最快的领域.一个重要原因 是聚类不存在客观标准；给定数据集，总能从某个角度找到以往算法未覆盖的

按大小，也能按颜色，甚至

能按产地聚类.    某种标准从而设计出新算法［Estivill-Castro, 2002］.相对于机器学习其他分支

来说，聚类的知识还不够系统化，因此著名教科书［Mitchell, 1997］中甚至没有 关于聚类的章节.但聚类技术本身在现实任务中非常重要，因此本章勉强采用 了 “列举式”的叙述方式，相较于其他各章给出了更多的算法描述.关于聚类

距离度量学习参见10.6 节.


凸形簇结构即形似“椭 球”的農结构.

Bregman距离亦称 Bregman divergence,是一 类不满足对称性和直递性 的距离.

降维参见第10章.


更多的内容5可参阅这方面的专门书籍和综述文章如[Jain and Dubes, 1988; Jain et al.5 1999; Xu and Wunsch II, 2005; Jain, 2009]等.

聚类性能度量除9.2节的内容外，常见的还有F值、互信息(mutual information)、平均廓宽(average silhouette width) [Rousseeuw, 1987]等，可 参阅[Jain and Dubes, 1988; Halkidi et al” 2001; Maulik and Bandyopadhyay, 2002].

距离计算是很多学习任务的核心技术.闵可夫斯基距离提供了距离计算的 一般形式.除闵可夫斯基距离之外，内积距离、余弦距离等也很常用，可参阅 [Deza and Deza，2009]. MinkovDM 在[Zhou and Yu, 2005]中正式给出.模式 识别、图像检索等涉及复杂语义的应用中常会涉及非度量距离[Jacobs et al, 2000; Tan et al, 2009].距离度量学习可直接嵌入到聚类学习过程中[Xing et al.5 2003].

k均值算法可看作高斯混合聚类在混合成分方差相等、且每个样本仅指 派给一个混合成分时的特例.该算法在历史上曾被不同领域的学者多次重 新发明，如 Steinhaus 在 1956 年、Lloyd 在 1957 年、McQueen 在 1967 年等 [Jain and Dubes, 1988; Jain, 2009]. k 均值算法有大量变体，如 Axmedoids 算 法[Kaufman and Rousseeuw, 1987]强制原型向量必为训练样本，fc-modes算 法[Huang, 1998]可处理离散属性，Fuzzy C-means (简称 FCM) [Bezdek, 1981] 则是“软聚类”(soft clustering)算法，允许每个样本以不同程度同时属于多个 原型.需注意的是，均值类算法仅在凸形簇结构上效果较好.最近研究表明, 若采用某种Bregman距离，则可显著増强此类算法对更多类型簇结构的适用性 [Banerjee et al., 2005].引入核技巧则可得到核/c均值(kernel fc-means)算法 [Scholkopf et al., 1998]，这与谱聚类(spectral clustering) [von Luxburg, 2007] 有密切联系[Dhillon et al., 2004],后者可看作在拉普拉斯特征映射(Laplacian Eigenmap)降维后执行fc均值聚类.聚类簇数k通常需由用户提供5有一些启 发式用于自动确定々[peiieg and Moore, 2000; Tibshirani et al., 2001],但常用 的仍是基于不同值多次运行后选取最佳结果.

LVQ算法在每轮迭代中仅更新与当前样本距离最近的原型向量.同时 更新多个原型向量能显著提高收敛速度，相应的改进算法有LVQ2、LVQ3等 [Kolionen, 2001]. [McLachlan and Peel, 2000]详细介绍了高斯混合聚类，算法 中EM迭代优化的推导过程可参阅[Bilmes，1998; Jain and Dubes，1988].

采用不同方式表征样本分布的紧密程度，可设计出不同的密度聚类算 法，除 DBSCAN [Ester et al.5 1996]夕卜，较常用的还有 OPTICS [Ankerst et al.,

1999］、DENCLUE ［Hinneburg and Keim, 1998］等.AGNES ［Kaufman and Rousseeuw, 1990］采用了自底向上的聚合策略来产生层次聚类结构，与之相 反，DIANA ［Kaufman and Rousseeuw, 1990］则是采用自顶向下的分拆策略. AGNES和DIANA都不能对已合并或已分拆的聚类簇进行回溯调整，常用的 层次聚类算法如 BIRCH ［Zhang et al., 1996］. ROCK ［Guha et al.，1999］等对 此进行了改进.

聚类集成(clustering ensemble)通过对多个聚类学习器进行集成，能有效 降低聚类假设与真实聚类结构不符、聚类过程中的隨机性等因素帯来的不利 影响，可参阅［Zhou, 2012］第7章.

亦称 outlier detection.    异常检测(anomaly detection) ［Hodge and Austin, 2004; Chandola et

al., 2009］常借助聚类或距离计算进行，如将远离所有簇中心的样本作为 异常点，或将密度极低处的样本作为异常点.最近有研究提出基于“隔离 性”(isolation)可快速检测出异常点［Liu et al., 2012］.



## 相关资料
1. 《机器学习》周志华
