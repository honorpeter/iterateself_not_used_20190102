---
title: 02 感知机与多层网络
toc: true
date: 2018-06-26 16:01:33
---




感知机与多层网络


感知机 (Perceptron) 由两层神经元组成，如图 5.3 所示，输入层接收外界输入信号后传递给输出层，输出层是 M-P神经元，亦称 “阈值逻辑单元” (threshold logic unit)。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/HH2jbcD06F.png?imageslim)


感知机能容易地实现逻辑与、或、非运算.注意到 $y=f(\sum_i w_ix_i-\theta)$ ，假定 f 是图5.2中的阶跃函数，有

- “与”($x_1\wedge x_2$): 令 $w_1=w_2=1$，$\theta=2$ ，则 $y=f(1\cdot x_1+1\cdot x_2 -2)$ ,仅在 $x_1=x_2=1$ 时，$y=1$ 。
- “或”($x_1\vee x_2$): 令 $w_1=w_2=1$，$\theta=0.5$ ，则 $y=f(1\cdot x_1+1\cdot x_2 -0.5)$ ,当 $x_1=1$ 或 $x_2=1$ 时，$y=1$ 。
- “非”($\neg x_1$): 令 $w_1=-0.6$，$w_2=0$，$\theta=-0.5$ ，则 $y=f(-0.6\cdot x_1+0\cdot x_2 +0.5)$ ,当 $x_1=1$ 时，y=0；当 x_1=0 时，$y=1$ 。



更一般地，给定训练数据集，权重购 $w_i(i=1,2,\cdots ,n)$ 以及阈值 $\theta$  可通过学习得到.阈值 $\theta$ 可看作一个固定输入为-1.0的 “哑结点”(dummy node)，所对应的连接权重 $w_{n+1}$ 这样，权重和阈值的学习就可统一为权重的学习。感知机学习规则非常简单，对训练样例 (x,y)，若当前感知机的输出为 $\hat{y}$ 则感知机权重将这样调整：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/fBBA41Fe96.png?imageslim)


其中 $\eta$ 称为学习率(learning rate)。从式(5.1)可看出，若感知机对训练 样例(x,y)预测正确，即 $\hat{y}=y$，则感知机不发生变化，否则将根据错误的程度进行权重调整。

需注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元(functional neuron)，其学习能力非常有限。事实上，上述与、或、 非问题都是线性可分(linearly separable)的问题.可以证明[Minsky and Papert, 1969],若两类模式是线性可分的，即存在一个线性超平面能将它们分开，如图 5.4(a)-(c)所示，则感知机的学习过程一定会收敛(converge)而求得适当的权向量 $\mathbb{w} = (w_1;w_2;\cdots;w_{n+1})$；否则感知机学习过程将会发生振荡(fluctuation)，$\mathbb{w}$ 难以稳定下来，不能求得合适解，例如感知机甚至不能解决如图5.4(d)所示的异或这样简单的非线性可分问题。<span style="color:red;">嗯</span>

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/EdKdbB6djE.png?imageslim)



要解决非线性可分问题，需考虑使用多层功能神经元.例如图5.5中这个简单的两层感知机就能解决异或问题.在图5.5(a)中，输出层与输入层之间的一 层神经元，被称为隐层或隐含层(hidden layer),隐含层和输出层神经元都是拥有激活函数的功能神经元.

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/11b2382672.png?imageslim)

更一般的，常见的神经网络是形如图5.6所示的层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。<span style="color:red;">为什么要不存在跨层连接？</span>这样的神经网络结构通常称为“多层前馈神经网络”(multi-layer feedforward neural networks),其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行 加工，最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元.因此，图5.6(a)通常被称为“两层网络”.为避免歧义，本书称其为“单隐层网络”。只需包含隐层，即可称为多层网络。神经网络的学习过程，就是根据训练数据来调整神经元之间的 “连接权”(connection weight)以及每个功能神经元的阈值；换言之，神经网络“学”到的东西，蕴涵在连接权与阈值中。<span style="color:red;">嗯</span>

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/4GG4c1ibLE.png?imageslim)





# REF
1. 《机器学习》周志华
