---
title: 07 深度学习中的正则化
toc: true
date: 2018-06-26 19:35:04
---
## 相关资料
1. 《深度学习》Ian Goodfellow




## 需要补充的




第七章 深度学习中的正则化
机器学习中的一个核心问题是设计不仅在训练数据上表现好，并且能在新输入

上泛化好的算法。在机器学习中，许多策略显式地被设计来减少测试误差（可能会

以增大训练误差为代价）。这些策略被统称为正则化。我们将在后文看到，深度学

习工作者可以使用许多不同形式的正则化策略。事实上，开发更有效的正则化策略

已成为本领域的主要研究工作之一。

第五章介绍了泛化、欠拟合、过拟合、偏差、方差和正则化的基本概念。如果你

不熟悉这些概念，请参考该章节再继续阅读本章。

在本章中，我们会更详细地介绍正则化，重点介绍深度模型（或组成深度模型

的模块）的正则化策略。

本章中的某些章节涉及机器学习中的标准概念。如果你已经熟悉了这些概念

可以随意跳过相关章节。然而，本章的大多数内容是关于这些基本概念在特定神经

网络中的扩展概念。

在第5.2.2节中，我们将正则化定义为 ‘‘对学习算法的修改——旨在减少泛化误 差而不是训练误差''。目前有许多正则化策略。有些策略向机器学习模型添加限制参 数值的额外约束。有些策略向目标函数增加额外项来对参数值进行软约束。如果我 们细心选择，这些额外的约束和惩罚可以改善模型在测试集上的表现。有时侯，这些 约束和惩罚被设计为编码特定类型的先验知识；其他时候，这些约束和惩罚被设计 为偏好简单模型，以便提高泛化能力。有时，惩罚和约束对于确定欠定的问题是必 要的。其他形式的正则化，如被称为集成的方法，则结合多个假说来解释训练数据。

在深度学习的背景下，大多数正则化策略都会对估计进行正则化。估计的正则 化以偏差的增加换取方差的减少。一个有效的正则化是有利的 ‘‘交易''，也就是能显 著减少方差而不过度增加偏差。我们在第五章中讨论泛化和过拟合时，主要侧重模

型族训练的 3 个情形：（ 1）不包括真实的数据生成过程——对应欠拟合和含有偏 差的情况，（ 2）匹配真实数据生成过程，（ 3）除了包括真实的数据生成过程，还包

括许多其他可能的生成过程——方差（而不是偏差）主导的过拟合。正则化的目标

是使模型从第三种情况转化为第二种情况。

在实践中，过于复杂的模型族不一定包括目标函数或真实数据生成过程，甚至

也不包括近似过程。我们几乎从未知晓真实数据的生成过程，所以我们永远不知道

被估计的模型族是否包括生成过程。然而，深度学习算法的大多数应用都是针对这

样的情况，其中真实数据的生成过程几乎肯定在模型族之外。深度学习算法通常应

用于极为复杂的领域，如图像、音频序列和文本，本质上这些领域的真实生成过程

涉及模拟整个宇宙。从某种程度上说，我们总是持方枘（数据生成过程）而欲内圆

凿（我们的模型族）。

这意味着控制模型的复杂度不是找到合适规模的模型（带有正确的参数个数）

这样一个简单的事情。相反，我们可能会发现，或者说在实际的深度学习场景中我

们几乎总是会发现，最好的拟合模型（从最小化泛化误差的意义上）是一个适当正

则化的大型模型。

现在我们回顾几种策略，以创建这些正则化的大型深度模型。

7.1 参数范数惩罚
正则化在深度学习的出现前就已经被使用了数十年。线性模型，如线性回归和逻

辑回归可以使用简单、直接、有效的正则化策略。

许多正则化方法通过对目标函数J添加一个参数范数惩罚Q（0），限制模型 （如神经网络、线性回归或逻辑回归）的学习能力。我们将正则化后的目标函数记为

J:

J（0;X，y） = J（0; X, y） + aQ（0）, （7.1）

其中a e [0,m）是权衡范数惩罚项Q和标准目标函数J（X;0）相对贡献的超参数。 将a设为0表示没有正则化。a越大，对应正则化惩罚越大。

当我们的训练算法最小化正则化后的目标函数J时，它会降低原始目标J关于 训练数据的误差并同时减小在某些衡量标准下参数0 （或参数子集）的规模。选择 不同的参数范数Q会偏好不同的解。在本节中，我们会讨论各种范数惩罚对模型的

影响。

在探究不同范数的正则化表现之前，我们需要说明一下，在神经网络中，参数包 括每一层仿射变换的权重和偏置，我们通常只对权重做惩罚而不对偏置做正则惩罚。 精确拟合偏置所需的数据通常比拟合权重少得多。每个权重会指定两个变量如何相 互作用。我们需要在各种条件下观察这两个变量才能良好地拟合权重。而每个偏置仅 控制一个单变量。这意味着，我们不对其进行正则化也不会导致太大的方差。另外 正则化偏置参数可能会导致明显的欠拟合。因此，我们使用向量W表示所有应受范 数惩罚影响的权重，而向量0表示所有参数(包括W和无需正则化的参数)。

在神经网络的情况下，有时希望对网络的每一层使用单独的惩罚，并分配不同

的a系数。寻找合适的多个超参数的代价很大，因此为了减少搜索空间，我们会在 所有层使用相同的权重衰减。

7.1.1 L1 2 参数正则化
在第5.2节中我们已经看到过最简单而又最常见的参数范数惩罚，即通常被称 为权重衰减(weight decay)的L2参数范数惩罚。这个正则化策略通过向目标函 数添加一个正则项Q(0) = 2 || w||2,使权重更加接近原点、在其他学术圈，L2也被 称为岭回归或 Tikhonov 正则。

我们可以通过研究正则化后目标函数的梯度，洞察一些权重衰减的正则化表现。 为了简单起见，我们假定其中没有偏置参数，因此0就是w。这样一个模型具有以 下总的目标函数：

换种写法就是：

w (1 — ea)w —巧wJ(w; X, y). (7.5)

我们可以看到，加入权重衰减后会引起学习规则的修改，即在每步执行通常的梯度更

新之前先收缩权重向量(将权重向量乘以一个常数因子)。这是单个步骤发生的变

化。但是，在训练的整个过程会发生什么呢？

我们进一步简化分析，令w*为未正则化的目标函数取得最小训练误差时的权 重向量，即w* = argminw J(w)，并在w*的邻域对目标函数做二次近似。如果目

标函数确实是二次的 (如以均方误差拟合线性回归模型的情况)，则该近似是完美的。

近似的J(0)如下

J(d) = J (w*) + ^2(w — w*)TH(w— w*), (7.6)

其中H是J在w*处计算的Hessian矩阵(关于w)。因为w*被定义为最优，即梯 度消失为0,所以该二次近似中没有一阶项。同样地，因为w*是J的一个最优点， 我们可以得出H是半正定的结论。

当J取得最小时，其梯度

w= (H + aT)-1Hw* (7.10)

当a趋向于0时，正则化的解w会趋向w*。那么当a增加时会发生什么呢? 因为H是实对称的，所以我们可以将其分解为一个对角矩阵A和一组特征向量的 标准正交基Q，并且有H= QAQT。将其应用于式(7.10)，可得：

w = (QA Qt + aI)-1 QAQT w* (7.11)

= [Q(A+aI)QT]-1QAQTw* (7.12)

= Q(A+aI)-1AQTw*. (7.13)

我们可以看到权重衰减的效果是沿着由H的特征向量所定义的轴缩放w*。具体来 说，我们会根据Ii+a因子缩放与H第i个特征向量对齐的w*的分量。（不妨查

看图 2.3 回顾这种缩放的原理）。

沿着H特征值较大的方向（如\》a）正则化的影响较小。而\《a的分量将 会收缩到几乎为零。这种效应如图7.1所示。

w1

图7.1: L2 （或权重衰减）正则化对最佳w值的影响。实线椭圆表示没有正则化目标的等值线。虚 线圆圈表示L2正则化项的等值线。在w点，这两个竞争目标达到平衡。目标函数J的Hessian的 第一维特征值很小。当从w*水平移动时，目标函数不会增加得太多。因为目标函数对这个方向没 有强烈的偏好，所以正则化项对该轴具有强烈的影响。正则化项将wi拉向零。而目标函数对沿着 第二维远离 w* 的移动非常敏感。对应的特征值较大，表示高曲率。因此，权重衰减对 w2 的位置 影响相对较小。

只有在显著减小目标函数方向上的参数会保留得相对完好。在无助于目标函 数减小的方向（对应 Hessian 矩阵较小的特征值）上改变参数不会显著增加梯度。这 种不重要方向对应的分量会在训练过程中因正则化而衰减掉。

目前为止，我们讨论了权重衰减对优化一个抽象通用的二次代价函数的影响

这些影响具体是怎么和机器学习关联的呢？我们可以研究线性回归，它的真实代价

函数是二次的，因此我们可以使用相同的方法分析。再次应用分析，我们会在这种

情况下得到相同的结果，但这次我们使用训练数据的术语表述。线性回归的代价函

数是平方误差之和：

我们添加 L3 正则项后，目标函数变为

(Xw — y)T(Xw — y) + 1 awT w. (7.15)

这将普通方程的解从

w = (XTX)-1XTy (7.16)

变为

w=(XTX+aI)-1XTy. (7.17)

式(7.16)中的矩阵XTX与协方差矩阵mXTX成正比。L3正则项将这个矩阵替换 为式(7.17)中的 (XTX+aI)-1 这个新矩阵与原来的是一样的，不同的仅仅是在对 角加了 a。这个矩阵的对角项对应每个输人特征的方差。我们可以看到，L3正则化能 让学习算法“感知”到具有较高方差的输人^，因此与输出目标的协方差较小(相对 增加方差)的特征的权重将会收缩。

7.1.2 L1 参数正则化
L3权重衰减是权重衰减最常见的形式，我们还可以使用其他的方法限制模型参 数的规模。一个选择是使用L1正则化。

形式地，对模型参数w的L1正则化被定义为：

叫0) = llwlli = [ K (7.18)

i

即各个参数的绝对值之和3。接着我们将讨论L1正则化对简单线性回归模型的影响， 与分析L3正则化时一样不考虑偏置参数。我们尤其感兴趣的是找出L1和L3正则 化之间的差异。与L3权重衰减类似，我们也可以通过缩放惩罚项Q的正超参数a 来控制L1权重衰减的强度。因此，正则化的目标函数J(w;X,y)如下所示

J(w; X, y) = a|w|i + J(w; X, y), (7.19)

对应的梯度 (实际上是次梯度)：

▽wJ(w;X，y) = asign(w) + VwJ(w; X, y), (7.20)

其中 sign(w) 只是简单地取 w 各个元素的正负号。

观察式(7.20)，我们立刻发现L1的正则化效果与L2大不一样。具体来说，我 们可以看到正则化对梯度的影响不再是线性地缩放每个Wi；而是添加了一项与 sign(wi) 同号的常数。使用这种形式的梯度之后，我们不一定能得到 J(X,y;w) 二 次近似的直接算术解(L2正则化时可以)。

简单线性模型具有二次代价函数，我们可以通过泰勒级数表示。或者我们可以

设想，这是逼近更复杂模型的代价函数的截断泰勒级数。在这个设定下，梯度由下

式给出

^wJ(w) = H(w — w*),

(7.21)

同样，H是J在w*处的Hessian矩阵(关于w)。

由于 L1 惩罚项在完全一般化的 Hessian 的情况下，无法得到直接清晰的代数表 达式，因此我们将进一步简化假设Hessian是对角的，即H = diag([Hi,i,.. .，Hn,n])， 其中每个Hi,i > 0。如果线性回归问题中的数据已被预处理(如可以使用PCA。，去 除了输入特征之间的相关性，那么这一假设成立。

我们可以将L1正则化目标函数的二次近似分解成关于参数的求和：

J (w;X,y)=J(w*;X,y)+ 2 Hi,i(Wi — w*)2 + a|wi|

(7.22)

(7.23)

i

如下列形式的解析解(对每一维i。可以最小化这个近似代价函数：

Wi = sign(w*) max{|w*| — H_, .

对每个 i, 考虑 wi* > 0 的情形，会有两种可能结果：

1. W* < 的情况。正则化后目标中的Wi最优值是Wi = 0。这是因为在方向i 上J(w; X, y)对J(w; X, y)的贡献被抵消，L1正则化项将Wi推至0。 2. w* > Ha_的情况。在这种情况下，正则化不会将Wi的最优值推至0,而仅仅 在那个方向上移动的距离。

w* < 0的情况与之类似，但是L1惩罚项使Wi更接近0(增加Ht)或者为0。 相比L2正则化，L1正则化会产生更稀疏(sparse。的解。此处稀疏性指的是 最优值中的一些参数为0。和L2正则化相比，L1正则化的稀疏性具有本质的不同。 式(7.13)给出了 L2正则化的解w。如果我们使用Hessian矩阵H为对角正定矩阵 的假设(与L1正则化分析时一样)，重新考虑这个等式，我们发现Wi = HHi+_w*。 如果w*不是零，那么Wi也会保持非零。这表明L2正则化不会使参数变得稀疏，而 L1正则化有可能通过足够大的a实现稀疏。 由L1正则化导出的稀疏性质已经被广泛地用于特征选择(feature selection )机 制。特征选择从可用的特征子集选择出有意义的特征，化简机器学习问题。著名的 LASSO (Tibshirani, 1995) (Least Absolute Shrinkage and Selection Operator)模 型将 L1 惩罚和线性模型结合，并使用最小二乘代价函数。 L1 惩罚使部分子集的权 重为零，表明相应的特征可以被安全地忽略。 在第5.6.1节，我们看到许多正则化策略可以被解释为MAP贝叶斯推断，特别 是L2正则化相当于权重是高斯先验的MAP贝叶斯推断。对于L1正则化，用于正则 化代价函数的惩罚项aQ(w) = a£i |wi|与通过MAP贝叶斯推断最大化的对数先 验项是等价的(weRn并且权重先验是各向同性的拉普拉斯分布(式(3.26))): logp(w) = log Laplace(wi; 0，1) = —a II wh, + n log a — n log 2. (7.24) a1 i 因为是关于w最大化进行学习，我们可以忽略loga - log2项，因为它们与w无关。 7.2 作为约束的范数惩罚 考虑经过参数范数正则化的代价函数： J(0;X，y) = J(0; X，y) + aQ(0). (7.25) 回顾第4.4节我们可以构造一个广义 Lagrange 函数来最小化带约束的函数，即 在原始目标函数上添加一系列惩罚项。每个惩罚是一个被称为Karush - Kuhn -Tucker ( Karush-Kuhn-Tucker )乘子的系数以及一个表示约束是否满足的函数之 间的乘积。如果我们想约束Q(0)小于某个常数k，我们可以构建广义Lagrange函 数 L(0，a;X，y)=J(0;X，y)+a(Q(0)-k). (7.26) 这个约束问题的解由下式给出 0* = arg min maxL(0，a). (7.27) q a,a>0

如第4.4节中描述的，解决这个问题我们需要对0和a都做出调整。第4.5节给 出了一个带L2约束的线性回归实例。还有许多不同的优化方法，有些可能会使用梯 度下降而其他可能会使用梯度为0的解析解，但在所有过程中a在Q(0) > k时必 须增加，在Q(0) < k时必须减小。所有正值的a都鼓励Q(0)收缩。最优值a*也 将鼓励Q(0)收缩，但不会强到使得Q(0)小于k。

为了洞察约束的影响，我们可以固定a*，把这个问题看成只跟0有关的函数：

0* = arg min L(0, a*) = arg min J(0; X, y) + a*Q(0). (7.28)

e e

这和最小化 J 的正则化训练问题是完全一样的。因此，我们可以把参数范数惩罚看 作对权重强加的约束。如果Q是L2范数，那么权重就是被约束在一个L2球中。如 果Q是L1范数，那么权重就是被约束在一个L1范数限制的区域中。通常我们不 知道权重衰减系数 a* 约束的区域大小，因为 a* 的值不直接告诉我们 k 的值。原则 上我们可以解得k，但k和a*之间的关系取决于J的形式。虽然我们不知道约束 区域的确切大小，但我们可以通过增加或者减小 a 来大致扩大或收缩约束区域。较 大的a，将得到一个较小的约束区域。较小的a，将得到一个较大的约束区域。

有时候，我们希望使用显式的限制，而不是惩罚。如第4.4节所述，我们可以修 改下降算法(如随机梯度下降算法)，使其先计算 J(0) 的下降步，然后将 0 投影到 满足Q(0) < k的最近点。如果我们知道什么样的k是合适的，而不想花时间寻找对 应于此 k 处的 a 值，这会非常有用。

另一个使用显式约束和重投影而不是使用惩罚强加约束的原因是惩罚可能会导 致目标函数非凸而使算法陷人局部极小 (对应于小的 0)。当训练神经网络时，这通 常表现为训练带有几个 ‘‘死亡单元'' 的神经网络。这些单元不会对网络学到的函数 有太大影响，因为进人或离开它们的权重都非常小。当使用权重范数的惩罚训练时 即使可以通过增加权重以显著减少J，这些配置也可能是局部最优的。因为重投影 实现的显式约束不鼓励权重接近原点，所以在这些情况下效果更好。通过重投影实 现的显式约束只在权重变大并试图离开限制区域时产生作用。

最后，因为重投影的显式约束还对优化过程增加了一定的稳定性，所以这是另 一个好处。当使用较高的学习率时，很可能进人正反馈，即大的权重诱导大梯度，然 后使得权重获得较大更新。如果这些更新持续增加权重的大小， 0 就会迅速增大，直 到离原点很远而发生溢出。重投影的显式约束可以防止这种反馈环引起权重无限制 地持续增加。 Hinton et al. (2012c) 建议结合使用约束和高学习速率，这样能更快地 探索参数空间，并保持一定的稳定性。

Hinton et al. (2012c)尤其推荐由Srebro and Shraibman (2005)引人的策略：约 束神经网络层的权重矩阵每列的范数，而不是限制整个权重矩阵的 Frobenius 范数。 分别限制每一列的范数可以防止某一隐藏单元有非常大的权重。如果我们将此约束 转换成 Lagrange 函数中的一个惩罚，这将与 L2 权重衰减类似但每个隐藏单元的权

重都具有单独的 KKT 乘子。每个 KKT 乘子分别会被动态更新，以使每个隐藏单

元服从约束。在实践中，列范数的限制总是通过重投影的显式约束来实现。

7.3 正则化和欠约束问题
在某些情况下，为了正确定义机器学习问题，正则化是必要的。机器学习中许 多线性模型，包括线性回归和PCA，都依赖于对矩阵X X求逆。只要X X是奇 异的，这些方法就会失效。当数据生成分布在一些方向上确实没有差异时，或因为 例子较少(即相对输人特征的维数来说。而在一些方向上没有观察到方差时，这个 矩阵就是奇异的。在这种情况下，正则化的许多形式对应求逆XTX + aI。这个正则 化矩阵可以保证是可逆的。

相关矩阵可逆时，这些线性问题有闭式解。没有闭式解的问题也可能是欠定的。 一个例子是应用于线性可分问题的逻辑回归。如果权重向量w能够实现完美分类， 那么 2w 也会以更高似然实现完美分类。类似随机梯度下降的迭代优化算法将持续 增加 w 的大小，理论上永远不会停止。在实践中，数值实现的梯度下降最终会达到 导致数值溢出的超大权重，此时的行为将取决于程序员如何处理这些不是真正数字 的值。

大多数形式的正则化能够保证应用于欠定问题的迭代方法收敛。例如，当似然

的斜率等于权重衰减的系数时，权重衰减将阻止梯度下降继续增加权重的大小。

使用正则化解决欠定问题的想法不局限于机器学习。同样的想法在几个基本线

性代数问题中也非常有用。

正如我们在第2.9节看到的，我们可以使用Moore-Penrose求解欠定线性方程。 回想X伪逆X+的一个定义：

X+ = lim(XTX+aI)-1XT. (7.29)

a\0

现在我们可以将第7.29节看作进行具有权重衰减的线性回归。具体来说，当正则化系 数趋向 0 时，式(7.29)是式(7.17)的极限。因此，我们可以将伪逆解释为使用正则

化来稳定欠定问题

7.4 数据集增强
让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当然，在

实践中，我们拥有的数据量是很有限的。解决这个问题的一种方法是创建假数据并

添加到训练集中。对于一些机器学习任务，创建新的假数据相当简单。

对分类来说这种方法是最简单的。分类器需要一个复杂的高维输人并用单 个类别标识y概括这意味着分类面临的一个主要任务是要对各种各样的变换保 持不变。我们可以轻易通过转换训练集中的来生成新的(a;,y)对。

这种方法对于其他许多任务来说并不那么容易。例如，除非我们已经解决了密

度估计问题，否则在密度估计任务中生成新的假数据是很困难的。

数据集增强对一个具体的分类问题来说是特别有效的方法：对象识别。图像是

高维的并包括各种巨大的变化因素，其中有许多可以轻易地模拟。即使模型已使用

卷积和池化技术(第九章)对部分平移保持不变，沿训练图像每个方向平移几个像

素的操作通常可以大大改善泛化。许多其他操作如旋转图像或缩放图像也已被证明

非常有效。

我们必须要小心，不能使用会改变类别的转换。例如，光学字符识别任务需要 认识到 “b'' 和 “d'' 以及“6'' 和 “9'' 的区别，所以对这些任务来说，水平翻转和旋转 180。并不是合适的数据集增强方式。

能保持我们希望的分类不变，但不容易执行的转换也是存在的。例如，平面外

绕轴转动难以通过简单的几何运算在输人像素上实现。

数据集增强对语音识别任务也是有效的 (Jaitly and Hinton, 2013)。

在神经网络的输人层注人噪声 (Sietsma and Dow, 1991) 也可以被看作是数据增 强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输 人，任务仍应该是能够被解决的。然而，神经网络被证明对噪声不是非常健壮 (Tang and Eliasmith, 2010)。改善神经网络健壮性的方法之一是简单地将随机噪声添加到 输人再进行训练。输人噪声注人是一些无监督学习算法的一部分，如去噪自编码 器(Vincent et al., 2008a)。向隐藏单元施加噪声也是可行的，这可以被看作在多个抽 象层上进行的数据集增强。 Poole et al. (2014) 最近表明，噪声的幅度被细心调整后 该方法是非常高效的。我们将在第7.12节介绍一个强大的正则化策略Dropout，该 策略可以被看作是通过与噪声相乘构建新输入的过程。

在比较机器学习基准测试的结果时，考虑其采取的数据集增强是很重要的。通 常情况下，人工设计的数据集增强方案可以大大减少机器学习技术的泛化误差。将 一个机器学习算法的性能与另一个进行对比时，对照实验是必要的。在比较机器学 习算法A和机器学习算法B时，应该确保这两个算法使用同一人工设计的数据集增 强方案。假设算法 A 在没有数据集增强时表现不佳，而 B 结合大量人工转换的数 据后表现良好。在这样的情况下，很可能是合成转化引起了性能改进，而不是机器 学习算法B比算法A更好。有时候，确定实验是否已经适当控制需要主观判断。例 如，向输入注入噪声的机器学习算法是执行数据集增强的一种形式。通常，普适操 作(例如，向输入添加高斯噪声)被认为是机器学习算法的一部分，而特定于一个 应用领域(如随机地裁剪图像)的操作被认为是独立的预处理步骤。

7.5 噪声鲁棒性
第 7.4 节已经提出将噪声作用于输入，作为数据集增强策略。对于某些模型而言 向输人添加方差极小的噪声等价于对权重施加范数惩罚(Bishop, 1995a,b)。在一般情 况下，注入噪声远比简单地收缩参数强大，特别是噪声被添加到隐藏单元时会更加强 大。向隐藏单元添加噪声是值得单独讨论重要的话题；在第7.12节所述Dropout算 法是这种做法的主要发展方向。

另一种正则化模型的噪声使用方式是将其加到权重。这项技术主要用于循环神 经网络 (Jim et al., 1996; Graves, 2011)。这可以被解释为关于权重的贝叶斯推断的 随机实现。贝叶斯学习过程将权重视为不确定的，并且可以通过概率分布表示这种 不确定性。向权重添加噪声是反映这种不确定性的一种实用的随机方法。

在某些假设下，施加于权重的噪声可以被解释为与更传统的正则化形式等同 鼓励要学习的函数保持稳定。我们研究回归的情形，也就是训练将一组特征 x 映射 成一个标量的函数6(巧，并使用最小二乘代价函数衡量模型预测值6(巧与真实值y 的误差：

J = Ep(x,y)[(y(^) — y^]-

(7.30)

训练集包含m对标注样例{＞⑴，y⑴)，...，(x(m)，y(m))}

现在我们假设对每个输人表示，网络权重添加随机扰动£w〜N(e;0,nI)。想象 我们有一个标准的l层MLP。我们将扰动模型记为yew(a;)。尽管有噪声注人，我们

仍然希望减少网络输出误差的平方。因此目标函数变为：

JW = Ep(x,y,ew)[(yew(x) — y)\ (7.31)

=Ep(x,y,ew)[y2w(x)—城印(x) +y2]. (7.32)

对于小的n，最小化带权重噪声(方差为ni。的J等同于最小化附加正则化项: nEp(x,y)[||Vw y(x)||2]的J。这种形式的正则化鼓励参数进人权重小扰动对输出相对 影响较小的参数空间区域。换句话说，它推动模型进人对权重小的变化相对不敏感 的区域，找到的点不只是极小点，还是由平坦区域所包围的极小点(Hochreiter and Schmidhuber, 1995)。在简化的线性回归中(例如，y(x) = wTx + b。，正则项退化为 nEp(x)[||x||2]，这与函数的参数无关，因此不会对Jw关于模型参数的梯度有影响。

1

更一般地，我们可以将参数正则化为接近空间中的任意特定点，令人惊讶的是这样也仍有正则化效果，但是特定

点越接近真实值结果越好。当我们不知道正确的值应该是正还是负时，零是有意义的默认值。由于模型参数正则化为

2

零的情况更为常见，我们将只探讨这种特殊情况。

3

如同L3正则化，我们能将参数正则化到其他非零值w(o)。在这种情况下，L1正则化将会引人不同的项 = ||w- w(o) ||i = Ei |wi - wio)|。



7.5.1 向输出目标注入噪声
大多数数据集的y标签都有一定错误。错误的y不利于最大化logp(y | x)。避 免这种情况的一种方法是显式地对标签上的噪声进行建模。例如，我们可以假设，对 于一些小常数e，训练集标记y是正确的概率是1 - e，(以e的概率)任何其他可能 的标签也可能是正确的。这个假设很容易就能解析地与代价函数结合，而不用显式 地抽取噪声样本。例如，标签平滑(label smoothing。通过把确切分类目标从0和 1替换成^和1 - e，正则化具有k个输出的softmax函数的模型。标准交叉熵 损失可以用在这些非确切目标的输出上。使用softmax函数和明确目标的最大似然 学习可能永远不会收敛一softmax函数永远无法真正预测0概率或1概率，因此 它会继续学习越来越大的权重，使预测更极端。使用如权重衰减等其他正则化策略 能够防止这种情况。标签平滑的优势是能够防止模型追求确切概率而不影响模型学 习正确分类。这种策略自20世纪80年代就已经被使用，并在现代神经网络继续保 持显著特色 (Szegedy et al., 2015)。

7.6 半监督学习
在半监督学习的框架下，P(x)产生的未标记样本和P(x,y)中的标记样本都用 于估计 P(y | x) 或者根据 x 预测 y。

在深度学习的背景下，半监督学习通常指的是学习一个表示h = f(勾。学习表 示的目的是使相同类中的样本有类似的表示。无监督学习可以为如何在表示空间聚 集样本提供有用线索。在输人空间紧密聚集的样本应该被映射到类似的表示。在许 多情况下，新空间上的线性分类器可以达到较好的泛化 (Belkin and Niyogi, 2002; Chapelle et al., 2003)。这种方法的一个经典变种是使用主成分分析作为分类前(在 投影后的数据上分类)的预处理步骤。

我们可以构建这样一个模型，其中生成模型P(x)或P(x,y)与判别模型P(y I x) 共享参数，而不用分离无监督和监督部分。我们权衡监督模型准则 -logP(y | x) 和无监督或生成模型准则(如-logP(x)或-logP(x, y))。生成模型准则表达了 对监督学习问题解的特殊形式的先验知识(Lasserre et al., 2006)，即P(x)的结构通 过某种共享参数的方式连接到P(y | x)。通过控制在总准则中的生成准则，我们可 以获得比纯生成或纯判别训练准则更好的权衡 (Lasserre et al., 2006; Larochelle and Bengio, 2008a)。

Salakhutdinov and Hinton (2008) 描述了一种学习回归核机器中核函数的方法 其中建模 P(x) 时使用的未标记样本大大提高了 P(y| x) 的效果。

更多半监督学习的信息，请参阅Chapelle et al. (2006)。

7.7 多任务学习
多任务学习 (Caruana, 1993) 是通过合并几个任务中的样例(可以视为对参数 施加的软约束)来提高泛化的一种方式。正如额外的训练样本能够将模型参数推向 具有更好泛化能力的值一样，当模型的一部分被多个额外的任务共享时，这部分将 被约束为良好的值(如果共享合理)，通常会带来更好的泛化能力。

图7.2展示了多任务学习中非常普遍的一种形式，其中不同的监督任务(给定x 预测y1 2)共享相同的输人x以及一些中间层表示h(share)，能学习共同的因素池。 该模型通常可以分为两类相关的参数：


图 7.2: 多任务学习在深度学习框架中可以以多种方式进行，该图说明了任务共享相同输人但涉及 不同目标随机变量的常见情况。深度网络的较低层(无论是监督前馈的，还是包括向下箭头的生

成组件)可以跨这样的任务共享，而任务特定的参数(分别与从fo(1)和以2)进人和发出的权重) 可以在共享表示 h(shared) 之上学习。这里的基本假设是存在解释输人 x 变化的共同因素池，而每 个任务与这些因素的子集相关联。在该示例中，额外假设顶层隐藏单元fo(1)和以2)专用于每个任 务(分别预测y⑴和y2)，而一些中间层表示h(shared)在所有任务之间共享。在无监督学习情 况下，一些顶层因素不与输出任务(h(3))的任意一个关联是有意义的：这些因素可以解释一些输 人变化但与预测 y(1) 或 y2 不相关。

式增加的比例)，并能改善泛化和泛化误差的范围(Baxter, 1995)。当然，仅当不同

的任务之间存在某些统计关系的假设是合理(意味着某些参数能通过不同任务共享)

时才会发生这种情况。

从深度学习的观点看，底层的先验知识如下：能解释数据变化(在与之相关联

的不同任务中观察到)的因素中，某些因素是跨两个或更多任务共享的。

7.8 提前终止
当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，训练误

差会随着时间的推移逐渐降低但验证集的误差会再次上升。图7.3是这些现象的一个

例子，这种现象几乎一定会出现。

这意味着我们只要返回使验证集误差最低的参数设置，就可以获得验证集误差

更低的模型(并且因此有希望获得更好的测试误差)。在每次验证集误差有所改善 后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新

的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会

终止。此过程在算法7.1中有更正式的说明。

这种策略被称为提前终止（early stopping。。这可能是深度学习中最常用的正 则化形式。它的流行主要是因为有效性和简单性。

算法 7.1 用于确定最佳训练时间量的提前终止元算法。这种元算法是一种通用策略， 可以很好地在各种训练算法和各种量化验证集误差的方法上工作。_

令n为评估间隔的步数。

令p为“耐心（patience）”，即观察到较坏的验证集表现p次后终止。

令0。为初始参数。

0^0。

i 0 j 0 v I⑵

0*    0

i*    i

while j < p do

运行训练算法 n 步，更新 0 。 i i + n

vz 卜 ValidationSetError（0）

if v’ < v then

j 0 0* 0

i* i v l v’

else

j j + 1

end if

end while

最佳参数为 0*，最佳训练步数为 i*

我们可以认为提前终止是非常高效的超参数选择算法。按照这种观点，训练步

数仅是另一个超参数。我们从图7.3可以看到，这个超参数在验证集上具有 U 型性能 曲线。很多控制模型容量的超参数在验证集上都是这样的 U 型性能曲线，如图5.3 在提前终止的情况下，我们通过控制拟合训练集的步数来控制模型的有效容量。大 多数超参数的选择必须使用高代价的猜测和检查过程，我们需要在训练开始时猜测

一个超参数，然后运行几个步骤检查它的训练效果。 ‘‘训练时间'' 是唯一只要跑一次 训练就能尝试很多值的超参数。通过提前终止自动选择超参数的唯一显著的代价是

训练期间要定期评估验证集。在理想情况下，这可以并行在与主训练过程分离的机 器上，或独立的CPU，或独立的GPU上完成。如果没有这些额外的资源，可以使

用比训练集小的验证集或较不频繁地评估验证集来减小评估代价，较粗略地估算取

得最佳的训练时间。

另一个提前终止的额外代价是需要保持最佳的参数副本。这种代价一般是可忽 略的，因为可以将它储存在较慢较大的存储器上（例如，在GPU内存中训练，但将 最佳参数存储在主存储器或磁盘驱动器上）。由于最佳参数的写人很少发生而且从不 在训练过程中读取，这些偶发的慢写人对总训练时间的影响不大。

(pooq-9^--Mo--9AI4"t6M9u) ssoq


0.20

0.15

0.10

0.05

0.00


0 50 100 150 200 250 Time （epochs）


图 7.3: 学习曲线显示负对数似然损失如何随时间变化（表示为遍历数据集的训练迭代数，或 轮数

（epochs））。在这个例子中，我们在MNIST上训练了一个maxout网络。我们可以观察到训练目

标随时间持续减小，但验证集上的平均损失最终会再次增加，形成不对称的 U 形曲线。

提前终止是一种非常不显眼的正则化形式，它几乎不需要改变基本训练过程

目标函数或一组允许的参数值。这意味着，无需破坏学习动态就能很容易地使用提

前终止。相对于权重衰减，必须小心不能使用太多的权重衰减，以防网络陷人不良局

部极小点（对应于病态的小权重）。

提前终止可单独使用或与其他的正则化策略结合使用。即使为鼓励更好泛化，使

用正则化策略改进目标函数，在训练目标的局部极小点达到最好泛化也是非常罕见

的。

提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地

利用这一额外的数据，我们可以在完成提前终止的首次训练之后，进行额外的训练

在第二轮，即额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策

略都可以用于第二轮训练过程。

一个策略(算法7.2)是再次初始化模型，然后使用所有数据再次训练。在这个

第二轮训练过程中，我们使用第一轮提前终止训练确定的最佳步数。此过程有一些

细微之处。例如，我们没有办法知道重新训练时，对参数进行相同次数的更新和对

数据集进行相同次数的遍历哪一个更好。由于训练集变大了，在第二轮训练时，每

一次遍历数据集将会更多次地更新参数。

另一个策略是保持从第一轮训练获得的参数，然后使用全部的数据继续训练

在这个阶段，已经没有验证集指导我们需要在训练多少步后终止。取而代之，我们

可以监控验证集的平均损失函数，并继续训练，直到它低于提前终止过程终止时的

目标值。此策略避免了重新训练模型的高成本，但表现并没有那么好。例如，验证

集的目标不一定能达到之前的目标值，所以这种策略甚至不能保证终止。我们会在

算法7.3中更正式地介绍这个过程。

提前终止对减少训练过程的计算成本也是有用的。除了由于限制训练的迭代次

数而明显减少的计算成本，还带来了正则化的益处(不需要添加惩罚项的代价函

数或计算这种附加项的梯度)。

算法7.2使用提前终止确定训练步数，然后在所有数据上训练的元算法。_

令X(train)和y(train)为训练集。

将 X(train) 和 y(train) 分别分割为 (X(subtrain), X(valid)) 和 (y(subtrain), y(valid))。

从随机0开始，使用X e do

在 X(train) 和 y(train) 上训练 n 步。 end while

提前终止为何具有正则化效果: 目前为止，我们已经声明提前终止是一种正则化策 略，但我们只通过展示验证集误差的学习曲线是一个u型曲线来支持这种说法。 提前终止正则化模型的真正机制是什么呢？ Bishop (1995a)和Sjoberg and Ljung (1995) 认为提前终止可以将优化过程的参数空间限制在初始参数值00 的小邻域内。 更具体地，想象用学习率e进行t个优化步骤(对应于t个训练迭代)。我们可以 将eT作为有效容量的度量。假设梯度有界，限制迭代的次数和学习速率能够限制从 00 到达的参数空间的大小，如图7.4所示。在这个意义上， et 的效果就好像是权重 衰减系数的倒数。

事实上，在二次误差的简单线性模型和简单的梯度下降情况下，我们可以展示提 前终止相当于L2正则化。

为了与经典L2正则化比较，我们只考察唯一的参数是线性权重(0 = w。的简 单情形。我们在权重w的经验最佳值w*附近以二次近似建模代价函数J:

J(0) = J (w*) + ^(w — w*)TH(w — w*),    (7.33)

其中H是J关于w在w*点的Hessian。鉴于假设w*是J(w)的最小点，我们知 道H为半正定。在局部泰勒级数逼近下，梯度由下式给出：

▽wJ (w) = H(w — w*).    (7.34)

接下来我们研究训练时参数向量的轨迹。为简化起见，我们将参数向量初始化 为原点3,也就是w(0) = 0。我们通过分析J上的梯度下降来研究J上近似的梯度





图 7.4: 提前终止效果的示意图。 (左) 实线轮廓线表示负对数似然的轮廓。虚线表示从原点开始

的SGD所经过的轨迹。提前终止的轨迹在较早的点&处停止，而不是停止在最小化代价的点w* 处。f右J为了对比，使用L2正则化效果的示意图。虚线圆圈表示L2惩罚的轮廓，L2惩罚使得总 代价的最小值比非正则化代价的最小值更靠近原点。

下降的效果：

w(T) = w(T-1) - eVw/(w(T-1))    (7.35)

=w(T-1) - eH(w(T-1) - w*),    (7.36)

w(T) 一 w* = (I — eH)(w(T-1) — w*).    (7.37)

现在让我们在H特征向量的空间中改写表达式，利用H的特征分解：H= QAQt， 其中A是对角矩阵，Q是特征向量的一组标准正交基。

w⑺-w* = (I- eQAQT)(w(T-1) — w*)    (7.38)

Qt(w(t) 一 w*) = (I — eA)QT(w(T-1) — w*)    (7.39)

假定w(0) = 0并且e选择得足够小以保证|1 - eAi| < 1,经过t次参数更新后轨迹 如下：

QTw⑺=[I- (I- eA)T]QTw*.    (7.40)

现在，式(7.13)中QTw的表达式能被重写为：

QT w = (A + aI)-1AQT w*,    (7.41)

QTw= [I- (A + aI)-1a]QTw*.    (7.42)

比较式(7.40)和式(7.42)，我们能够发现，如果超参数e, a和t满足如下：

(I — eA)T = (A + aI)-1a,    (7.43)

那么 L2 正则化和提前终止可以被看作是等价的(至少在目标函数的二次近似下)。

进一步取对数，使用log (1+x)的级数展开，我们可以得出结论：如果所有人是 小的(即e\《1且Ai/a < 1 )，那么

1

t —， ea

1

a ——. te


(7.44)

(7.45)

也就是说，在这些假设下，训练迭代次数 t 起着与 L2 参数成反比的作用， te 的倒 数与权重衰减系数的作用类似。

在大曲率(目标函数)方向上的参数值受正则化影响小于小曲率方向。当然

在提前终止的情况下，这实际上意味着在大曲率方向的参数比较小曲率方向的参数

更早地学习到。

本节中的推导表明长度为t的轨迹结束于L2正则化目标的极小点。当然，提前 终止比简单的轨迹长度限制更丰富；取而代之，提前终止通常涉及监控验证集误差 以便在空间特别好的点处终止轨迹。因此提前终止比权重衰减更具有优势，提前终 止能自动确定正则化的正确量，而权重衰减需要进行多个不同超参数值的训练实验。

7.9 参数绑定和参数共享
目前为止，本章讨论对参数添加约束或惩罚时，一直是相对于固定的区域或点。 例如，L2正则化(或权重衰减)对参数偏离零的固定值进行惩罚。然而，有时我们 可能需要其他的方式来表达我们对模型参数适当值的先验知识。有时候，我们可能 无法准确地知道应该使用什么样的参数，但我们根据相关领域和模型结构方面的知 识得知模型参数之间应该存在一些相关性。

我们经常想要表达的一种常见依赖是某些参数应当彼此接近。考虑以下情形

我们有两个模型执行相同的分类任务(具有相同类别)，但输人分布稍有不同。形式 地，我们有参数为w(A)的模型A和参数为w⑻的模型B。这两种模型将输人映射 到两个不同但相关的输出：y(A) = f (w(A)，$)和y(B) = f(w(b)，t)。

我们可以想象，这些任务会足够相似（或许具有相似的输入和输出分布。，因 此我们认为模型参数应彼此靠近：Vi,w（A）应该与w（B）接近。我们可以通过正则 化利用此信息。具体来说，我们可以使用以下形式的参数范数惩罚：Q（w（A）, w（B））= ||w（A） - w^B） ||2。在这里我们使用L2惩罚，但也可以使用其他选择。

这种方法由Lasserre ef aZ. （2006）提出，正则化一个模型（监督模式下训练的分 类器。的参数，使其接近另一个无监督模式下训练的模型（捕捉观察到的输入数据 的分布。的参数。构造的这种架构使得分类模型中的许多参数能与无监督模型中对 应的参数匹配。

参数范数惩罚是正则化参数使其彼此接近的一种方式，而更流行的方法是使用 约束： 强迫某些参数相等。由于我们将各种模型或模型组件解释为共享唯一的一组 参数，这种正则化方法通常被称为参数共享（parameter sharing。。和正则化参数使 其接近（通过范数惩罚。相比，参数共享的一个显著优点是，只有参数（唯一一个集 合。的子集需要被存储在内存中。对于某些特定模型，如卷积神经网络，这可能可 以显著减少模型所占用的内存。

7.9.1 卷积神经网络
目前为止，最流行和广泛使用的参数共享出现在应用于计算机视觉的卷积神经 网络（CNN。中。

自然图像有许多统计属性是对转换不变的。例如，猫的照片即使向右边移了一

个像素，仍保持猫的照片。CNN通过在图像多个位置共享参数来考虑这个特性。相

同的特征（具有相同权重的隐藏单元。在输入的不同位置上计算获得。这意味着无

论猫出现在图像中的第i列或i + 1列，我们都可以使用相同的猫探测器找到猫。

参数共享显著降低了CNN模型的参数数量，并显著提高了网络的大小而不需要 相应地增加训练数据。它仍然是将领域知识有效地整合到网络架构的最佳范例之一。

我们将会在第九章中更详细地讨论卷积神经网络。

7.10 稀疏表示
前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中的激活

单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。

我们已经讨论过（在第7.1.2节中）L1惩罚如何诱导稀疏的参数，即许多参数为

零（或接近于零）。另一方面，表示的稀疏描述了许多元素是零（或接近零）的表示。

我们可以线性回归的情况下简单说明这种区别：

18

4

0

0

-2

0

0

5

0

0

-1

0

3

0

15

=

0

5

0

0

0

0

-9

1

0

0

-1

0

-4

-3

1

0

0

0

-5

0

2

3

-2

-5

1

4

E Rn

y E Rm

A e RmXn


-14

3-

1

42

19

=

-1 5

2

31

23

-5 4

E Rm


2

-5

4

1

-3

-1

1

3

4

2

-3

-2

2

-3

0

-3

-2

2

-5

-1

BE

Rm X n

0

2

0

0

-3

0

h E Rn


(7.46)


(7.47)


第一个表达式是参数稀疏的线性回归模型的例子。第二个表达式是数据 x 具 有稀疏表示h的线性回归。也就是说，h是的一个函数，在某种意义上表示存在 于 x 中的信息，但只是用一个稀疏向量表示。

表示的正则化可以使用参数正则化中同种类型的机制实现。

表示的范数惩罚正则化是通过向损失函数 J 添加对表示的范数惩罚来实现的。 我们将这个惩罚记作Q（h）。和以前一样，我们将正则化后的损失函数记作J:

J（0; X，y） = J（0; X，y） + aQ（h），    （7.48）

其中a e [0，⑻]权衡范数惩罚项的相对贡献，越大的a对应越多的正则化。

正如对参数的 L1 惩罚诱导参数稀疏性，对表示元素的 L1 惩罚诱导稀疏的表示 Q（h） = ||h^1 = £i |hi|。当然L1惩罚是使表示稀疏的方法之一。其他方法还包括 从表示上的Student-t 先验导出的惩罚（Olshausen and Field, 1996; Bergstra, 2011） 和KL散度惩罚（Larochelle and Bengio, 2008b），这些方法对于将表示中的元素约束 于单位区间上特别有用。Lee et ‘（2008）和Goodfellow et ‘（2009）都提供了正则 化几个样本平均激活的例子，即令m^ Ei h（i）接近某些目标值（如每项都是.01的向

量)

还有一些其他方法通过激活值的硬性约束来获得表示稀疏。例如， 正交匹配追 踪 (orthogonal matching pursuit)(Pati et al., 1993) 通过解决以下约束优化问题将输 入值 x 编码成表示 h

arg min h- Wh||2,    (7.49)

Mh"0jy> pensemble (y; | x)


(7.55)


涉及Dropout的一个重要观点(Hinton et al., 2012c)是，我们可以通过评估模型 中P(y | X)来近似Pensemble：该模型具有所有单元，但我们将单元i的输出的权重乘 以单元i的被包含概率。这个修改的动机是得到从该单元输出的正确期望值。我们 把这种方法称为权重比例推断规则(weight scaling inference rule。。目前还没有在

深度非线性网络上对这种近似推断规则的准确性作任何理论分析，但经验上表现得

很好。

因为我们通常使用1的包含概率，权重比例规则一般相当于在训练结束后将权 重除 2，然后像平常一样使用模型。实现相同结果的另一种方法是在训练期间将单元 的状态乘 2。无论哪种方式，我们的目标是确保在测试时一个单元的期望总输人与在 训练时该单元的期望总输人是大致相同的(即使近半单位在训练时丢失。。

对许多不具有非线性隐藏单元的模型族而言，权重比例推断规则是精确的。举 个简单的例子，考虑softmax函数回归分类，其中由向量v表示n个输人变量：

P(y = y | v) = softmax( WTv + b)y.

(7.56)


(7.57)


(7.58)


我们可以根据二值向量d逐元素的乘法将一类子模型进行索引：

P(y = y | v; d) = softmax(WT(d© v) + b)y. 集成预测器被定义为重新标准化所有集成成员预测的几何平均：

Pensemble(y = y | v)


Pensemble(y = y 丨 v)

y^y> Pensemble(y = y’ | v)

其中

Pensemble(y = y 丨 v)


2n    P(y = y | v; d).

V de{0,i}n


(7.59)


为了证明权重比例推断规则是精确的，我们简化

Pensemble

Pensemble ( y = y | v)


2n    P(y=y |v;d)

y de{0,i}n

2' Il softmax( WT(d0 v) + b)y

V de{0，i}n


n

de{0,i}1


eXP(Wy，:(d0 V)+ by)

Ey/ eXP( WT，;(dOV) + M


zn


dG{0,1}n


exP(WJ,：(d© v) + by)


Vnde{0,i}n Ey exP( wT,:(d© v) + by)

由于P将被标准化，我们可以放心地忽略那些相对y不变的乘法：


Pensemble(y = y | V) K 2^ JJ eXp(Wj，:(d© V)+ by)

£    WT；(d © V) +

de{0,i}n    /


de{0,i}n

1


exp


(1w,


V+by


(7.60)

(7.61)

(7.62)

(7.63)

(7.64)

(7.65)

(7.66)


将其代人式(7.58)，我们得到了一个权重为i W的softmax函数分类器。

权重比例推断规则在其他设定下也是精确的，包括条件正态输出的回归网络以

及那些隐藏层不包含非线性的深度网络。然而，权重比例推断规则对具有非线性的 深度模型仅仅是一个近似。虽然这个近似尚未有理论上的分析，但在实践中往往效 果很好。 Goodfellow et al. (2013b) 实验发现，在对集成预测的近似方面，权重比例 推断规则比蒙特卡罗近似更好(就分类精度而言)。即使允许蒙特卡罗近似采样多达 1000 子网络时也比不过权重比例推断规则。 Gal and Ghahramani (2015) 发现一些 模型可以通过二十个样本和蒙特卡罗近似获得更好的分类精度。似乎推断近似的最 佳选择是与问题相关的。

Srivastava et al. (2014)显示，Dropout比其他标准的计算开销小的正则化方法 (如权重衰减、过滤器范数约束和稀疏激活的正则化)更有效。Dropout也可以与其 他形式的正则化合并，得到进一步的提升。

计算方便是Dropout的一个优点。训练过程中使用Dropout产生n个随机二进制 数与状态相乘，每个样本每次更新只需O(n)的计算复杂度。根据实现，也可能需要

O(n) 的存储空间来持续保存这些二进制数(直到反向传播阶段)。使用训练好的模

型推断时，计算每个样本的代价与不使用Dropout是一样的，尽管我们必须在开始运 行推断前将权重除以 2。

Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。几乎在所有 使用分布式表示且可以用随机梯度下降训练的模型上都表现很好。包括前馈神经网 络、概率模型，如受限玻尔兹曼机(Srivastava et aZ., 2014)，以及循环神经网络(Bayer and Osendorfer, 2014; Pascanu et al., 2014a)。许多效果差不多的其他正则化策略对 模型结构的限制更严格。

虽然Dropout在特定模型上每一步的代价是微不足道的，但在一个完整的系统 上使用Dropout的代价可能非常显著。因为Dropout是一个正则化技术，它减少了模 型的有效容量。为了抵消这种影响，我们必须增大模型规模。不出意外的话，使 用Dropout时最佳验证集的误差会低很多，但这是以更大的模型和更多训练算法的迭 代次数为代价换来的。对于非常大的数据集，正则化带来的泛化误差减少得很小。在 这些情况下，使用Dropout和更大模型的计算代价可能超过正则化带来的好处。

只有极少的训练样本可用时，Dropout不会很有效。在只有不到5000的样本 的Alternative Splicing数据集上(Xiong et al., 2011)，贝叶斯神经网络(Neal, 1996) 比Dropout表现得更好(Srivastava et al., 2014)。当有其他未分类的数据可用时，无 监督特征学习也比Dropout更有优势。

Wager et al. (2013)表明，当Dropout作用于线性回归时，相当于每个输人特征 具有不同权重衰减系数的L2权重衰减。每个特征的权重衰减系数的大小是由其方差 来确定的。其他线性模型也有类似的结果。而对于深度模型而言，Dropout与权重衰 减是不等同的。

使用Dropout训练时的随机性不是这个方法成功的必要条件。它仅仅是近似所有 子模型总和的一个方法。 Wang and Manning (2013) 导出了近似这种边缘分布的解 析解。他们的近似被称为快速Dropout ( fast dropout )，减小梯度计算中的随机性 而获得更快的收敛速度。这种方法也可以在测试时应用，能够比权重比例推断规则更 合理地(但计算也更昂贵)近似所有子网络的平均。快速Dropout在小神经网络上 的性能几乎与标准的Dropout相当，但在大问题上尚未产生显著改善或尚未应用。

随机性对实现Dropout的正则化效果不是必要的，同时也不是充分的。为了证明 这一点， Warde-Farley et al. (2014) 使用一种被称为 Dropout Boosting 的方法设 计了一个对照实验，具有与传统Dropout方法完全相同的噪声掩码，但缺乏正则化效

果。Dropout Boosting训练整个集成以最大化训练集上的似然。从传统Dropout类 似于Bagging的角度来看，这种方式类似于Boosting。如预期一样，和单一模型训 练整个网络相比，Dropout Boosting几乎没有正则化效果。这表明，使用Bagging解 释Dropout比使用稳健性噪声解释Dropout更好。只有当随机抽样的集成成员相互独 立地训练好后，才能达到Bagging集成的正则化效果。

Dropout启发其他以随机方法训练指数量级的共享权重的集成。DropConnect是 Dropout的一个特殊情况，其中一个标量权重和单个隐藏单元状态之间的每个乘积 被认为是可以丢弃的一个单元(Wan et al, 2013)。随机池化是构造卷积神经网络集 成的一种随机化池化的形式 (见第9.3节)，其中每个卷积网络参与每个特征图的不同 空间位置。目前为止，Dropout仍然是最广泛使用的隐式集成方法。

一个关于Dropout的重要见解是，通过随机行为训练网络并平均多个随机决定进 行预测，实现了一种参数共享的Bagging形式。早些时候，我们将Dropout描述为通 过包括或排除单元形成模型集成的Bagging。然而，这种参数共享策略不一定要基于 包括和排除。原则上，任何一种随机的修改都是可接受的。在实践中，我们必须选 择让神经网络能够学习对抗的修改类型。在理想情况下，我们也应该使用可以快速 近似推断的模型族。我们可以认为由向量m参数化的任何形式的修改，是对M所有 可能的值训练P(y | x,m)的集成。注意，这里不要求m具有有限数量的值。例如， M可以是实值。Srivastava et al. (2014)表明，权重乘以m〜N(1, I)比基于二值掩 码Dropout表现得更好。由于E[m] = 1，标准网络自动实现集成的近似推断，而不需 要权重比例推断规则。

目前为止，我们将Dropout介绍为一种纯粹高效近似Bagging的方法。然而，还 有比这更进一步的Dropout观点。Dropout不仅仅是训练一个Bagging的集成模型，并 且是共享隐藏单元的集成模型。这意味着无论其他隐藏单元是否在模型中，每个隐藏 单元必须都能够表现良好。隐藏单元必须准备好进行模型之间的交换和互换。 Hinton et al. (2012d) 由生物学的想法受到启发：有性繁殖涉及到两个不同生物体之间交换 基因，进化产生的压力使得基因不仅是良好的而且要准备好不同有机体之间的交换。 这样的基因和这些特点对环境的变化是非常稳健的，因为它们一定会正确适应任何 一个有机体或模型不寻常的特性。因此Dropout正则化每个隐藏单元不仅是一个很好 的特征，更要在许多情况下是良好的特征。Warde-Farley et al. (2014)将Dropout与 大集成的训练相比并得出结论：相比独立模型集成获得泛化误差改进，Dropout会带 来额外的改进。

Dropout强大的大部分原因来自施加到隐藏单元的掩码噪声，了解这一事实是重

要的。这可以看作是对输人内容的信息高度智能化、自适应破坏的一种形式，而不 是对输人原始值的破坏。例如，如果模型学得通过鼻检测脸的隐藏单元hi，那么丢 失hi对应于擦除图像中有鼻子的信息。模型必须学习另一种hi，要么是鼻子存在的 冗余编码，要么是像嘴这样的脸部的另一特征。传统的噪声注人技术，在输人端加 非结构化的噪声不能够随机地从脸部图像中抹去关于鼻子的信息，除非噪声的幅度 大到几乎能抹去图像中所有的信息。破坏提取的特征而不是原始值，让破坏过程充 分利用该模型迄今获得的关于输人分布的所有知识。

Dropout的另一个重要方面是噪声是乘性的。如果是固定规模的加性噪声，那么 加了噪声e的整流线性隐藏单元可以简单地学会使hi变得很大(使增加的噪声e变 得不显著)。乘性噪声不允许这样病态地解决噪声鲁棒性问题。

另一种深度学习算法——批标准化，在训练时向隐藏单元引人加性和乘性噪声 重新参数化模型。批标准化的主要目的是改善优化，但噪声具有正则化的效果，有 时没必要再使用Dropout。批标准化将会在第8.7.1节中被更详细地讨论。

7.13 对抗训练
在许多情况下，神经网络在独立同分布的测试集上进行评估已经达到了人类表

现。因此，我们自然要怀疑这些模型在这些任务上是否获得了真正的人类层次的理 解。为了探索网络对底层任务的理解层次，我们可以探索这个模型错误分类的例子。 Szegedy et al. (2014b) 发现，在精度达到人类水平的神经网络上通过优化过程故意 构造数据点，其上的误差率接近100%，模型在这个输人点的输出与附近的数据 点非常不同。在许多情况下，与非常近似，人类观察者不会察觉原始样本 和对抗样本(adversarial example )之间的差异，但是网络会作出非常不同的预测。 见图7.8中的例子。

对抗样本在很多领域有很多影响，例如计算机安全，这超出了本章的范围。然 而，它们在正则化的背景下很有意思，因为我们可以通过对抗训练(adversarial training)减少原有独立同分布的测试集的错误率一在对抗扰动的训练集样本上训 练网络 (Szegedy et al., 2014b; Goodfellow et al., 2014b)。

Goodfellow et al. (2014b) 表明，这些对抗样本的主要原因之一是过度线性。神 经网络主要是基于线性块构建的。因此在一些实验中，它们实现的整体函数被证明 是高度线性的。这些线性函数很容易优化。不幸的是，如果一个线性函数具有许多



+ .007 X



x

y =“panda” w/ 57.7% confidence


x+

esign(VxJ(0，x，y)) “gibbon” w/ 99.3 %

confidence


sign(VxJ(0,x，y))

“nematode”

w/ 8.2% confidence


图 7.8: 在 ImageNet 上应用 GoogLeNet (Szegedy et al., 2014a) 的对抗样本生成的演示。通过添 加一个不可察觉的小向量(其中元素等于代价函数相对于输人的梯度元素的符号)，我们可以改变

GoogLeNet对此图儀的分类结果。经Goodfellow社a! (2014b)许可转载。

输人，那么它的值可以非常迅速地改变。如果我们用e改变每个输人，那么权重为 w的线性函数可以改变e ||w||i之多，如果w是高维的这会是一个非常大的数。对 抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线 性行为。这可以被看作是一种明确地向监督神经网络引人局部恒定先验的方法。

对抗训练有助于体现积极正则化与大型函数族结合的力量。纯粹的线性模型

如逻辑回归，由于它们被限制为线性而无法抵抗对抗样本。神经网络能够将函数从

接近线性转化为局部近似恒定，从而可以灵活地捕获到训练数据中的线性趋势同时

学习抵抗局部扰动。

对抗样本也提供了一种实现半监督学习的方法。在与数据集中的标签不相关联 的点x处，模型本身为其分配一些标签y。模型的标记y未必是真正的标签，但如 果模型是高品质的，那么y提供正确标签的可能性很大。我们可以搜索一个对抗样 本x\导致分类器输出一个标签y'且y' = y。不使用真正的标签，而是由训练好 的模型提供标签产生的对抗样本被称为 虚拟对抗样本( virtual adversarial example) (Miyato et al., 2015)。我们可以训练分类器为 x 和 x' 分配相同的标签。这鼓励分类 器学习一个沿着未标签数据所在流形上任意微小变化都很鲁棒的函数。驱动这种方 法的假设是，不同的类通常位于分离的流形上，并且小扰动不会使数据点从一个类 的流形跳到另一个类的流形上。

7.14 切面距离、正切传播和流形正切分类器
如第5.11.3节所述，许多机器学习通过假设数据位于低维流形附近来克服维数

灾难。

一个利用流形假设的早期尝试是切面距离(tangent distance。算法(Simard et al., 1993, 1998)。它是一种非参数的最近邻算法，其中使用的度量不是通用的欧几 里德距离，而是根据邻近流形关于聚集概率的知识导出的。这个算法假设我们尝试 分类的样本和同一流形上的样本具有相同的类别。由于分类器应该对局部因素(对 应于流形上的移动)的变化保持不变，一种合理的度量是将点和X2各自所在流 形Mi和M2的距离作为点Xi和X2之间的最近邻距离。然而这可能在计算上是困 难的(它需要解决一个寻找 M1 和 M2 最近点对的优化问题。，一种局部合理的廉价 替代是使用Xi点处切平面近似Mi，并测量两条切平面或一个切平面和点之间的距 离。这可以通过求解一个低维线性系统(就流形的维数而言。来实现。当然，这种算 法需要指定那些切向量。

受相关启发，正切传播(tangent prop。算法(Simard et al., 1992)(图7.9。训 练带有额外惩罚的神经网络分类器，使神经网络的每个输出 f(X) 对已知的变化因素 是局部不变的。这些变化因素对应于沿着的相同样本聚集的流形的移动。这里实现 局部不变性的方法是要求Vxf(x)与已知流形的切向#〉正交，或者等价地通过正 则化惩罚Q使f在X的17(i)方向的导数较小：





# COMMENT
