---
title: DL 不平衡样本的处理
toc: true
date: 2018-06-26 19:34:10
---

## 相关资料
1. 《解析卷积神经网络》魏秀参


## 需要补充的






  * aaa



* * *




# INTRODUCTION






  * aaa
















不平衡样本的处理

在机器学习的经典假

是均衡（平衡）的，

一般说来，不平衡（

的类别，而“轻视”

受到影响。一个极端 而负例只有i个。

“放弃”负例预测，因

准确率。但是试想，

1%的测试正确率，


















设中往往假定训练样本各类别是同等数量即各类样本数目 但我们真实场景中遇到的实际任务却时常不符合这一假设。 imbalance）的训练样本会导致训练模型侧重样本数目较多 样本数目较少类别，这样模型在测试数据上的泛化能力就会 5的例子是对于某二分类问题，训练集中有99个正例样本， 不考虑样本不平衡的很多情况下，学习算法会使分类器 3为把所有样本都分为“正”便可获得高达99%的训练分类 若测试集有99个负例仅1个正例，这样该分类器仅仅只有 完全丧失了测试集上的预测能力。其实，除了常见的分类、 语义分割（semantic segmentation） [60]、深度估计（depth 素级别任务中也不乏不平衡样本出现的现象。为了进一步 解决网络训练时经常遇到的不平衡样本处理问题，本章将 算法层面”两个方面介绍不平衡样本问题的处理方法。



lampling）使整体训练集样本趋于平衡，


12.1

数据层e 即各类

12.1.1




勺数据重采样包括上采样（over-sampling或up-sampling）和下采样 •-sampling或down-sampling）。对于样本较少类，可使用上采样，即复制 C象直至与样本最多类的样本数一致。当然也可以用数据扩充方式替代简 ）制操作。而对于样本较多类别，可采用下采样。需指出的是，对深度学 「下采样并不是直接随机丢弃一部分图像，因为那样做会降低训练数据多 i而影响模型泛化能力。正确的下采样方式为，在批处理训练时对每批随 〔的图像严格控制其样本较多类别的图像数量。以二分类为例，原数据分 a下每次批处理训练正负样本平均数量比例为5 : 1。如仅使用下采样，可



12.1.数据层面处理方法

在每批随机挑选训练样本时每5个正例只取1个放人作为该批训练集的正例，

负例选取仍按照原来准则，这样可使得每批选取的数据中正负比例均等。此外，

还需指出的是，仅使用数据上采样有可能会引起模型过拟合问题。更保险且有

效的数据重采样是将上采样和下采样结合使用。

12.1.2类别平衡采样

另一类数据重采样策略则直接着眼于类别，即类别平衡采样。其策略是把样本

按类别分组，每个类别生成一个样本列表。训练过程中先随机选择1个或几个 类别，然后从各个类别所对应的样本列表中随机选择样本。这样可以保证每个 类别参与训练的机会比较均衡。

不过上述方法对于样本类别较多任务需事先定义与类别数等量的列表，对 于海量类别任务如ImageNet数据集等此举将极其繁琐。在类别平衡采样的基 础上，国内海康威视研究院Shicai Yang等在ILSVRC场景分类任务中提出了 “类别重组”(label shuffling) ［92］的平衡方法，值得一提的是他们还获得2016 年ILSVRC场景分类(scene classification)任务的冠军。

类别重组法［92］只需原始图像列表即可完成同样的均匀采样任务。如图

12.2,其方法步骤如下：首先按照类别顺序对原始样本进行排序，之后计算每 个类别的样本数目，并记录样本最多的那个类别的样本数量。之后，根据这个 最多样本数对每类样本产生一个随机排列列表，然后用此列表中的随机数对各 自类别的样本数求余，得到对应的索引值。接着，根据索引从该类的图像中提 取图像，生成该类的图像随机列表。之后，把所有类别的随机列表连在一起随 机打乱次序，即可得到最终图像列表，可以发现最终列表中每类样本数目均等。 根据此列表训练模型，当训练时列表遍历完毕，则重头再做一遍上述操作即可 进行第二轮训练，如此重复下去……类别重组法的优点在于，只需原始图像列 表，且所有操作均在内存中在线完成，易于实现。细心的读者或许能发现，类 别重组法与上节提到的数据下采样有异曲同工之意。

ID

图像名

图像类别

0

img0⑻

a

1

img001

a

2

img002

a

0

img003

b

1

img004

b

0

img005

c

1

img006

c

2

img007

c

3

img008

c

4

img009

c

1.按类别排序




0



img0⑻

a

img004

b

img006

c

img001

a

img003

b

img002

a

img007

c

img004

b

img0⑻

a

img009

c

img001

a

img005

c

img008

c

img003

b

img003

b

6.随机打乱


图12.2:类别


12.2
对于不平衡样本导致样本数目较少的类别“欠学习”这一现象，一个很自然的 解决办法是增加小样本错分的“惩罚代价”并将此“惩罚代价”直接体现在目 标函数中，这便是“代价敏感”方法、这样通过优化目标函数就可以调整模型 在小样本上的“注意力”。算法层面处理不平衡样本问题的方法也多从代价敏感 (cost-sensitive)角度出发。

12.2.1代价敏感方法

代价敏感方法可概括为两种，一则基于代价敏感矩阵，另一则是基于代价敏感

1可将原始目标函数看作对不同类别样本错分权重均等的情形。在使用代价敏感法后，如错分则

施加对应权重的惩罚，相对样本较多类别来说小样本类别其错分代价往往更高。

12.2.算法层面处理方法

基于代价敏感矩阵的代价敏感

以分类问题为例，假设某训练集共N个样本，形如：{Xn,yn}N=1,其中样本标 记y隶属于K类。基于代价敏感矩阵方法是利用K x K的矩阵C对不同样 本类别施加错分惩罚(亦可称为权重)：

C(1, 1) C(1, 2) C(2, 1) C(2, 2)

C (K, 1) C (K, 2

其中，C(yi,yj) e [0,^)表示类别yi错分为类别yj的“惩罚”或“代价”，其 取值不小于0;且C(yi,yi)=0。施加代价后的训练目标变为：训练得到某分类 器g使得期望代价之和EnC(yn,g(Xn))最小。可以发现，式12.1中的代价敏 感矩阵反映的是类别级别的错分惩罚。

基于代价敏感向量的代价敏感

另一种代价敏感的反映方式则针对样本级别：对某样本(Xn,yn),有对应的一 个K维代价敏感向量Cn € [0, ^)K，其中Cn的第k维表示该样本被错分为 第k类的惩罚，自然其第yn维应为0。基于代价敏感向量的方法在模型训练阶 段是将样本级别的代价敏感向量与样本以 (xn,yn,Cn) 三元组形式一同作为输 人数据送人学习算法。细心的读者不难发现，代价敏感矩阵法实际上是代价敏 感向量法的一种特殊形式，即对于某类的所有样本其错分惩罚向量为同一向量。

12.2.2代价敏感法中权重的指定方式

通过以上描述可发现，代价敏感方法处理不平衡样本问题的前提是需事先指定

代价敏感矩阵或向量，其中关键是错分惩罚或错分权重的设定。实际使用中可

根据样本比例、分类结果的混淆矩阵等信息指定代价敏感矩阵或向量中错分权

按照样本比例指定

在此以代价敏感矩阵为例说明如何按照样本比例信息指定矩阵取值。假设训练 样本标记共计3类：a类，b类和c类，它们的样本数目比例为3 : 2 : 1。则根 据节12+2+1的描述，代价敏感矩阵可指定为：

113 112 O

2-3 O 2

O 3-2 3


具体来讲，当a类样本被错分为b类(c类)时，由于其样本数最多，对应惩 罚权重可设为稍小值，即b类(c类)样本数与a类样本数的比值3 (1);当b 类样本被错分为a类(c类)时，对应惩罚权重同样为a类(c类)样本数与 b类样本数的比值2 (2);当样本数最少的c类样本被错分为a类(b类)时， 对应惩罚权重应加大，为 3 (2)，以增加小样本错分代价从而体现小样本数据 的重要程度。当然，也可在以上矩阵基础上对矩阵元素都乘上类别数的最小公 倍数6,确保有效惩罚权重不小于1,即：

042

C =    9    0    3.    (12.3)

18 12 0

根据混淆矩阵指定

混淆矩阵(confusion matrix)是人工智能中的一种算法分析工具，用来度量模

型或学习算法在监督学习中预测能力的优劣。在机器学习领域,混淆矩阵通常 也被称作“列联表”或“误差矩阵”。混淆矩阵的每一列代表一个类的实例预测 而每一行表示其真实类别,如下表所示。仍以 a、b、c 三类分类为例,有如下

混淆矩阵：

矩阵对角线为正确分类样本数，各类分别为4、3和21。矩阵其他位置为错 分样本数，如a类错分为b类的样本数为1,错分为c类的样本数为3; b类 错分为a类的样本有2个，错分为c类的样本有4个；c类错分为a类的样本 数为3个，错分为b类的样本有2个。虽说各类错分的样本数的绝对数值接近

12.3.小结

预测结果

类别《

类别*

类别c

真实标记

类别打

4

1

3

类别*

2

3

4

类别C

3

2

21

（均错分了 3个左右的样本），但相对而言，样本数较少的a和b类分别有50% 和66.67%样本被错分，比例相当高。而对于样本较多的c类，其错分概率就 相对较低（约19%）。该情况下利用代价敏感法处理时，可根据各类错分样本数 设置代价敏感矩阵的取值。一种方式可直接以错分样本数为矩阵取值：

013

C =    2 0 4    .    （12.4）

320

不过，更优方案还需考虑各类的错分比例，并以此比例调整各类错分权重。对 a类而言，a类错分比例为50%,占所有错分比例136% （50%十67%十19%）的 百分之36.76;同理，b类占49.26%, c类最少，占13.97%。以此为权重乘上 原代价矩阵可得新的代价矩阵（已取整）：

(12+5)

12.3小结
§ 许多真实应用问题中都会遇到样本不平衡问题,且样本不平衡对深度网络

模型的预测性能有较大影响,因此在实践中需考虑样本不平衡因素并做出

解决方案；

§ 数据层面多采用数据重采样法处理样本不平衡问题,其操作简单,不过该 类方法会改变数据原始分布,有可能因此产生过拟合等问题；

§ 算法层面多采用代价敏感法处理样本不平衡问题，通过指定代价敏感矩阵 或代价敏感向量的错分权重，可缓解样本不平衡带来的影响。



















* * *




# COMMENT
