# 需要补充的

- 感觉透视变换还是会经常使用的，尤其是在我们对摄像头拍摄的画面进行处理的时候，或者对视频画面进行过处理的时候，或者进行别的预处理的时候，经常会使用这个。

# 透视变换

对于视角变换，我们需要一个 3x3 变换矩阵。在变换前后直线还是直线要构建这个变换矩阵，你需要在输入图像上找 4 个点，以及他们在输出图像上对应的位置。

这四个点中的任意三个都不能共线。

这个变换矩阵可以有函数 `cv2.getPerspectiveTransform()` 构建。然后把这个矩阵传给函数 `cv2.warpPerspective`。

一个例子：

```py
import cv2
import numpy as np

img = cv2.imread('2.jpg')
rows, cols, ch = img.shape

pts1 = np.float32([[56, 65], [368, 52], [28, 387], [389, 390]])
pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])

M = cv2.getPerspectiveTransform(pts1, pts2)
img_dst = cv2.warpPerspective(img, M, (cols, rows))
cv2.imwrite('2_wrap_perspective.jpg', img_dst)
```

2.jpg:

![mark](http://images.iterate.site/blog/image/20181215/prx92QKnzc6j.jpg?imageslim)

输出：

2_wrap_perspective.jpg:

![mark](http://images.iterate.site/blog/image/20181215/gS6gGpy5adwn.jpg?imageslim)

嗯，但是怎么确定要对哪四个点进行纠正呢？

## 可以用手动标注的方式


例子如下：

```py
import cv2
import numpy as np

select_point_num = 0
img = None
star_points = []
opened_pic_file = None


def onMouse(event, x, y, flag, param):
    global select_point_num
    global img

    if event == 4 and select_point_num < 4:
        print(x, y, select_point_num, )

        # 已选择的点加 1
        select_point_num = select_point_num + 1

        # 将选择好的点添加到相应的数组当中
        point = (x, y)
        cv2.circle(img, point, 2, (0, 255, 0), 2)  # 修改最后一个参数

        # 划线
        if len(star_points) >= 1:
            # 取出最后一个点
            last_point = star_points[len(star_points) - 1]
            # 划线
            cv2.line(img, point, last_point, (155, 155, 155), 2)

        if len(star_points) == 3:
            # 取出开始的一个点
            last_point = star_points[0]
            # 划线
            cv2.line(img, point, last_point, (155, 155, 155), 2)

        # 更新图片
        cv2.imshow("show", img)
        star_points.append(point)
        if len(star_points) == 4:
            rectify_that_part_of_photo()


def rectify_that_part_of_photo():
    global star_points
    global opened_pic_file

    show_width = 400
    show_height = 300
    # 打开一份备份img
    img_copy = cv2.imread(opened_pic_file)
    cv2.namedWindow("result_img", 0);

    origin_selected_conors = []
    rigin_selected_lu = (star_points[0][0], star_points[0][1])
    rigin_selected_ru = (star_points[1][0], star_points[1][1])
    rigin_selected_ld = (star_points[3][0], star_points[3][1])
    rigin_selected_rd = (star_points[2][0], star_points[2][1])

    # 添加到 origin_selected_conors
    origin_selected_conors.append(rigin_selected_lu)
    origin_selected_conors.append(rigin_selected_ru)
    origin_selected_conors.append(rigin_selected_rd)
    origin_selected_conors.append(rigin_selected_ld)

    # 变换过后图像展示在 一个 宽为 show_width 长为 show_height的长方形窗口
    show_window_conors = []
    show_window_lu = (0, 0)
    show_window_ru = (show_width - 1, 0)
    show_window_ld = (0, show_height - 1)
    show_window_rd = (show_width - 1, show_height - 1)

    # 添加到 show_window_conors中
    show_window_conors.append(show_window_lu)
    show_window_conors.append(show_window_ru)
    show_window_conors.append(show_window_rd)
    show_window_conors.append(show_window_ld)

    # 获得transform 函数
    transform = cv2.getPerspectiveTransform(np.array(show_window_conors, dtype=np.float32),
                                            np.array(origin_selected_conors, dtype=np.float32))

    #
    transfered_pos = np.zeros([show_width, show_height, 2])
    for x in range(show_width):
        for y in range(show_height):
            temp_pos = np.dot(transform, np.array([x, y, 1]).T)
            transed_x = temp_pos[0] / temp_pos[2]
            transed_y = temp_pos[1] / temp_pos[2]
            transfered_pos[x][y] = (int(transed_x), int(transed_y))

    # 生成 一个空的彩色图像
    result_img = np.zeros((show_height, show_width, 3), np.uint8)
    print(result_img.shape)

    for x in range(show_width):
        for y in range(show_height):
            result_img[y][x] = img_copy[int(transfered_pos[x][y][1])][int(transfered_pos[x][y][0])]

    cv2.imshow("result_img", result_img);


if __name__ == '__main__':
    # 获取用户的输入
    # opened_pic_file 输入的图片地址和文件名
    opened_pic_file = "3.jpg"
    img = cv2.imread(opened_pic_file)
    img2 = []
    window = 'show'
    cv2.namedWindow(window, cv2.WINDOW_NORMAL)
    cv2.imshow(window, img)
    # 2. 给用户注册鼠标点击事件
    cv2.setMouseCallback(window, onMouse, None);
    # 监听用户的输入，如果用户按了esc建，那么就将window给销毁
    key = cv2.waitKey(0)
    if key == 27:
        cv2.destroyWindow(window)
```

3.jpg:

![mark](http://images.iterate.site/blog/image/20181215/Xu8jAxPkvV3B.jpg?imageslim)

show 窗口：

![mark](http://images.iterate.site/blog/image/20181215/fte8HJkRgBKG.png?imageslim)

连续点四个点之后，弹出 result_img 窗口：

![mark](http://images.iterate.site/blog/image/20181215/2bf7hlkibzyu.png?imageslim)

控制台输出：

```
107 9 0
268 29 1
192 345 2
41 310 3
(300, 400, 3)
```

<span style="color:red;">上面这个例子跑了一下，嗯，没有怎么看，还是不错的。</span>

## 可以先用 canny 对边缘进行检测


可以用 canny 对边缘进行检测，然后，对检测出的矩形进行变换：

例子如下：

```py
import sys
import os
import numpy as np
import cv2


class Line:
    def __init__(self, l):
        self.point = l
        x1, y1, x2, y2 = l
        self.c_x = (x1 + x2) / 2
        self.c_y = (y1 + y2) / 2

def intersection(l1, l2):
    x1, y1, x2, y2 = l1.point
    x3, y3, x4, y4 = l2.point
    a1, b1 = y2 - y1, x1 - x2
    c1 = a1 * x1 + b1 * y1
    a2, b2 = y4 - y3, x3 - x4
    c2 = a2 * x3 + b2 * y3
    det = a1 * b2 - a2 * b1
    assert det, "lines are parallel"
    return (1. * (b2 * c1 - b1 * c2) / det, 1. * (a1 * c2 - a2 * c1) / det)


def threshold(img):
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # TODO 对于这个的理解不深
    gray = cv2.adaptiveThreshold(img_gray, 255,
                                 cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                 cv2.THRESH_BINARY, 7, 5)
    return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)


def scanner_lite(im, debug=False):
    # resize
    h, w, _ = im.shape
    min_w = 200
    scale = min(10., w * 1. / min_w)
    h_proc = int(h * 1. / scale)
    w_proc = int(w * 1. / scale)
    im_dis = cv2.resize(im, (w_proc, h_proc))
    cv2.imwrite('3_1_im_dis.jpg', im_dis)
    # gray
    gray = cv2.cvtColor(im_dis, cv2.COLOR_BGR2GRAY)

    # blur
    # gray = cv2.blur(gray, (3, 3))
    # gray = cv2.GaussianBlur(gray, (3,3), 0)

    # canny edges detection
    high_thres = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[0]
    low_thres = high_thres * 0.5
    canny = cv2.Canny(gray, low_thres, high_thres)
    cv2.imwrite('3_2_canny.jpg', canny)

    # lines detection
    lines = cv2.HoughLinesP(canny, 1, np.pi / 180,
                            int(w_proc / 6),
                            None,
                            int(w_proc / 3), 20)  # 20

    # classify lines
    img_canny_bgr = cv2.cvtColor(canny, cv2.COLOR_GRAY2BGR)
    hori, vert = [], []
    for l in lines:
        x1, y1, x2, y2 = l[0]
        if abs(x1 - x2) > abs(y1 - y2):
            hori.append(Line(l[0]))
        else:
            vert.append(Line(l[0]))
        cv2.line(img_canny_bgr, (x1, y1), (x2, y2), (0, 0, 255), 1)
    cv2.imwrite('3_3_canny_line.jpg', img_canny_bgr)

    # not enough
    if len(hori) < 2:
        if not hori or hori[0].c_y > h_proc / 2:
            hori.append(Line((0, 0, w_proc - 1, 0)))
        if not hori or hori[0].c_y <= h_proc / 2:
            hori.append(Line((0, h_proc - 1, w_proc - 1, h_proc - 1)))

    if len(vert) < 2:
        if not vert or vert[0].c_x > w_proc / 2:
            vert.append(Line((0, 0, 0, h_proc - 1)))
        if not vert or vert[0].c_x <= w_proc / 2:
            vert.append(Line((w_proc - 1, 0, w_proc - 1, h_proc - 1)))

    hori.sort(key=lambda l: l.c_y)
    vert.sort(key=lambda l: l.c_x)

    # corners
    for l in [hori[0], vert[0], hori[-1], vert[-1]]:
        x1, y1, x2, y2 = l.point
        cv2.line(img_canny_bgr, (x1, y1), (x2, y2), (0, 255, 255), 1)

    img_pts = [intersection(hori[0], vert[0]), intersection(hori[0], vert[-1]),
               intersection(hori[-1], vert[0]), intersection(hori[-1], vert[-1])]

    for i, p in enumerate(img_pts):
        x, y = p
        img_pts[i] = (x * scale, y * scale)
        cv2.circle(img_canny_bgr, (int(x), int(y)), 1, (255, 255, 0), 3)
    cv2.imwrite('3_4_canny_line.jpg', img_canny_bgr)

    # perspective transform
    w_a4, h_a4 = 130, 200
    # w_a4, h_a4 = 600, 800
    dst_pts = np.array(
        ((0, 0), (w_a4 - 1, 0), (0, h_a4 - 1), (w_a4 - 1, h_a4 - 1)),
        np.float32)
    img_pts = np.array(img_pts, np.float32)
    transmtx = cv2.getPerspectiveTransform(img_pts, dst_pts)
    return cv2.warpPerspective(im, transmtx, (w_a4, h_a4))


if __name__ == '__main__':
    img = cv2.imread('3.jpg')
    img_dst = scanner_lite(img, debug=False)
    img_dst_threshold = threshold(img_dst)
    cv2.imwrite('3_scanner_lite.jpg', img_dst)
    cv2.imwrite('3_threshold.jpg', img_dst_threshold)
```

3.jpg:

![mark](http://images.iterate.site/blog/image/20181215/x0DiW7ji5a6I.jpg?imageslim)

输出：

3_1_im_dis.jpg:

![mark](http://images.iterate.site/blog/image/20181215/DlKXDNPyBhVe.jpg?imageslim)

3_2_canny.jpg:

![mark](http://images.iterate.site/blog/image/20181215/Vqq4q5dDUYsx.jpg?imageslim)

3_3_canny_line.jpg:

![mark](http://images.iterate.site/blog/image/20181215/OS9gvm6b3Urm.jpg?imageslim)

3_4_canny_line.jpg:

![mark](http://images.iterate.site/blog/image/20181215/PzC6Sqe7rwSi.jpg?imageslim)

3_scanner_lite.jpg:

![mark](http://images.iterate.site/blog/image/20181215/GoQu6F3XdHm7.jpg?imageslim)

3_threshold.jpg:

![mark](http://images.iterate.site/blog/image/20181215/tlc5datoJAyN.jpg?imageslim)



# 相关资料

- [Python&CV- PPT拍歪了？OpenCV来帮你‘矫正’！](https://www.jianshu.com/p/bd6b9b22e711)
- [CamScanWorker](https://gitee.com/zhao0/CamScanWorker/blob/master/scannerLite.py)
