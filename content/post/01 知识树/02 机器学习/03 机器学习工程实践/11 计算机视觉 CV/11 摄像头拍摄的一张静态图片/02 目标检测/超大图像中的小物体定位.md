---
title: 超大图像中的小物体定位
toc: true
date: 2018-11-04
---
# 需要补充的

- 感觉还是需要系统的整理下的。嗯，想全面的进行认识。

# 超大图像中的小物体定位

比如一个 5000*5000 的图像，怎么识别定位一个 40*40 的，或者更小的物体？

首先，看这个图像与物体相对来说，是不是物体特别小，如果不是特别小，其实可以直接用 YOLO 等来定位识别的。


如果真的是特别小，那么就要用下面这些方法了：

## 比较主流的做法


嗯，感觉比较主流的做法是这样的：


- 定位热门区域
- 分块
- 分别定位识别

### 定位热门区域

可能你要定位的物体在一个比较大的物体里面，那么你可以先定位这个大的东西，然后在这个大的东西里面定位小的东西。

或者，你能从大图上找到一些这个小图可能存在的地方，这样也可以缩小后面定位的范围。

一般使用的方法是：

- 场景定位
- 用 robust 的数学方法粗略定位  <span style="color:red;">什么是 robust 的数学方法？这个地方的粗略定位是怎么做的？</span>



### 分块

做了上面这一步，如果还是太大，那么做分块。也可以直接做分块。

crop with overlapping

图像分块，分成很多tile

对图块进行训练，做分割

测试，拼接图块结果

### 分别定位识别

rcnn 一系列的检测加边框回归在有数据的情况下已经很准了。


没数据的情况下利用边缘纹理找一些 handcraft feature 也能做。 <span style="color:red;">一直想知道，图像处理中根据边缘纹理来做 handcraft feature 到底要怎么做？</span>


嗯，好像大概有下面几种方法：


-  有人说，可以用这个 [Deformable-ConvNets](https://github.com/msracver/Deformable-ConvNets) ，这里面的 FPN 可以解决 5000×5000 大图上大概 20 * 20 小目标的检测(12G显存)。当然是指推断，训练还是要用小图。 其实你把基础网改为 mobilenet 或者更小的网，8000 * 8000 我都试过，一次性检测亲测可用。PS: MXNet 省内存杠杠的～  <span style="color:red;">嗯，要看下 FPN是怎么解决这个问题的，而且，推断是什么意思？是前向计算吗？MXNet 真的省内存吗？ mobilenet 或者更小的网络是什么样的？做出来的识别和定位的精度到底怎样？能应用在实际中吗？而且，5000*5000 的图前向定位一次大概需要多长时间？</span>


- 如果你不resize，很可能显存放不下。如果你resize，大物体缩小之后还是有很大，检测起来问题不大。如果是小物体，缩小之后可能真的很小，可能检测得不好。这个时候可以试试在 roipooling 之前做点操作，增大 pooling 之前的尺寸，各种不同的操作对应不同的 paper。<span style="color:red;">不 resize 要怎么做？现在的模型还有不 resize 的吗？想知道。而且，增大 pooling 之前的尺寸这个是怎么做的？把小的 resize 大？这个显存还能放下吗？</span>


- 以高分辨遥感图像中的舰船、飞机等典型地物的识别为例，目标物尺寸相对于整幅图像来说太小，除了小目标检测算法，常见的检测、识别算法妥妥的失效。比较可行的做法是，结合显著性检测或者典型场景的识别，缩小物体识别定位的范围，然后再做进一步的检测识别。<span style="color:red;">什么是显著性检测？什么是典型场景的识别？是先从图像中识别定位出物体可能存在的场地，然后再在场地中进行识别定位吗？那么显著性检测又是什么？</span>



- 按照我们的经验，图像分块并且是有重叠的分块是比较简单有效的方法。可以滑窗分块，分成 常用的 300~500 的，然后一块一块的输入到SSD进行检测，然后拼接。比如裁成了50块，输入的时候可以把 n 个块合成一个batch，然后直接把这个 batch 输入网络。当然了，图片大了估计你得等好久。。。。<span style="color:red;">嗯，这个是我之前想用的方法。这些小 batch 一定要是互相重叠的，但是这个效率估计不是很高吧，对于效率要求高的场景要怎么优化。分块后可以看看可不可以多线程并行处理，或者多机并行处理。</span>




- 前段时间做的一个课题背景相似，大场景图像中的小目标检测。具体是检测航拍高速公路图像中的裂缝目标并分类定位计算裂缝长度，图像是 6K*8K 的尺寸，裂缝目标在图像中的宽度是1个像素左右。初期直接采用单卡进行 Region Proposal 的模型方法 Faster R-CNN和R-FCN 等训练，网络采用小网络 ZF-Net 时，Batch Size 只能设为 4 才保证显存够用，而且训练时间很长。后来分析图像区域特征，做了个高速公路的高召回率道路分割网络，将原图 resize 分割为重叠的小图像块分批喂进网络，先行提取道路区域的 Feature Map，利用其感受野坐标在航拍原图中对道路区域分割，并对分割后的路面图像进行显著性分析增强小目标特征，用分割后的道路增强原图作为数据进行 Faster R-CNN 的裂缝分类定位，最后用其裂缝原图坐标采用链码跟踪方法计算具体的裂缝长度。<span style="color:red;">哇塞，这个比我的困难多了，嗯，可以尝试下，感觉这个还是有些厉害的，这里面的一些名词之前没听过，想要系统的掌握下。比如怎么利用感受野坐标对道路区域进行分割的？怎么进行显著性分析增强小目标的？怎么用分割后的道路增强原图作为数据的？怎么用链码跟踪方法计算裂缝长度的？嗯，还是有很多需要掌握的。</span>



- 可以先参考 Google 的乳腺瘤识别。对于大图片可以根据需求裁剪成多个互相重叠的 tile 用 maskrcnn 识别每个 tile，再拼接出最终结果。<span style="color:red;">嗯，没想到还有这种例子。是要认真掌握下。</span>



- 之前我们做过遥感图像处理的时候要面对的就是 10000*10000 以上的大数据量图像。当前，目标检测的主流思路是 course-to-fine 方法，即由粗到精的一个过程。主流思路中，首先确定出目标的大致区域，然后再通过 refine 的过程，再在候选区中定位目标。在 course 阶段，根据你所需要检测目标的不同，可以采用响应的场景识别方法，显著性检测，机场检测，港口检测等等。。fine阶段就可以使用当然非常成熟的 faste r-cnn，ssd 等深度方法，训练模型，得到最后结果。具体方法和模型根据数据和目标的不同灵活选择。当然这也是一种主流思路，也可以看看end-to-end相关的文章，尝试直接输出结果。<span style="color:red;">嗯，这个的确是一个很好的总结，也是一般的方法。场景识别和显著性检测也是上面提到过的，尝试使用下。嗯，不过这一套下来，估计还是会用很多时间的吧，尤其是使用 CPU 的时候，而且，end-to-end 现在不知道有什么好的方法出来，以前总是觉得 end-to-end 很厉害，但是现在觉得，当精度有严格的要求的时候，而且数据比较少的时候，还是怎么高精度怎么来吧。</span>




- 不知道你说的是效果更好还是效率更高。传统方法的话可以多尺度分析，mallat的那个，寻找合适的小波变换因子，可能效果会不错；深度学习的话大多数都有多尺度提取特征的功能，需要解决的可能是单个训练数据太大的问题，粗暴一点的就是多个显卡啊，把显存总量提上去，不行的话就只能用 minibatch 了。窃以为 5000x5000 不大，你要解决的是不是一个低信噪比的问题？就是目标的面积很小？这样的话使用合适的特征是最最重要的，单纯的数据量大或者说如果是那种像素位深很大的，可以考虑降维，pca 或者 kpca 什么的，要结合具体问题来讲。。。如果单纯是觉得速度慢，可以想办法做并行嘛，无论是 pc 级别的或者用 dsp 都可以。。。<span style="color:red;">这个人说的，感觉也很有用，很多不知道的，什么是多尺度分析？什么是 mallat ？什么是小波变换因子，有什么作用？为什么要做降维？ dsp 是什么？</span>



# 相关资料

- [如果想要对超大分辨率的图像里的小物体进行识别定位有什么好方法吗(例如图像是5000*5000的)?](https://www.zhihu.com/question/266522566)
