---
title: 02 深度学习对计算机视觉的影响
toc: true
date: 2018-08-29
---


# 深度学习对计算机视觉的影响

## 2012年，计算机视觉的新起点


在深度学习出现之前，计算机视觉就像是设计精妙的火箭，缺少一个强大的助推器。<span style="color:red;">嗯，好像是这样。</span>

ILSVRC举办的前两年，各种手工设计特征+编码+SVM框架下的算法就霸占了前几名。ILSVRC的分类错误率的标准是让算法选出最有可能的5个预测，如果有一个是正确的则算通过，如果都没有预测对则算错误。2010 年 ILSVRC 的冠军是 NEC 的余凯带领的研究组，错误率达到了 28% 。2011年施乐欧洲研究中心的小组将这个成绩提高到了 25.7%。

终于，到了 2012 年，这年辛顿的小组也参加了竞赛，主力选手是辛顿的一名研究生阿历克斯•克里泽夫斯基(Alex Krizhevsky)。阿历克斯是一名学术和工程都非常厉害的学生，在这一年的竞赛上，他提出了一个5卷积层+2全连接层的卷积神经网络 AlexNet，并利用 CUDA 给出了实现，这个算法一下将前5类错误率从 25.7% 降到了 15.3%，在之前的 ImageNet竞赛中，哪怕有一个百分点的提升，都是很不错的成绩，而深度学习第一次正式 应用在图像分类竞赛就取得了 10 个百分点的改进，并且完胜第二名(26.2%)。这在当时对传统计算机视觉分类算法的冲击是不言而喻的。简单来说当时的改进主要有以下3点。<span style="color:red;">厉害了，竟然能用 CUDA 给出实现。</span>

- 更深的网络结构。
- 校正线性单元(Rectified Linear Unit, ReLU)，Dropout等方法的应用。<span style="color:red;">2012 年就有 Dropout了？看来我落后了非常多</span>
- GPU训练网络。<span style="color:red;">之前不是使用 GPU 进行训练的吗？</span>


尽管在当年许多传统计算机视觉的学者仍然对AlexNet抱有种种质疑，如算法难以解释，参数过多（实际上比许多基于SVM的办法还少）等，但自从 2012 年后，ImageNet 的参赛者几乎全体转向了基于卷积神经网络的深度学习算法，或者可以说计算机视觉领域 全体转向了深度学习。基于深度学习的检测和识别、基于深度学习的图像分割、基于深度 学习的立体视觉等如雨后春笋般一夜之间全冒了出来。深度学习，尤其是卷积神经网络就 像一把万能的大杀器，在计算机视觉的各个领域开始发挥了作用。



## 从ImageNet竞赛到AlphaGo战胜李世石——计算机视觉超越人类

前面已经介绍过ImageNet图像分类竞赛和AlexNet的一骑绝尘。本节来看看接下来几 年发生了什么。

2013年，马修•塞勒(Matthew Zeiler)以初创公司Clarifi创始人，以及纽约大学计算机系的博士生的两个身份参加了 ImageNet 比赛，并分别取得了第一名和第三名，这一年他把ImageNet的前5分类错误率降低到了 11.7%。从这一年开始几乎所有的参赛者都开始使用卷积神经网络，少数没有使用深度神经网络的参赛者都处于垫底位置。

2014年，Google 开始在 ImageNet 发力。当时在 Google 担任软件工程师的克里斯蒂 安•赛格蒂(Christian Szegedy)提出了一种 Inception 的结构，并基于这种结构搭建了一个22层的卷积神经网络 GoogLeNet ，达到了 6.66% 错误率的成绩。和2013年相比，这一年基于卷积神经网络的成绩普遍提升，前5名都达到了小于10%的成绩。另外值得一提的 是，GoogLeNet从网络、形态上讲，已经脱离了 AlexNet和LeNet的卷积叠加+全连接的框架。这一年，所有的参赛者都使用了深度神经网络。<span style="color:red;">原来GoogleNet 就是 Inception？</span>


2015年，在建立更深网络的大趋势下，微软亚洲研究院(Microsoft Research Asia, MSRA)的何恺明提出了深度残差网络(Deep Residual Networks)，把网络层数做到了 152 层，并在ImageNet的分类比赛中取得了 3.57% 的错误率。在当年，这个成绩的意义除了第一名，更重要的是超过了接收过训练的人在 ImageNet 数据集上对图片进行分类的成绩(5.1%)。虽然这个结果并不能说明深度学习算法已经真的超过了人类，但是在深度学习介入ImageNet的分类竞赛前，算法只能做到28%的错误率，而在引入深度学习后，三年内就填补了最先进算法到人类分类水平的 23% 左右的空白，深度学习已经充分展现了威力。<span style="color:red;">深度残差网络也是 2015年的事情了，不知道现在的情况是什么样了？</span>

2016年，前5名分类的错误率被进一步降低到了 2.99%。冠军是我国公安部三所的搜神(Trimps-Soushen)代表队。2016年的 ImageNet 竞赛基本上是中国公司代表队的全面开 花。在各个不同类别比赛的最终排行榜上都能看到中国公司和机构的名字，出现最多的是海康威视、公安部三所搜神和汤晓鸥老师的商汤科技。这是个可喜可贺的情况，说明中国在深度学习的应用上已经走在了世界的前列。不过从另一方面来讲，2016年很多国外传统强队根本没有参赛，并且也没有什么特别亮眼的新方法被提出，这届竞赛有些更像是模型 组合及调参大赛，也不是一件特别鼓舞人心的事情。<span style="color:red;">嗯。为什么国外的传统强队没有参赛？</span>

每一门学科技术的发展都是螺旋式上升，深度学习被大炒几年后是否也会像股票和三线城市的房价一样回调停滞？总之，作为一门威力强大但是却没有被透彻研究的技术，深度学习还有很多可以探索的领域，其发展也许还任重道远。如图1-7是从2011年到2016 年ImageNet竞赛中物体分类最好成绩的趋势。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180831/GHbgdHkiah.png?imageslim)


深度学习在图片分类上的成功是被关注讨论最多的，事实上在其他领域深度学习算法在指标上也在渐渐赶超人类。如人脸识别领域的一个公认数据集LFW(Labeled Faces in the Wild)上，人类识别的准确率是97.53%,而如今基于深度学习的人脸识别已经可以达到 99.5%的水平。

2016年初万众瞩目的围棋人机大战中，AlphaGo突破了人类智慧的最后堡垒。虽然 AlphaGo不算是计算机视觉的应用，但是深度卷积神经网络却在其中扮演了重要角色。棋盘的特征是以19X19的图像形式表示的，通道数是人为规定的颜色、轮次等其他特征，然后放到基于深度卷积神经网络的估值和策略网络中进行训练。<span style="color:red;">是这样吗？想深入了解下 AlphaGo 和他们后来出的 AlphaZero </span>

事实上在许多特定任务上，基于深度学习的算法超越人类水平都不是什么新鲜事，未来还会看到更多的例子。



## 相关资料

- 《深度学习与计算机视觉》
