---
title: 02 例子
toc: true
date: 2018-08-18 16:39:08
---


## 例子：Soft Attention for Captioning

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/icHHK9A2FI.png?imageslim)

我们已经有了 CNN、RNN 工具

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/d4ALLAai8g.png?imageslim)

CNN 把一个图像变成了一个 tensor 的表示，会比变成一个 4096 的向量，他的 multi instance 的信息就包含进去了，就是说里面的每一个小柱子代表了图像中一个区域，这个是它的核心，这个事情是需要从机器学习的角度来看的，我们这个 attention 其实就是利用了这个表示，他把tansor 拿出来了，这个每一个框框![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/40hJf0Ij9f.png?imageslim)代表的是每一个小柱子，而这个框框是能够回溯到原图像中的具体的区域的，然后，我再针对于这些 instance 利用 RNN 我每次做一个 softmax，softmax 回归的时候，我需要 attention 的 instance 的 id。所以，一个是这些 instance 的一个线性叠加，一个是我的 caption 的 word，我就能每次预测出一个需要 attention  attend 到的一个 instance 的位置。<span style="color:red;">还是没理解，要弄明白，并且要弄清楚我对于这些知识的掌握还有哪些不足？</span>

所以，如果你回到这篇论文之前，有人让你帮他做一个attention，那么如果你对 CNN 的真正的背后比较了解，又懂一些 RNN，那么你需要能够自己做出来。<span style="color:red;">现在还不能够，看来没看一篇论文都要达到这样的程度才行，只看他提出的问题，然后自己想出解决方案，并真正实现。然后与这个论文进行对比。</span>


另一个例子：

## Learn a shared space for both images and texts

就是我们想做一个隐空间，shared space，以前我们对label 的编码是 one-hot encoder 比如 00010 ，其实我们的每一个 label 是一个英文词。我们的 NLP 里面是有一个东西叫做 word2vec ，这种表示比 one-hot 的表示要好非常多，所以，如果我们要做一个分类问题，把这个label 背后的语义信息忽视了的话，直接强行回归到不包含任何语义信息的这么一个 one-hot label 里面去，肯定是不够圆满的。

有没有可能我们把这些label 当做一些词，然后用一种 embadding 的方式嵌入成一个向量，然后，我们做的是一个回归任务？


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/5ach50chAi.png?imageslim)


就是，图像的一种 embadding 和 label 的一种 embadding，label 在共享的空间中的嵌入是这么样的，然后，图像在空间中的嵌入是这样的。然后我们通过监督学习的方式，尽可能让标注有 cat 的label 的图像都跟 cat 这个label 比较近。

这个事情也有人做

比如说，我们的图像输入 VGG，然后，输出，然后输出成 word2vec，那么这一层就是我们的 shared space。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/chl77bmGfg.png?imageslim)


<span style="color:red;">第一次听到这种 shared space ，真的是非常好，感觉图像和文字就有了某种关系。再理解下。</span>

在这个shared space 中就可以做一些事情了，这个关注一下。



## Kaggle Whale Challenge

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/dKBD4hDdmk.png?imageslim)


4237 张鲸鱼的照片，有 427 个类别，对鲸鱼进行分类。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/Ilci4AiJKb.png?imageslim)


有的类别只有一张图片。


我们最基本的方法就是：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/fbg48J6i5A.png?imageslim)

做机器学习还是这样迭代开发比较好，先从最简单的开始。

当你把它卷积后的一些图像输出看的时候，你会发现，海浪上的一些波纹也成为了一些特征，这个是不想发生的。

OK，那么怎么解决呢？

一种方式是我们可以把图像中鲸鱼头部的地方切出来，然后放到 VGG 里面

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/labIEE4C4a.png?imageslim)

那么怎么找到这个鲸鱼头部的框呢？

我们可以标注一些 bounding box ，然后做回归，因此我们可以做 RCNN 或者 Faster-RCNN。

OK，现在还需要做什么吗？

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/87gCAHdH3k.png?imageslim)


我们发现鲸鱼的头部的指向是随机的，而神经网络会把这个角度作为一个特征。

所以，我们需要找到他的头和脖子，然后做一个旋转，把头的方向扭成这个方向。

那么我们怎么找关键点呢？

我们只要标注足够多的数据，然后回归这两个坐标就行。回归完之后，我们计算一下这个坐标与平面的夹角，然后旋转一下。



## 车型识别

做工程化的CV 项目的时候，一定要遵循我们的思路，我们想要什么，我们现在有什么工具。然后分步骤解决。

我们就把神经网络看做一个分类和回归的工具，而且我能够生成一些东西，等。

因此，我们要把 problem fit 成 ML 的一个问题，然后用 ML 的 tools 来解决他。
就是把想做的东西变成机器学习的一个问题，然后用机器学习的工具来解决他。<span style="color:red;">真的是厉害。</span>

至于机器学习中的工具要怎么选呢？这个要结合具体的场景和工具的特点，这个是专业知识范围，但是我们之前的思考的思路是不需要什么专业知识的。不用慌。迭代的问自己：你想干什么，你能干什么。

对搞科研的，老师强调一点：提出问题比解决问题要重要的多。真正区分出牛人和不牛人的就是，你是否能提出具有重要意义的问题。一般只要问题提出来了，没有解决不了的。<span style="color:red;">厉害。为什么我感觉这个冯老师这么厉害。讲课也非常清晰。</span>






后面是提问环节：

### VGG ，部署之后，运行不会很慢的，实时要看需求是多实时。
- 首先，可以对网络进行压缩，能够大幅的加快你的训练时间和运算时间。<span style="color:red;">怎么压缩的？model compression 要总结下。</span>
- 然后，买个好一点的显卡就行，一般来说问题不大。

然后，这个同学还是说实测不行，说已经使用了 titanx。

老师说：这个 titanX 很好，但是，你是否装了一些比较好的加速库，这个是决定你神经网络运行时间的关键性因素，就是比如 cudnn 和 底层的什么MKL库，这些比较好的数学运算库，这个的提升效果是比你从 1080 升到 titanX 所能得到的性能的增益要来的更多的。 cudnn 有和没有的影响是数量级的。

有人问，除了这两个还有什么吗？老师说：你可以到 intel 的官网上，有一个  parellel stuidio 所带的所有 intel 的商用库和编译器，最好都装上

还有一个方式就是，一般你做一个 前向运算是 30ms 左右，如果还想加速，就只能进行模型的压缩。如果你已经是 titanX 了，那么也没什么更好的方法了。

同学说他装得是 opencmblas ，老师说肯定没有 intel 给的 blas 好。一定不要小看 intel 的那些库，也是要装的。


而且，你要做高性能计算的话，首先要找到程序的瓶颈，然后定一个目标，然后精准率要容忍要掉多少。<span style="color:red;">看来高性能计算也是要掌握的，尤其是图像处理领域的计算量还是很大的，有些配置的不同性能都会有很大的不同，因此还是要系统的学习的。</span>

如果是要快5倍，那么老师说：可以对 VGG 进行压缩，就用model compression的一些方法，和有牺牲性的一些方法，把它做小一点。<span style="color:red;">到底有哪些 model compression 的方法？牺牲性的方法是不是只有之前提过的把知识迁移到 简单的网络里面？还有别的方法吗？</span>对于压缩，老师说：一种是参数的压缩，这个是传统的压缩，还有一个就是用迁移学习把模型换成一个小的。


所以，基本就是两点：

- 库更新一下
- 模型压缩一下


后来老师又补充了一个，就是 二值化，这个小网络里面有提到，<span style="color:red;">查了下，小网络看来是[小网络之shufflenet](https://littletomatodonkey.github.io/2018/06/25/shufflenet/) [轻量级网络](https://littletomatodonkey.github.io/tags/#%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C) 这种网络 应该是这些小网络里面有用这种方法的。[CVPR 2018 高效小网络探密（上）](https://zhuanlan.zhihu.com/p/37074222)  [模型加速-小网络论文跟踪](https://blog.csdn.net/Iriving_shu/article/details/80613345)</span>




然后，这个同学说了他的场景是 faster rcnn 和 resnet100 做 detection，然后老师说：瓶颈也许是 rcnn，然后具体的运行时间要分别看，术语叫做 profiling。 <span style="color:red;">到底什么是 profiling</span>






## 相关资料

- 七月在线 opencv计算机视觉
