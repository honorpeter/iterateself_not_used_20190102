---
title: 01 介绍
toc: true
date: 2018-08-18 16:32:46
---


# 图像描述


图像描述，类似看图说话，给一幅图，然后用一句话描述这个图像。

这个是 CV 和 NLP 的最新结合。<span style="color:red;">不知道现在有什么结合？</span>

<span style="color:red;">类似的问题还是要整理确认下的：怎么用一段话描述这个图像？</span>



- 图像描述概述(introduction to image captioning)
    - 简介
    - 数据库
    - 群内⼤组、知名⼈物
- 背景知识： RNN, LSTM
- ⼏种最新⽅法概述
    - NeuralTalk
    - DenseCap
    - Show, Attend and Tell
- 值得思考的问题
- 作业


其实这次讲的image captioning 很大的背景知识在于 RNN 和 LSTM。

然后基于这个我们讲一些最新的方法  NeuralTalk 是 15年提出来的，DenseCap 是 16年提出的，Show,Attend and Tell 是开山鼻祖的文章，因此我们讲的顺序是 3,1,2。

然后是值得思考的一些问题。



图像描述就是看图说话：image captioning

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/25bEK1LEcc.png?imageslim)

一看就知道要用到之前所有的 cv 的知识，比如 object detection。这个地方老师说了下：对于小的风筝叫做物体检测，但是对于蓝天，沙滩这种大的东西又叫做场景检测。

就是比如人脸检测是一块，行人检测又是一块。因此 cv 的各种 task 在学术界分的非常细。可能工业界就是一套检测就完了，可能人脸检测就拿一套 general object detecition 就直接检测了。<span style="color:red;">好吧，学的时候，还是要每个 task 都要学到的</span>

所以：

- 这幅图会用到很多 object detection ，
- 然后他们的label 与label 之间的 connection 也是一个问题，
- 然后这个句子的风筝 kite 在最后，之所以在句子最后，这个是靠的 RNN。

之后我们会详细的介绍。


下面我们看看几个点：

### 一个好的 pre-trained model 是非常重要的

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/A5HiddI3ad.png?imageslim)


这幅图，我们看上面的，就能发现 fine-tuned model 是多么的重要，即使用 RNN，在 pre-train 的时候也要用到 convoluation model 。

上面这个 黑色的 A brown bear is swimming in the water ，这个是用的比较low 的 net ， google net，然后下面这个图就是用的16年他们公布的 model 就是用的 V4 的模型，结果就变成了 Two brown bears sitting on top of rocks.

可见，有一个很好的 model 是非常重要的。

### 当给模型提供一张训练集类似的图片的时候，他经常直接使用人类的描述

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/BeB1mi2gjB.png?imageslim)

### 模型根据训练集类似的场景产生了一个新的描述

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/icB2eFf5HB.png?imageslim)

传统的识别任务，classification 的时候，有狗就是1，没狗就是0 ，但是，现在这个 captioning 是一个非常主观的东西，怎么量化出来呢？

从本质上说，其实我们就是说的 就是RNN 和 LSTM 的应用

一个就是图像描述，一张图输入是输入是 1 1 输出是很多，
那么很多输入很多输出是什么？就是 language translation。

所以，今天课的本质就是 RNN、LSTM。

其实还有很多应用，比如，问问题：这个图中有几只狗？回答：两只。这个也是一个应用。

上面的几幅图的地址：
https://research.googleblog.com/2016/09/show-and-tell-image-captioning-open.html
PAMI paper: https://arxiv.org/pdf/1609.06647v1.pdf PAMI 是整个 CV 界第一的期刊


基本上你要用 RNN 或者 LSTM，你基本用 Torch，老师主要用的就是 Caffe 和 Torch，60%用 Caffe，然后，小的 Project 用 Torch，因为 Torch 他实现这些 graph 尤其是RNN 绕来绕去的比较简单。Caffe 的就比较啰嗦。




大家来看下这个 demo

- https://vimeo.com/146492001

这个 demo 的其中一个画面如下：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/jH60l1f0Gm.png?imageslim)


这个 demo 就是用一个 mac 电脑，因为 Mac pro 是有显卡的，然后，拿着和这个 mac 在这个城市里一边走一遍用  neural talk model 来生成一些话，有的是不太准的，不过挺有意思的。

不过这个不准的原因主要是因为这个不是科研的数据，就是 实时的test。

一些看图说话是不准的，这就回到刚才的一个问题：怎么评价这个 image captioning 的结果呢？


下面这个是在静态图片上的一些效果：

http://cs.stanford.edu/people/karpathy/neuraltalk2/demo.html



## 数据库和比赛：

### COCO Captioning Challenge

数据下载地址：http://mscoco.org/dataset/#download

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/b1cihi2H00.png?imageslim)

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/ih6hHgGBj6.png?imageslim)

这个比赛分为 detection 和 captioning 和 一个人预测出他的姿势，比如双手撞开还是双手合拢。


我们说一下上面的一些评价指标：Evaluation metric:

- A human study to understand how staisfactory are the results obtained from the captions submitted in the COCO captioning challenge.

其实它在评价的时候一定会考虑下面这三条：

- 哪些算法产生了最好的描述？
- 有哪些因素影响了这些算法？
- 这些算法产生的句子跟人产生的句子是不是很像？

为了解决上面的问题，他们在开发了一个软件来收集的评价，从评价中，他们制定了下面5个指标：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/JCfK75JmGK.png?imageslim)

M1：描述比人这个水平更好或相等，的数量的百分比
M2：可以通过图灵测试的百分比是多少
M3：平均的描述的正确程度。1~5， 1 是最不正确。
M4：平均的这个描述的细节的数量。1~5， 1是缺少细节，5是非常详细。
M5：与人的描述相近的描述的数量百分比。

我们经常用的是 M5。


### Visual Genome

https://visualgenome.org/

这个比 COCO 还要著名。

这个是 斯坦福的 lifeifei 和 斯坦福的 NLP 组共同开发的一个数据库，他的特色是非常大，非常全。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/Leck7aB5Gf.png?imageslim)

有十万张图。


## 相关的文章和知名的研究组

相关的文章：

- Google ICML paper: show, attend and tell
- 斯坦福 Fei-fei Li’s 组：
    - DenseCap
    - NeuralTalk2
- 更多的是在一些比赛里面：
    ms coco website, arxiv, conference websites, etc.

比较经典的文章下面列出来了：

- Explain Images with Multimodal Recurrent Neural Networks, Mao et al.
- Deep Visual-Semantic Alignments for Generating Image Descriptions, Karpathy and Fei-Fei 这个就是 NeuralTalk
- Show and Tell: A Neural Image Caption Generator, Vinyals et al.
- Long-term Recurrent Convolutional Networks for Visual Recognition and Description, Donahue et al.
- Learning a Recurrent Visual Representation for Image Caption Generation, Chen and Zitnick






## REF

- 七月在线 opencv计算机视觉
