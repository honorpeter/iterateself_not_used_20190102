---
title: 04 案例1：
toc: true
date: 2018-07-22 11:52:44
---

# 使用Logistic Regression做CTR预估

在这里，我们将要走一遍这整个过程，讨论为什么 LR 对于 CTR 这种任务来说是一个号的选择。

使用的数据：https://www.kaggle.com/c/avazu-ctr-prediction  click-through rate prediction sponsored by Avazu

这个比赛的目标就是预测广告被点击的概率。

## Step 1: 读取和探索数据 这个是必须的

我们从下载的数据集里面抽取了一部分来演示。

从 https://www.kaggle.com/c/avazu-ctr-prediction/data 下载之后，把 `train.gz` 解压出来，使用这句指令 `head -n100000 train.csv > train_subset.csv` 来提取前 100,000 行。<span style="color:red;">这句指令是什么意思？在linux 上使用的吗？</span>


Our first step is to read the data into an SFrame, which is GraphLab's tabular data structure that is similar to a data frame in R or a pandas DataFrame in Python.

This data happens to be stored in the popular CSV (comma separated value) format, but SFrames can be constructed from a variety of [sources](https://turi.com/products/create/docs/graphlab.data_structures.html#connectors). We'll use the [read_csv](https://turi.com/products/create/docs/generated/graphlab.SFrame.read_csv.html) method to read in the data:


```python
#import pandas as pd
#data = pandas.read_csv('train_subset.csv', verbose=False)
import graphlab as gl
data = gl.SFrame.read_csv('train_subset.csv', verbose=False)
```

Let's take a quick look at the first row of data, to see what we're working with:


```python
data.head(1)
```


| id                  | click | hour     | C1   | banner_pos | site_id  | site_domain | site_category | app_id   |
| ------------------- | ----- | -------- | ---- | ---------- | -------- | ----------- | ------------- | -------- |
| 1000009418151094273 | 0     | 14102100 | 1005 | 0          | 1fbe01fe | f3845767    | 28905ebd      | ecad2386 |

| app_domain | app_category | device_id | device_ip | device_model | device_type | device_conn_type | C14   | C15  | C16  |
| ---------- | ------------ | --------- | --------- | ------------ | ----------- | ---------------- | ----- | ---- | ---- |
| 7801e8d9   | 07d7df22     | a99f214a  | ddd2926e  | 44956a24     | 1           | 2                | 15706 | 320  | 50   |

| C17  | C18  | C19  | C20  | C21  |
| ---- | ---- | ---- | ---- | ---- |
| 1722 | 0    | 35   | -1   | 79   |

[1 rows x 24 columns]



From Kaggle's [data dictionary](https://www.kaggle.com/c/avazu-ctr-prediction/data), I know that click=0 means the ad was not clicked, and click=1 means the ad was clicked. The "click" column is therefore our target variable, and the other columns are our potential features!

The first thing we want to know is what percentage of ads in the dataset were actually clicked. In this case, we can simply take the mean of the "click" column, since that is equivalent to adding up all of the ones (which is the number of clicks) and dividing by the total number of ads:


```python
data['click'].mean()
```

输出：

```
0.1749017490174896
```



We see that 17.5% of the ads were clicked, meaning the overall click-through rate is 17.5%. This is useful to keep in mind as a "baseline", as we'll see later on.

Before we start building a machine learning model, it's always useful to explore the dataset. One way to get started is by using the GraphLab Canvas, a browser-based visualization platform:


```python
gl.canvas.set_target('ipynb')
data.show()
```



I noticed that "device_type" only has 4 unique values, and it makes intuitive sense that the type of device you're using when viewing an ad might affect your likelihood of clicking the ad, so let's explore it further.

To understand the relationship between this feature and the target variable, we want to calculate the click-through rate for each value of device_type. We can accomplish this by "grouping the data" by device_type, and then calculating the mean of the click column for each group:


```python
data.groupby('device_type', {'CTR':gl.aggregate.MEAN('click')})
```

我们用 LR 这样的模型，线性模型，哪些特征比较重要，我们想看一下哪些特征比较重要，那么我们可以怎么做呢？其实我们可以看一下每个手机类型下面它的点击率的高低。 比如使用iphone 的人可能不会去点击比较便宜的车的广告。

这里他们使用的是 groupmap ，实际上是可以使用 pandas 来完成的。

上面这句就是先按照 `device_type` 来分组，然后统计不同的组里面的点击率。

| device_type | CTR             |
| ----------- | --------------- |
| 0           | 0.227499406317  |
| 5           | 0.0990566037736 |
| 4           | 0.0725075528701 |
| 1           | 0.175977623465  |

[4 rows x 2 columns]

看一下这个数据，我们可以看到不同的手机类型对于这个 CTR 的影响还是很大的，那说明手机型号这个特征是一个比较好的特征。


We saw earlier that the baseline click-through rate is 17.5%, and it appears that there is a big difference in average click-through rate depending on device_type. This looks like a good feature!

同样：我们可以看一下 C1 是不是一个好的特征：

```python
data.groupby('C1', {'CTR':gl.aggregate.MEAN('click')})
```


| C1   | CTR             |
| ---- | --------------- |
| 1008 | 0.4             |
| 1005 | 0.176174097389  |
| 1001 | 0.103448275862  |
| 1010 | 0.0742713882795 |
| 1002 | 0.227499406317  |
| 1007 | 0.0             |

[6 rows x 2 columns]


上面这两个只是给大家举个例子，如果我要用 LR，而且我想要了解我最后的每个特征有没有使用，我就可以通过简单的这种统计方法来知道。因为这个比赛的数据是做过脱敏处理的，所以我只能通过这个统计的方式来知道哪些特征是比较重要的。

I also noticed that C15 and C16 appear to be the dimensions of the ad (width and height), which we would also imagine are good predictors of whether an ad is clicked:

如果是针对时间，需要自己划分时间段，

这个地方就要注意了：

如果这个维度是 category 的，但是类别非常多。如果是针对含义比较明确的，比如时间，可以自己做，如果是针对含义不那么明确的，可以进行聚类。比如用户的 id，是比较稀疏的，但是用户与用户的行为还是可以做聚类的，然后给不同的聚类不同的 classid ，这样维度就降下来了。


那想看一下单个feature 的出现的频次：

```python
data['C15'].sketch_summary().frequent_items()
```

```
{120: 2, 216: 912, 300: 3935, 320: 95132, 728: 18}
```


```python
data['C16'].sketch_summary().frequent_items()
```

```
{20: 2, 36: 912, 50: 95620, 90: 18, 250: 3427, 480: 20}
```

出现频次非常多的，但是这个用处是什么呢？比如 50 出现了 95620 次。20 出现了2 次。那么我如果 One-hot 时候 20 也给一列的话，维度就会增长很大，第二个危险是，如果我只出现了两次，那么我这个One-hot 之后的 C16_20 这个特征就只有两个样本来学习这个权重，是学不到东西的。

如果出现这种只出现 1,2 的频次非常低的样本，有时候我们会把它单独拿出来，看看本身是不是可以直接判定。

或者我们可以把频次比较低的比如只出现1~10 次的这些类别只划分成一个特征比如 C16_low。




For our initial model, we'll just use device_type, C1, C15, and C16 as our features.

Note that when we built the SFrame from the CSV file, it simply guessed the data type of each column. Sometimes these data types need to be adjusted, so let's take a quick look at the column names and their associated types to see if there's anything we need to fix:


```python
zip(data.column_names(), data.column_types())
```

```
[('id', str),
 ('click', int),
 ('hour', int),
 ('C1', int),
 ('banner_pos', int),
 ('site_id', str),
 ('site_domain', str),
 ('site_category', str),
 ('app_id', str),
 ('app_domain', str),
 ('app_category', str),
 ('device_id', str),
 ('device_ip', str),
 ('device_model', str),
 ('device_type', int),
 ('device_conn_type', int),
 ('C14', int),
 ('C15', int),
 ('C16', int),
 ('C17', int),
 ('C18', int),
 ('C19', int),
 ('C20', int),
 ('C21', int)]
```



We know that both device_type and C1 are "categorical variables", meaning that their numerical values represent categories. We'll convert the data type of both of those columns from integer to string, because we don't want our machine learning model to think there is a mathematical relationship between the category values:


```python
data['device_type'] = data['C1'].astype(str)
data['C1'] = data['C1'].astype(str)
```

You could spend a lot more time on the exploratory phase, but let's move along to the next step in predictive modeling! If you want to learn how to manipulate SFrames in more depth, read through this example notebook, [Introduction to SFrames](https://turi.com/learn/gallery/notebooks/introduction_to_sframes.html).

## Step 2: Splitting the Data

One of the keys to proper machine learning is model evaluation. The goal of model evaluation is to estimate how well your model will "generalize" to future data. In other words, we want to build a model that accurately predicts the future, not the past!

One of the most common evaluation procedures is to split your data into a "training set" and a "testing set".

Let's use an 80/20 split, in which 80% of the data is used for training and 20% is used for testing:


```python
train_data, test_data = data.random_split(0.8, seed=1)
```

We now have two separate SFrames, called train_data and test_data.

## Step 3: Selecting a Machine Learning Model

There are two main types of models: classification models, which are used when your target variable is categorical (such as yes/no), and regression models, which are used when your target variable is continuous (such as price). In this case, we'll need to use a classification model, since our target variable is categorical (click: yes or no).

The specific model we're going to use in this case is logistic regression. In logistic regression, the probability that the target is True is modeled as a logistic function of a linear combination of the features. Thus, the model is predicting a probability (which is a continuous value), but that probability is used to choose the predicted target class. In other words, it's using regression to predict a continuous value, but we're using the continuous value that is output from the model to perform classification. (Pretty cool, right?)

It can take a lot of study to truly understand a machine learning model, but a good introduction to logistic regression is available in the [user guide](https://turi.com/learn/userguide/supervised-learning/logistic-regression.html).

So, why exactly did we choose logistic regression for this task, instead of any of the other [available classification models](https://turi.com/learn/userguide/supervised-learning/classifier.html)? Well, it turns out that logistic regression has many nice properties. For starters, it is a very fast model, meaning that it does not take long to train the model or make predictions. As well, it is highly interpretable, meaning that you can understand exactly how it's making predictions. But the key consideration in this case is that logistic regression outputs "well-calibrated" predicted probabilities.

## Step 4: Training a Machine Learning Model

Now that we've selected our model, we can finally start the model training process! In GraphLab Create, this can be done in a single line. You simply pass in the training data, the name of the target column, and the names of the feature columns. And in fact, if you just replace `gl.logistic_classifier.create` with `gl.classifier.create`, GraphLab will choose the best model for you automatically (based on the properties of your data), meaning that you can skip Step 3 above!


```python
model = gl.logistic_classifier.create(train_data, target='click', features=['device_type', 'C1', 'C15', 'C16'])
```

    PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.
              You can set ``validation_set=None`` to disable validation tracking.

    PROGRESS: Logistic regression:
    PROGRESS: --------------------------------------------------------
    PROGRESS: Number of examples          : 76149
    PROGRESS: Number of classes           : 2
    PROGRESS: Number of feature columns   : 4
    PROGRESS: Number of unpacked features : 4
    PROGRESS: Number of coefficients    : 13
    PROGRESS: Starting Newton Method
    PROGRESS: --------------------------------------------------------
    PROGRESS: +-----------+----------+--------------+-------------------+---------------------+
    PROGRESS: | Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |
    PROGRESS: +-----------+----------+--------------+-------------------+---------------------+
    PROGRESS: | 1         | 2        | 1.074658     | 0.824095          | 0.819668            |
    PROGRESS: | 2         | 3        | 1.122571     | 0.824095          | 0.819668            |
    PROGRESS: | 3         | 4        | 1.168321     | 0.824095          | 0.819668            |
    PROGRESS: | 4         | 5        | 1.224780     | 0.824095          | 0.819668            |
    PROGRESS: | 5         | 6        | 1.274098     | 0.824095          | 0.819668            |
    PROGRESS: | 6         | 7        | 1.319348     | 0.824095          | 0.819668            |
    PROGRESS: +-----------+----------+--------------+-------------------+---------------------+

    PROGRESS: TERMINATED: Iteration limit reached.
    PROGRESS: This model may not be optimal. To improve it, consider increasing `max_iterations`.


Note that we didn't have to tell GraphLab how to handle each of the features, even though two features were numerical and the other two were categorical. The categorical features were automatically handled using "dummy encoding", which is why the output above indicates that there were 4 features but 13 model coefficients. (A simple explanation of dummy encoding is available in the [user guide](https://turi.com/learn/userguide/supervised-learning/linear-regression.html#linregr-categorical-features).)

## Step 5: Making Predictions

After training a model, the final step is to use the model to make predictions. In other words, the model has learned a mathematical relationship between the features and the target, and it will use that relationship to predict the target value for new data points.

In this case, we pass the testing data to the "fitted model", and ask it to output the predicted probability of a click:


```python
model.predict(test_data, output_type='probability').head(5)
```




    dtype: float
    Rows: 5
    [0.16537085227336723, 0.22480874210027335, 0.16537085227336723, 0.16537085227336723, 0.16537085227336723]



At this point, you would want to evaluate the model by comparing the predicted probabilities versus the actual target values, using an appropriate "evaluation metric." The best metric to use in this case is probably [logarithmic loss](https://www.kaggle.com/wiki/LogarithmicLoss), which is commonly used when you care about having well-calibrated probabilities. In addition, you might inspect the ROC curve and compute other metrics such as the F1-score and AUC. (See this [blog post](http://blog.turi.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics) for more details.)

Now that we have these probabilities, we could find the ad that maximizes revenue by multiplying these probabilities by the cost-per-click, and finding the largest value.

Although we're at the end of this notebook, this is really just the beginning! You can continue to add more features to the model, and then use the evaluation metric to compare the expected performance of each of your models. As well, you can use [feature engineering](https://turi.com/learn/gallery/notebooks/feature-engineering.html) to create new features, you can try other models, and so much more!

If you'd like to read more about click-through rate prediction, there are readable papers on the topic by both [Criteo](http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf) and [Google](http://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/41159.pdf).
