---
title: 06 内部机制
toc: true
date: 2018-06-27 07:24:34
---
### 内部机制

“知其然还必须知其所以然”，除了掌握Python本身的语法以及使用外，对其内部机制的 探索可以让我们更深人地理解和掌握语言本身所蕴含的思想和理念。本章将探讨Python的一 些内部机制以及髙于语法级别的话题，包括名字査找机制、描述符、对象的管理与冋收，以 及迭代器协议等。通过本章，希望读者可以更好地理解和掌握Python的精髓及其衍学原理。

##### ■议 54:理解 built-in objects

我们知道Python中一切皆对象：字符是对象，列表是对象，内建类型(built-in type)也 是对象；用户定义的类型是对象，object是对象，type也是对象。自Python2.2之后，为了弥 补内建类型和古典类(classic classes)之间的鸿沟引人丫新式类(new-style classes)。在新式类 中，object是所有内建类型的基类，用户所定义的类可以继承自object也可继承自内建类型。

那么内建类型、object、type以及用户所定义的类之间到底有什么关系呢？它们之间本 质上有什么不同吗？我们来看一个简单的例子：

class A:    ........................①古典类A

pass

class B (object): pass

class C(type): pass

㊀这里的鸿沟指的是：在2.2版本之前，类和类型并不统一，如a是古典类ClassA的一个实例，那么a._ class_ 返回 4class_main_ClassA’，type(a)返回 <type •instance、。当引人新类后，比如 ClassB 是个新类， b 是 ClassB 的实例，b._class_ 和 type(b)都是返回• class*_main_.ClassB •。

class D(diet):



pass

现在有类A、B、 果，如表6-1所示。



........................②D继承自内建类型diet

###### C、D的实例分别对应为a、b、c、d，我们来看一组求值的结

表6-1不同对象求值结果

| 编号 | 对象   | type<*>             | ••_class_           | *•_bases_           | isinstance(♦.object) | isinstance(•.type) |
| ---- | ------ | ------------------- | ------------------- | ------------------- | -------------------- | ------------------ |
| [1]  | object | <type *type*>       | <type .type.〉      | 0                   | 真                   | 真                 |
| 【2] | type   | <type 'type’〉      | <type 'type*>       | (<typc .object’〉,) | 真                   | 真                 |
| [3]  | a      | 〈type .instance.〉 | main.A              | 0                   | 真                   | 假                 |
| [4]  | b      | 〈class ’ main .B’> | 〈class ’—main .B*> | (<typc 'object^,)   | 真                   | 假                 |
| [5]  | c      | 〈class •main.C’>   | 〈class •main.C">   | (〈type ’type.〉，) | 真                   | 真                 |
| [6]  | d      | <class •main.D*>    | <class •main.D*>    | (<type *dicf>J      | 真                   | 假                 |

注：上表中求值时*用表中第一列的元素代替。

###### 从表6。1中我们可以得出如下结论：

□    object［l］和古典类［3］没有基类，type［2］的基类为object。

□新式类(［4］,［5］，［6］)中type()的值和_class_的值是一样的，但古典类［3］中实例的 type 为 instance，其 type()的值和 _class_ 的值不一样。

□继承自内建类型的用户类的实例［6］也是object的实例，object［l］是type的实例， type实际是个元类(metaclass)o

□    object和内建类型以及所有基于type构建的用户类［5］都是type的实例。

□在古典类中，所有用户定义的类的类型都为instance。

综上，不同类型的对象之间的关系如图6-1所示。

图6-1不同类型对象的关系图



我们知道古典类和新式类的一个区别是：新式类继承自object类或者内建类型。那么是 不是可以这么理解：如果一个类定义的时候继承自object或者内建类型，那么它就是一个新 式类，否则则是古典类？我们来看一个例子：

\>» class TestNewClass:

• • •    metaclass_ = type    ............①设置 _metaclass_ 鸚性为 type

參 •    •

\>>>

\>>> type(TestNewClass)

<type 1 type 1>

\>» TestNewClass ._bases_

(<type * object•>,)

〉>> a= TestNewClass()

»> type (a)

<class 1_main_.TestNewClass•〉

\>>> a._class_

〈class ’_main_.TestNewClass•〉

\>>>

从上述例子我们可以看出，TestNewClass在定义的时候并没有继承任何类，但测试的结 果表明其父类为object,它还是属于新式类。这其中的原因在于TestNewClass中设置了_ metaClaSS_属性(关于元类的更多介绍可以参看后面的章节)。所以我们并不能简单地从定 义的形式上来判断一个类是新式类还是古典类，而应当通过元类的类型来确定类的类型：古 典类的元类为types.ClassType,新式类的元类为type类。

新式类相对于古典类来说有很多优势：能够基于内建类型构建新的用户类型，支持 property和描述符特性等。作为新式类的祖先，Object类中还定义了一些特殊方法，如：_ new_()，_init_(), _delattr_()，_getattribute_()，_setattr_()，_hash_(), _repr_()， _str_()等。object的子类可以对这些方法进行覆盖以满足自身的特殊需求，建议62中会对 其中某些内容详细阐述，感兴趣的读者可以阅读。

![img](12 1699d828cfe301 3984Python0b8f84912afaae-60.jpg)



在Python中一切皆对象，type也是对象。



##### 建议55:



##### init_()不是构造方法



很多Pythoner会有这样的误解，认为方法是类的构造方法。因为从表面上看 它确实很像构造方法：当需要实例化一个对象的时候，使用a=ClaSS(argS...)便可以返冋一 个类的实例，其中args的参数与_1!^_()方法中申明的参数一样。可是事实真相是怎样的 呢？我们通过例子说明。

class A(object):

def _new_(cis, *args, **kwargs): print cis print args print kwargs print M---------••

instance = object._new_(cis, *argsf **kwargs)

print instance

def _init_(self,a, b):

print ninit gets called" print "self is.’，self self.a, self.b = a, b

al=A(lr 2)

print al.a

print al.b

运行程序输出如下：

<class

(lr 2)



—main_. A1 >



{}

< _main A object at 0x00D66B30>

Traceback (most recent call last):

File Htest.pyH, line 15, in <module> print al.a

AttributeError: •NoneType’ object has no attribute 1 a1

我们原本期望的是能够正确输出a和b的值，可是运行却抛出了异常。除了异常外还有 来自对_new_()方法调用所产生的输出，可是我们明明没有直接调用_new_0方法，原 因在哪里？实际上并不是真正意义上的构造方法，_inh_()方法所做的工作是 在类的对象创建好之后进行变景的初始化。_new_()方法才会真正创建实例，是类的构造 方法。这两个方法都是object类中默认的方法，继承自object的新式类，如果不覆盖这两 个方法将会默认调用object中对应的方法。上面的程序抛出异常是因为_new_()方法中并 没有显式返回对象，因此实际上al为None，当去访问实例属性a时抛出“AttributeError 'NoneType* object has no attribute 'a'M 的错误也就不难理解了。

我们来看看_new_()方法和_init__0方法的定义。

□    object._new_ (cis [，args…]):其中 cis 代表类，args 为参数列表。

□    object._init_ ( self [,args-]):其中self代表实例对象，args为参数列表。

这两个方法之间有些不同点，总结如下：

□根据 Python 文档([http://docs.python.Org/2/reference/datamodel.html#object._](http://docs.python.Org/2/reference/datamodel.html%23object._) new_) 可知，_new_()方法是静态方法，而」1^_()为实例方法。

□    _new_()方法一般需要返回类的对象，当返回类的对象吋将会自动调用方 法进行初始化，如果没有对象返回，则」nit_()方法不会被调用。」nit_()方法不

###### 需要显式返回，默认为None,否则会在运行时拋出TypeError。

□当需要控制实例创建的时候可使用_new_()方法，而控制实例初始化的时候使用_

init_()方法。

□—般情况下不需要覆盖_new_()方法，但当子类继承自不可变类型，如str、int、 Unicode或者tuple的时候，往往需要覆盖该方法。

□当需要覆盖_new_()和_init_()方法的时候这两个方法的参数必须保持一致，如 果不一致将导致异常。示例如下：

\>» class Test (object):

"• def _new_ (cis, x):

...    return super(Test,cis)._new_(cis)

... def init (self# k,y):

—— —■

...    self.x=x

• • •    self.y = y

\>» Test (1)

Traceback (most recent call last):

File •’<stdin>", line 1, in <module>

TypeError: _init_() takes exactly 3 arguments (2 given)

»> Test (2r 3)

Traceback (most recent call last):

File "<stdin>”， line 1, in <module>

TypeError: _new_() takes exactly 2 arguments (3 given)

\>>>

前面我们提到，一般情况下覆盖_!1^_()方法就能满足大部分需求，那么在什么特殊 情况下需要復盖_1^*_()方法呢？有以下几种情况：

1 )当类继承(如str、int、Unicode、tuple或者forzenset等)不可变类型且默认的_new_() 方法不能满足需求的时候。来看一个例子：假设我们需要一个不可修改的集合，该集合能 够将任何以空格隔开的字符串变为集合中的元索。现在不覆盖_new_0方法，仅覆盖_ init_()方法看看是否可行。

class UserSet(frozenset):

def _init_(self, arg=None):

if isinstance (arg, basestring):

arg = arg.split() frozenset. init (self, arg)

print UserSet(HI am testing w)

print frozenset (MI am testing

###### 运行稈序发现其输出如下：

UserSet ([ r 1 \ fe 1 r 9g9 f 919 f •m* z 9 n\ 1 i 1 r 1 s 1 r 111 ]) frozenset ([fa1/ 1 \ *e f r 9 g9, * 11# •m* 9 fn1r 1i * r 1s * r * t1])

显然没有满足用户的需求，用户希望得到的输出是UserSet ( [T, ’frozen’，’set’，W, 'tesing'] ) o实际上这些不可变类S的_init_()方法是个伪方法，必须重新覆盖_new_()方 法才能满足需求。_new_G*法实现的代码如下：

def new (cis, *args):

T? args and isinstance <args【0】， basestring):

args = (args[0】•split (),) + args[1:] return super (UserSet, cis)._new_(cis, *args)

2)用来实现工厂模式或者单例模式或者进行元类编程(元类编程中常常需要使用_ new_()来控制对象创建。这部分内容会在建议62中进行阐述)的时候。以简单T厂为例子， 它由一个工厂类根据传人的参量决定创建出哪一种产品类的实例，属于类的创建型模式。其 类的关系如图6-2所示。

图6-2简单工厂模式类关系示意图

###### 工厂模式的实现代码如下：

class Shape(object):

def _init_(object):

pass

def draw(self): pass

class Triangle(Shape):

def —init_(self):

print n I am a triangle" def draw(self):

print "I am drawing triangle"

class Rectangle(Shape):

def _init_(self):

print •• I am a rectnagle" def draw(self):

print "I am drawing triangle"

class Trapezoid(Shape):

def —init_(self):

print " I am a trapezoid11

def draw(self):

print "I am drawing triangle•’

class Diamond(Shape):

def init_(self):

print M I am a diamond** def draw(self):

print "I am drawing triangle" class ShapeFactory(object):

shapes = {* triangle1: Triangle, 1 rectangle *: Rectangle, •trapezoid•: Trapezoid, 'diamond1: Diamond}

def _new_(klass, name):

if name in ShapeFactory.shapes.keys():

print "creating a new shape %s" % name return ShapeFactory.shapes(name]()

else:

print "creating a new shape %s” % name return Shape()

在ShapeFactory类中重新覆盖了 _new_()方法，外界通过调用该方法来创建其所需 的对象类型，但如果所请求的类是系统所不支持的，则返回Shape对象。在引入了工厂类之 后，只需要使用如下形式就可以创建不同的图形对象：

ShapeFactory(•rectangle').draw()

###### 3)作为用来初始化的方法在多继承的情况下，子类的_ini匕()方法如果不 显式调用父类的_init_()方法，则父类的_init_()方法不会被调用。

class A(object):

def _init_(self):

print "I am A1 s init_•’

class B(A):

def _init_(self):

print "I am B• s _init_•’

b = B()

程序输出为：IamB’s」nit_。父类A的_init_()方法并没有被调用，所以要初始化 父类中的变量需要在子类的_init_()方法中使用super ( B,self) .」nit_()。对于多继承的情 况，我们可以通过迭代子类的_baseS_属性中的内容来逐一调用父类的初始化方法。

_new_()方法才是类的构造方法，i?5_init_()不是。

##### 建议56:理解名字查找机制

###### 在Python中，所有所谓的变量，其实都是名字，这些名字指向一个或多个Python对象3

###### 比如以下代码：

\>>>    a    =    1

\>»    b    =    a

\>»    c    -    1 china 1

\>»    id (a)    M    id (b)

True

\>» id (a) M id (c)

False

从中我们可以看出，名字a和b指向同一个Python对象，即一个int类型的对象，这个 对象的值为1 ;而c则指向另一个Python对象，它是•-个str类型的对象。所有的这些名字, 都存在于一个表里(又称为命名空间)，一般情况下，我们称之为局部变量(locals)，可以通 过locals()闲数调用看到。

\>>> locals()

{•a1: 1, 1: •china*, *6*: 1, 1_builtins_•: <module •_builtin__1 (built-in)>,

• package •: None, 1 name •: • main •, • doc •: None}

现在我们是直接在Python shell中执行这一些代码，实际上这些变量也是全局的，所以 在一个叫globals的表里也可以看到。

\>>> globals()

{•a•: 1, ^c*: 1 china1/ •b1: 1, •_builtins_•: <module •_builtin_• (built-in)>, • package •: None, 1 name •: ’ main •, 1 doc 1: None}

###### 如果我们在一个函数里面定义这些变量，情况会有所不同。

〉>> def foo(x):

| • . .    g « 1 china■•••    print locals() |                      |                    |           |             |              |
| ------------------------------------------ | -------------------- | ------------------ | --------- | ----------- | ------------ |
|                                            | printprintprintprint | * 10 globals()* 10 |           |             |              |
| c                                          | ①打印全局变量c       |                    |           |             |              |
| • • •>>>                                   | foo (1)              |                    |           |             |              |
| {•e.                                       | :lr •g1:             | 1 china1,          | •f•: 1,   | •x1: 1}     |              |
| ##*####*##                                 |                      |                    |           |             |              |
| < •a1                                      | :1, 'c* :            | •china、           | •b.: 1,   | 1_builtins_ | 」：〈module |
|                                            | in)>r 1_package_•    | :None,             | •_name_•: | •_main_•,   |              |

_builtin_• (built-foo1: 〈function foo at

0xl04fad320>r    •_doc_•: None)

\###*######

china

###### 可以看到函数中的localsO返回值并不包含之前定义在全局中的a、b、c等名字，只 有定义在函数内的e、f、g和函数形参x，这是什么原因呢？要回答这个问题，首先要理解

Python中变量的作用域。

Python中所有的变量名都是在赋值的时候生成的，而对任何变量名的创建、査找或者改 变都会在命名空间(namespace)中进行。变量名所在的命名空间直接决定了其能访问到的范 围，即变量的作用域。Python中的作用域自PythOn2.2之后分为局部作用域(local)、全局作 用域(Global)、嵌套作用域(enclosing functions locals)以及内置作用域(Build-in)这4种。

□局部作用域：一般来说函数的毎次调用都会创建一个新的本地作用域，拥有新的命名 空间。因此函数内的变量名可以与函数外的其他变量名相同，由于其命名空间不同， 并不会产生冲突。默认情况下函数内部任意的赋值操作(包括=语句、import语句、 def语句、参数传递等)所定义的变景名，如果没用global语句，则申明都为局部变 量，即仅在该函数内可见。

□全局作用域：定义在Python模块文件中的变量名拥有全局作用域，需要注意的是这 里的全局仅限单个文件，即在一个文件的顶层的变量名仅在这个文件内可见，并非所 有的文件，其他文件中想使用这些变量名必须先导人文件对应的模块。当在函数之外 给一个变量名赋值时是在其全局作用域的情况下进行的。

□嵌套作用域：一般在多重函数嵌套的情况下才会考虑到。需要注意的是global语句仅 针对全局变量.在嵌套作用域的情况下，如果想在嵌套的函数内修改外层函数中定义 的变量，即使使用global进行申明也不能达到目的，其结果最终是在嵌套的函数所在 的命名空间中创建r一个新的变量。示例如下：

def ex2():

var = * a 1 def inner():

global var var = 'b*

print 1 inside inner, var is •, var inner()

print •inside outer function, var is 1, var

上述程序的输出如下：

inside inner, var is b

inside outer function, var is a

□内置作用域：这个相对简单，它是通过一个标准库中名为_builtin_的模块来实 现的。

回到前面代码中标注①的语句print c，仍然正确输出了 china这个值。这是因为当访问 一个变量的时候，其査找顺序遵循变量解析机制LEGB法则，即依次搜索4个作用域：局部 作用域、嵌套作用域、全局作用域以及内置作用域，并在第一个找到的地方停止搜寻，如果 没有搜到，则会抛出异常。因此当存在多个同名变量的时候，操作生效的往往是搜索顺序在 前的。具体来说Python的名字査找机制如下：

###### 1 )在最内层的范围内査找，一般而言，就是函数内部，即在locals()里面査找。

###### 2)    在模块内査找，即在globalsO里面查找。

###### 3)    在外层査找，即在内置模块中査找，也就是在 builtin 中査找。

至此，我们可以理解清楚能够在foo()函数中访问到名字c的原W在于当Python在局部 变量中找不到c时，它会尝试在模块级的全局变量中查找，并成功地找到该名字。

不过，当我们试图改变全局变量的值时，事情可能跟想象的稍有不同。

\>» def bar ():

...    c = 1america1

."    print c

• • •

\>» bar () america »> print c china

真奇怪！不是吗？在bar()函数中修改c的值，并没有修改到全局变量的c,而是好像 bar()闲数有了一个局部变量c 一样！事实上确实如此，在CPython的实现中，只要出现了赋 值语句(或者称为名字绑定)，那么这个名字就被当作局部变量来对待。所以在这里如果需要 改变全局变量c的值，就需要使用global关键字。

\>>> def bar ():

...    global c

...    c = •america•

...    print c

• • •

\>» bar () america »> print c america

###### 不过，随着更多Python特性的加人，事情变得更加复杂起来。比如在Python闭包中， 有这样的问题：

\>>> def foo():

»> foo()()

Traceback (most recent call last):

File "<stdin>", line 1, in <module>

File "<stdin>”， line 4, in bar

UnboundLocalError: local variable •a1 referenced before assignment

从上例中可以看出，在闭包bar()中，在编译代码为字节码时，因为存在3=1)+1这条语 句，所以a被当作了局部变量看待，而执行时因为b=a*2先执行，此时局部变量a尚不存在, 所以产生了一个UnboundLocalError。在Python2.x中可以使用global关键字解决部分问题， 先把a创建为一个模块全局变最.然后在所有读写(包括只是访问)该变量的作用域中都要 先使用global声明其为全局变量。

〉>> a = 1

\>» def foo (x):

...    global a

...    a = a * x

•    •.    def bar ():

...    global a

...    return bar

\>» foo (1)()

3

这种方案抛开编程语言并不提倡全局变量不谈，有的时候还影响业务逻辑。此外，还有 把a作为容器的一个元索来对待的方案，但也都相当复杂。真正的解决方案是PythorB引人 的nonlocal关键字，通过它能够解决这方面的问题。

»> def foo (x):

»> barl = foo (1)

##### I议57:为什么需要self参数

self想必大家都不陌生，在类中当定义实例方法的时候需要将第一个参数显式声明为 self,而调用的时候并不需要传人该参数。我们可以使用self.x来访问实例变量，也可以在类 中使用self.m()来访问实例方法。self的使用示例如下：

class SelfTest(object):

def _init_(self,name):

self.name = name def showself(self):

print "self here is%su%self def display(self):

self.showself ()

print ("The name is:", self.name)

st = SelfTest("instance self0}

st.display()

print "%X"%(id<st>)

上例中我们使用self.name来表示实例变量name,在display方法中使用self.showself() 来调用实例方法showselfO,并且调用的时候没有显式传入self参数。程序输出如下：

self here is< jnain .SelfTest object at 0x00D67C10>

(•The name is:1,    * instance self1)

D67C10

从上述输出中可以看出，self表示的就是实例对象本身，即SelfTest类的对象在内存中 的地址。self是对对象st本身的引用。我们在调用实例方法的时候也可以直接传人实例对象: 如：SelfTest.display(st)。其实self本身并不是Python的关键字(cis也不是)，可以将self替 换成任何你喜欢的名称，如this、obj等，实际效果和self是一样的(并不推荐这样做，使用 self更符合约定俗成的原则)。

也许很多人感受self最奇怪的地方就是：在方法声明的时候需要定义self作为第一个参 数，而调用方法的时候却不用传人这个参数。虽然这并不影响语言本身的使用，而且也很容 易遵循这个规则，但多多少少会在心里问一问：既然这样，为什么必须在定义方法的时候声 明self参数呢？去掉第一个参数self不是更简洁吗？就如C++中的this指针一样。我们来简 单探讨一下为什么需要self。

1 ) Python在当初设计的时候借鉴了其他语言的一些特征，如Moudla-3中方法会显式 地在参数列表中传人self。Python起源于20世纪80年代末，那个时候的很多语言都有self, 如Smalltalk、Modula-3等。Python在最幵始设计的时候受到了其他语言的影响，因此借鉴 了芄中的一些理念(注：即使不了解Smalltalk、Modula-3也没有关系，此处只是为了说明当 初在设计Python时借鉴了其他语言的一些特点)。下面这段话摘自Guido 1998年接受的一个 访问，他自己也提到了这一点。

Andrew:What other languages or systems have influenced Python's design?(在 Python 的设 计过程中受到了哪些语言或者系统的影响？)

Guido:There have been many. ABC was a major influence, of course, since I had been working on it at CWI. It inspired the use of indentation to delimit blocks, which are the high-level types and parts of object implementation. I’d spent a summer at DEC’S Systems Research Center, where I was introduced to Modula-2+; the Modula-3 final report was being written there at about the same time. What I learned there showed up in Python’s exception handling, modules, and the fact that methods explicitly contain “ self" in their parameter list. String slicing came from

Algol-68 and Icon.(有很多，当然，ABC影响最大，因为在CWI的时候我一直在研究它。它 启发了我使用缩进来分块，这些是高级的类型以及部分对象的实现。我在DEC的系统研究 中心花费了一个暑假的时间，在那里我学到了 Modula-2+。而Modula-3也是在同一时期在那 里被实现的。我在那里学到的，在Python的弃常处理、模块以及方法的参数列表中显式包含 self中都有体现，而字符串的分隔则是从Algol-68和Icon中借鉴的。)

2) Python语言本身的动态性决定了使用self能够带来一定便利。下例中len表示求点到 原点距离的函数，现在有表示直角三角形的类Rtriangle，我们发现求第三边边长和len所实 现的功能其实是一样的，所以打算直接重用该方法。由于self在函数调用中是隐式传递的， 因此当直接调用全局函数len()吋传人的是point对象.而当在类中调用该方法时，传入的是 类所对应的对象，使用self可以在调用的时候决定应该传入哪一个对象3

\>>> def len (point):

... return math.sqrt(point.x ** 2 + point.y * * 2)

• • •

»> class RTriangle (object):

... def _init_(self,right_angle_sideX/right_angle_sideY): ...    self.right_angle_sideX = right_angle_sideX

•••    self.right_angle_sideY = right_angle_sideY

»> RTriangle. len = len »> rt = RTriangle (3f 4) »> rt. len ()

5.0

»>

Python属于一级对象语言(first class object),如果m是类A的一个方法，宵好儿种方式 都可以引用该方法，如下例所示：

»> class A:

"•    def m(self r value):

...    pass

• • •

\>» A._diet_(•m* ]

〈function m at 0x00D617B0>

\>» A.m. func

〈function m at 0x00D617B0>

实例方法是作用于对象的，如果用户使用上述两种形式来调用方法，最简单的方式就是 将对象本身传递到该方法中去，self的存在保证了 A._dict_[W] (a，2)的使用和a.(2)—致。 同时当子类衔盖了父类中的方法但仍然想调用该父类的方法的时候，可以方便地使用baseclass. methodname ( self,〈argument list〉)或 super ( childclass, self) .methodname ( < argument list > ) 来实现3

3)在存在同名的局部变量以及实例变tt的情况下使用self使得实例变量更容易被区分。

value — 'default global

class Test(object):

def _init_(self,pari):

value = parl+"----

self.value = value

def show(self):

print self.value print value

a = Test ("instance") show ()

上述程序中第一个value为全局变量，第二个为局部变量，仅仅在方法中可见，而类同 时定义了一个实例变景value。如果没有self,我们很难区分到底哪个表示局部变量，哪个表 示实例变量，有了 self这一切一目了然了。

其实关于要不要self或者要不要将self作为关键字一直是一个很有争议的问题，也有人 提了一些修正建议。但Guido认为，基于Python目前的一些特性(如类中动态添加方法，在 类风格的装饰器中没有self无法确认是返回一个静态方法还是类方法等)保留其原有设计是 个更好的选择，更何况Python的哲学是：显式优于隐式(Explicit is better than implicit.)。个 人体会是除了在定义的时候多输入几个字符外，self的存在并不会给用户带来太多困扰，我 们没有必要过分纠结于它是否应该存在这个问题。

##### 建议58:理解MRO与多继承

跟其他编程语言一样，Python也支持多继承。多继承的语法非常简单。

class DerivedClassName(Basel, Base2, Base3)

谈到多继承，我们来讨论一下图6-3所示的菱 形继承的经典问题。

假设有图6-3所示继承关系，当用古典类实现 的时候，如果有实例d=D()，当调用d.getvalue()和 d.show()方法的时候分别对应哪个父类中的方法？ 当改为新式类来实现吋，结果又将是怎样的呢？我 们来看具体实现：

class A():

def getvalue(self):

print "return value of A" def show(self):

图6-3多继承UML示意图



print "I can show the information of A"

class B(A):

def getvalue(seif):

print "return value of B"

class C(A):

def getvalue(self):

print "return value of C" def show(self):

print "I can show the information of C"

class D(BZC,:pass

当用古典类实现的时候我们会发现，分别调用的是B类的getvalueO方法和A类中 的show()方法，而当改为新式类实现(请读者自行验证)的时候，结果却变为调用B类的 getvalue()方法和C类的show()方法。从两种不同实现方式的输出上也町以证实这一点。

古典类输出如下：

return value of B I can show the information of A

新式类输出如下：

return value of B

I can show the information of C

为什么两种情况下输出结果会有所不同呢？这背后到底发生了什么？根本原因在哪 里？实际上，导致这些不同点的根本原因在于古典类和新式类之间所采取的MRO (Method Resolution Order,方法解析顺序)的实现方式存在差异。

在古典类中，MRO搜索采用简单的自左至右的深度优先方法，即按照多继承申明的顺 序形成继承树结构，自顶向下采用深度优先的搜索顺序，当找到所需要的属性或者方法的时 候就停止搜索。因此如阁6-3所示，当调用d.getvalueO的时候，其搜索顺序为D-〉B,所以 调用的是B类中对应的方法。而d.show()的搜索顺序为D->B->A,因此最后调用的是A类 中对应的方法。

而新式类采用的是C3 MRO搜索方法，该算法描述如下：

假定，C1C2...CN表示类CI到CN的序列，其中序列头部元素(head)=Cl,序列尾部 (tail)定义为=C2..CN;

C继承的基类自左向右分别表示为BI, B2...BN；

L[C]表示C的线性继承关系，其中L[object]=object。

算法具体过程如下：

L[C(B1 …BN)J = C + merge(L[B1]…L[BN], BI

BN)



其中merge方法的计算规则如下：在L[B1]...L[BN],B1…BN中 该元素不在L[B2]...L[BN]，B1...BN的尾部序列中，则添加该元素 到C的线性继承序列中，同时将该元素从所有列表中删除(该头 元素也叫good head)，否则取L[B2]的head。继续相同的判断，直 到整个列表为空或者没有办法找到任何符合要求的头元素(此时 将引发一个异常)。

图6-4菱形继承关系示意图



我们结合上面的例子来说明C3 MRO算法的具体计算方法， 以新式类实现的上述菱形继承关系如阁6-4所示。

根据算法规则有如下关系表达式：

L(0)=0; L(A)=AO;

则:

L(B)=B+merge(L(A))=B+merge(AO)=B+A+merge(0,0)=B,A,0

L(C)=C+merge(L(A))=C+merge(AO)=C+A+merge(0,0)=C,A,0

L(D)=D+merge(L(B),L(C),BC)

=D+merge(BAO,CAO,BC)

=D+B+merge(A0,CA0,C) ＜下一个计算取AO的头A.但A包含在CAO的尾部，因此不满足条件. 跳到下一个元紊CAO继续计算)

=D+B+C+merge(AO,AO)

=D+B+C+A+O =DBCAO

因此对于上述例子，当D的实例d调用getvalueO和showO方法时按照D->B->C->A->O的 顺序进行搜索，在第一个找个该方法的位置停止搜素并调用该类对应的方法，因此getvalueO 会在B的类中找到对应的方法，而show会在C()类中找到对应的方法。

关于MRO的搜索顺序我们也可以在新式类中通过查看_1^0_属性得到证实。D._ mro_的输出如下：

(〈class’_main_. D•〉，<class 1_main_. B • >, <class 1 _main_• C • >, <class • _mai

n_•A1>,<type1object1>)

实际上MRO虽然叫方法解析顺序，但它不仅是针对方法搜索，对于类中的数据属性也 适用。读者可以自行验证。

根据C3 MRO算法的描述，如果找不到满足条件的good head,则会摒弃该元素从而 对下一个元素进行査找。但如果找遍了所有的元素都找不到符合条件的good head会怎么样 呢？来看一个具体例子。

| class | A (object) | :pass          |                       |
| ----- | ---------- | -------------- | --------------------- |
| class | B (object) | :pass          |                       |
| class | C(Ar B):   | pass    ...... | ......①基类顺序为A，B |
| class | D(B, A):   | pass    ...... | ......②基类顺序为B, A |
| class | E(Cr D):   | pass           |                       |

运行程序我们会发现这种情况下有昇常抛出。

TypeError: Error when calling the metaclass bases Cannot create a consistent method resolution

order (MRO) for bases B, A

###### 根据上述代码的继承关系图(请读者自行画出)和MRO算法可以得出：

L(E)=E+merge(L(C)rL(D) ,CD)

=E+merge(CABO,CBAO,CD)

=E+C*Hnerge (ABO, BAOr D)

=E+C+D+merge(AB04BA0)

当算法进行到最后一步的吋候便再也找不到满足条件的head 了，因为当选择ABO的头 A元素的时候，发现其包含在BAO的尾部A0中；同理，B包含在BO中，此时便形成了一 个死锁，Python解释器此时不知道如何处理这种情况，便直接抛出异常，这就是上述例子有 异常抛出的原因。

菱形继承是我们在多继承设计的时候需要尽量避免的一个问题。

##### 含议59:理解描述符机制

###### 除了在不同的局部变量、全局变量中查找名字，还有一个相似的场景不可不察，那就是 査找对象的属性。在Python中，一切皆是对象，所以类也是对象，类的实例也是对象。

\>>> class MyClass(object):

... class attr = 1

\>» MyClass ._dict_

diet—proxy <{•_diet_•:〈attribute



of



module_•: •MyClass•



•_main_•,    •_weakref_•:

objects〉， 1_doc_•: None,



_dict_1 of *MyClass1 objects>z



<attribute •_weakref • class _attr•: 1})



###### 毎一个类都有一个 diet属性，其中包含的是它的所有屈性，又称为类属性。留意类 属性的最后一个元索，可以看到我们代码中定义的属性在其中的体现。

\>>> my_instance = MyClass()

〉>〉my_instance._diet_

U

除了与类相关的类属性之外，毎一个实例也有相应的属性表(_dict_)，称为实例属性。 当我们通过实例访问一个属性时，它首先会尝试在实例属性中查找，如果找不到，则会到类 屈性中査找。

\>>> my instance. class attr 1

###### 可以看到实例my」nstance可以i方问类属性class_attr。但与读操作有所不同，如果通过 实例增加一个属性，只能改变此实例的属性，对类属性而言，并没有丝毫变化。这从下面的

代码中可以得到印证。

»> my_instance. inst_attr = 9 china 1

\>>> my_instance._dict_

{•inst^attr1: 1 china 1}

»> MyClass. diet

dietproxy({1_diet_1: 〈attribute ’_diet__• of 1MyClass1 objects〉， module •: •一main_*, \_weakref_•: 〈attribute * weakref_■

•MyClass1 objects〉， •_doc_*: None, 1 class _attr•: 1})

那么，能不能给类增加一个属性呢？答案是，能，也不能。说能，是因为每一个class 也是一个对象.动态地增减对象的属性与方法正是Python这种动态语言的特性，自然是支 持的。

\>>〉MyClass.class_attr2 = 100 >» my^instance. class_attr2 100

###### 说不能，是因为在Python中，内置类型和用户定义的类型是有分别的，内置类型并不 能够随意地为它增加属性或方法。

\>» str .new_attr = 1

Traceback (most recent call last):

File "<stdin>", line lr in <module>

TypeError: can 11 set attributes of built-in/extension type *str >» setattr (strr *new_attr • z 1)

Traceback (most recent call last):

File "<stdin>", line 1, in <module>

TypeError: can11 set attributes of built-in/extension type 1str

至此，我们应当理解了，当我们通过操作符访问一个属性时，如果访问的是实例 属性，与直接通过_dict_属性获取相应的元素是一样的；而如果访问的是类属性，则并不 相同：操作符封装了对两种不同属性进行査找的细节。

\>>> mv instance. diet ( 1inst attr*]

1 china 1

\>>> my instance. diet [1 class attr2 9] Traceback (most recent call last):

File H<stdin>H, line 1, in <module> KeyError: •class_attr2 f

###### 不过，这里要讲的并不止于此，操作符封装了对实例属性和类属性査找的细节，只 讲了一半事实，还有一部分隐而未谈，那就是描述符机制。

\>>> MyClass.—diet_[1inst_attr1] •china*

»> MyClass . inst attr •china•

我们已经知道访问类属性时，通过_dict_访问和使用操作符访问是一样的，但 如果是方法，却又不是如此了。

\>>> class MyClass(object):

... def my一method(self):

...    print ,my_methodl

• •參

\>» MyClass . _diet_ [ ,my_method,]

<function my一method at 0xl02773aa0>

\>>> MyClasshod

〈unbound method MyClass.my_method>

甚至它们的类型都不一样！

\>>> type(MyClass.my_method)

<type * instancemethod * >

\>>> type(MyClass._diet_[,my_method,])

<type 1 function•〉

这其中作怪的就是描述符了。当通过操作符访问时，Python的名字査找并不是之 前说的先在实例属性中査找，然后再在类属性中査找那么简单，实际上，根据通过实例访问 属性和根据类访问属性的不同，有以下两种情况：

一种是通过实例访问，比如代码obj.x,如果x是一个描述符，那么_getattribute_ ()会返回 type(obj)._dict_[fx']._get_(obj,type(obj))结果，即：type(obj)获取 obj 的类型； type(obj)._dict_[’x*]返回的是一个描述符，这里有一个试探和判断的过程；最后调用这个描 述符的_get__()方法。

另一种是通过类访问的情况，比如代码cls.x,则会被_getattribUte_()转换为cls._ diet_['x']._get_(Nonc,cls)o

至此，就能够明白 MyClass._diet_[•my melhod’]返回的是 function 而不是 instancemethod 了，原因是没有凋用它的_get_()方法。是否如此呢？怎么验证一下？我们可以尝试手动 调用 _gCt_()o

»> t = f._get_(None, MyClass)

»> t

〈unbound method MyClass.my_method>

\>» type (t)

<type 1instancemethod1>

看，果然是这样！这是因为描述符协议是一个Duck Typing的协议，而每一个函数都有 法，也就是说其他每一个函数都是描述符。

描述符机制有什么作用呢？其实它的作用编写一般程序的话还真用不上，但对于编写 程序库的读者来说，就非常有用了。比如大家熟悉的已绑定方法和未绑定方法，它是怎么来 的呢？

〉>> MyClass.my_method

〈unbound method MyClass.my一method〉

»> a = MyClass ()

\>>> a.my method

<bound method MyClass.mymethod of <_main_.MyClass object at 0xl0277a490>>

上面例子输出的不同，其实来自T对描述符的_get_()的调用参数的不同，当以obj.x 的形式访问时，调用参数是_get_(obj，type(obj));而以cls.x的形式访问时，调用参数是_ get_(None，type(obj))，这可以通过未绑定方法的im self属性为None得到印证。

»> print MyClass .my一method. im_self None

»> a .my method, im self

<_main_.MyClass object at 0xl0277a490>

除此之外，所有对屈性、方法进行修饰的方案往往都用到了描述符，比如classmethod、 staticmethod和property等。在这里，給出property的参考实现作为本节的结束，更深人的应 用可以进一步参考Python源码中的其他用法。

class Property(object):

"Emulate PyProperty_Type() in Objects/descrobject.cw

def _init_(self, fget=None, fset=None, fdel=Noner doc=None):

self.fget = fget self.fset - fset self.fdel = fdel self._doc_ = doc

def _get_(self, obj, objtype=None):

if obj is None: return self

if self.fget is None:

raise AttributeError, "unreadable attribute" return self.fget(obj)

def _set_(self, obj, value): if self.fset is None:

raise AttributeError, Mcan• t set attribute** self.fset(obj, value)

def _delete_(self, obj): if self.fdel is None:

raise AttributeError, "canft delete attribute self.fdel(obj)

##### 建议 60:区别 _getattr_()和 _getattribute_()方法

_getattr_()和_getattribute_()都町以用做实例属性的获取和拦截(注意，仅对实例属 性(instance variable)有效，非类属性)，_getattr_()适用于未定义的属性，即该属性在实例 中以及对应的类的基类以及祖先类中都不存在，而_getattribute_()对于所有属性的访问都

会调用该方法。它们的函数签名分别为：

_getattr_: 一getattr_(self,name) getattribute_: _getattribute__(self,name)

其.中参数name为属性的名称。需要注意的是_getattribute ()仅应用于新式类。 既然这两种方法都用作属性的访问，那么它们有什么区别呢？我们来看一个例子。

class A(object):

def _init_(self,name):

self.name = name a = A("attribute") print a.name print a.test

上面的程序输出如下：

attribute

Traceback (most recent call last):

File ntest.pyMr line 7r in〈module〉

print a.test

AttributeError: •A1 object has no attribute 1 test•

当访问一个不存在的实例属性的时候就会抛出AttributeError异常。这个异常是由内部方 法_getattribute_(self,name)抛出的，因为_getattribute_()会被无条件调用，也就是说只 要涉及实例属性的访问就会调用该方法，它要么返回实际的值，要么抛出异常。Python的文 约 [http://docs.python.Org/2/reference/datamodel.html#object.getattribute](http://docs.python.Org/2/reference/datamodel.html%23object.getattribute) 中也提到了这一点。那 么_getattr_()会在什么情况下调用呢？我们在上面的例子中添加_getattr_()方法试试。

def _getattr_(selfr name):

print ("calling _getattr_:",name)

再次运行程序会发现输出为：

attribute

('calling _getattr_* test•)

None

这次程序没有抛出异常，而是调用了 _getattr_O方法。实际上_getatn*_()方法仅如下 情况下才被调用：属性不在实例的_出(^_中；属性不在其基类以及祖先类的_出(^_中; 触发AttributeError异常时(注意，不仅仅是_getattribute_()引发的AttributeError异常， property中定义的gct()方法抛出异常的时候也会调用该方法)。需要特別注意的是当这两个 方法同时被定义的时候，要么在_getattribute_()中显式调用，要么触发AttributeError异 常，否则_getattr_()永远不会被调用。_getattribute_()及_getattr_()方法都是Object类 中定义的默认方法，当用户需要覆盖这些方法时有以下几点注意事项：

1)避免无穷递归。当在上述例子中添加_getattribute_()方法后程序运行会抛出

RuntimeError 异謂•提示 “ RuntimeError:maximum recursion depth exceeded/’ o

def _getattribute_《self, attr): try:

return self._diet_[attr] except KeyError:

return 1 default1

这是因为属性的访问调用的是覆盖了的_getattribute_()方法，而该方法中self._ diet_[attr]又要调用_getattribute_(self,attr),于是产生了无穷递归，即使将语句self._ diet [attr]替换为 self._getattribute_(self,attr)和 getattr(self，attr)也不能解决问题。正确的 做法是使用 super(obj,self)._getattribute_(attr),因此上面的例子可以改为：supcr(A,sclf)._ getattribute_(attr)或者 object._getattribute_(self，attT)。无穷递归是覆盖 _getatt_()和 _ getattribute_()方法的时候需要特别小心。

2)访问未定义的属性。如果在_getattr()_方法中不抛出AttributeError异常或者显式 返回一个值，则会返回None,此时可能会影响到程序的实际运行预期。我们来看一个示例：

class A(object):

def _init_(selfr name):

self.name = name self.x = 20

def _getattr_(self,name):

print ("calling _getattr_:",name) if name == •z1:

return self.x ** 2 elif name == •y1:

return self.x ** 3

def _getattribute_(selfr attr): try:

return super(A,self)•_getattribute_(attr, except KeyError:

return •default'

a = A("attribute") print a.name print a•z if hasattr(ar1t1):

c= a. t print c

else :

print "instance a has no attribute t"

用户本来的意图是：如果t不属于实例属性，则打印出警告信息，否则给C赋值。按照 用户的理解本来应该是输出警告信息的，可是实际却输出None。这是因为在_getattr_O 方法中没有抛出任何异常也没有显式返回一个值，None被作为默认值返回并动态添加了属 性t，因此hasattr(object，name)的返回结果是True。如果我们在上述例子中抛出异f ( raise

TypeErrorfunknown attr:' + name))，则一切将如用户期待的那样。

另外关于_getattr_()和_getattribute_()有以下两点提醒：

1)    覆盖了 _getattribUte_()方法之后，任何属性的访问都会凋用用户定义的_ getattribUte_()方法，性能上会有所损耗，比使用默认的方法要慢。

2)    覆盖的_getattr_()方法如果能够动态处理事先未定义的属性，可以更好地实现数据 隐藏。因为dir()通常只显示正常的属性和方法，因此不会将该属性列为可用属性，上述例子 中如果动态添加属性y，即使hasattr(a，y)的值为True，dir(a)得到的却是如下输出：

[• _class_,, ’ _delattr_•, ■ _diet_•, • 一doc_•, • _format_•, • _getattr_’，

•_getattribute_ •, 1 hash_ • " _init_ ’，• _module_■, • _new_•, 1 _reduce—

reduce ex 1 z • repr 1, f setattr    sizeof    str    subc

lasshook_1, • weakref一 •， •name 1, •x•】

再来思考一个问题：我们知道property也能控制属性的访问，如果一个类中同时定义了 property、_getattribute_()以及_getattr_()来对屈性进行访问控制，那么具体的査找顺序 是怎样的呢？

class A(object):

_c ="test”

def _init_(self):

self.x = None

^property

def a(self):

print "using property to access attribute" if self.x is None:

print "return value" return 1 a 1

else:

print "error occured11 raise AttributeError

@a.setter

def a(selfr value):

self>x = value

def _getattr_(self, name):

print "using _getattr_ to access attribute” print (•attribute name: •, name)

return "b"

def _getattribute_(self, name):

print "using _getattribute_ to access attribute return object._getattribute_(self,name)

al = A()

print al.a

print "------------------，•

al.a - 1

print al.a

print ••------------------•’

print A._c

上述程序的输出如下：

using _getattribute_ to access attribute using property to access attribute using _getattribute_ to access attribute return value

using __getattribute_ to access attribute using property to access attribute using getattribute to access attribute error occured

using _getattr_ to access attribute (1 attribute name: •,    1 a 1)

b

当实例化al时由于其默认的属性x为None,当我们访问al.a时，最先搜索的是_ getattribute_()方法，由于a是一个property对象，并不存在于al的diet中，因此并不能返 回该方法，此时会搜索property中定义的get()方法，所以返回的结果是a。当用property中 的set()方法对x进行修改并再次访问property的get()方法时会抛出异常，这种情况下会触 发对_getattr_O方法的调用并返回结果b。程序最后访问类变量输出test是为了说明对类 变量的访问不会涉及_getattribute_()和_getattr_()方法。

1    会被膩，」■」)只有在-—」)中引发异常

##### 建议61:使用更为安全的property

property是用来实现属性可管理性的built-in数据类型(注意：很多地方将property称为 函数，我个人认为这是不恰当的，它实际上是一种实现T_get_()、_set_()方法的类，用 户也可以根据A己的需要定义个性化的property)，其实质是一种特殊的数据描述符(数据描 述符：如果一个对象同时定义了 _861_()和_3以_()方法，则称为数据描述符，如果仅定 义了 _get_()方法，则称为非数据描述符)。它和普通描述符的区别在于：普通描述符提供 的是一种较为低级的控制属性访问的机制，而property是它的髙级应用，它以标注库的形式

###### 提供描述符的实现，其签名形式为：

property(fget=None, fset=None# fdel=Noner doc=None) -> property attribute

Property常见的使用形式有以下几种。

###### 1 )第一种形式如下：

class Some_Class(object): def _init (self):

self._somevalue = 0 def getvalue(self):

print "calling get method to return value" return self._somevalue

def setvalue(selff value):

print "calling set method to set value" self._somevalue = value

def del_attr(self):

print ..calling delete method to delete value" del self._somevalue

x - property(get_valuer set_valuer del_attrf WI*m the *x1 property."}

obj = Some_Class() obj.x = 10 print obj.x + 2 del obj.x obj . x

###### 2)第二种形式如下：

class Some_Class(object):

_x=None

def _init_(self):

self._x = None

^property def x (self):

print "calling get method to return value" return self. x

@x.setter

def x(self/value):

print ••calling set method to set value" selfx - value

@x.deleter def x (self):

print "calling delete method to delete value** del self._x

在了解完property的基本知识之后来探讨一下这些问题：property到底有什么优势呢？ 为什么要有这个特性呢？ property的优势可以简单地概括为以下儿点：

###### 1)代码更简洁，可读性更强。这条优势是显而易见的，显然obj.x^l比obj.set_ value(obj.get_value()+l)要更简洁易读，而且对于编程人员来说还少敲了几次键盘。

2)更好的管理属性的访问。property将对属性的访问直接转换为对对应的get、set等相 关函数的调用，属性能够更好地被控制和管理，常见的应用场景如设置校验(如检査电子邮 件地址是否合法)、检测赋值的范围(如某个变量的赋值范围必须在0到10之间)以及对某 个属性进行二次计算之后再返回给用户(如将RGB形式表示的颜色转换为*******形式返回 给用户)或者计算某个依赖于其他属性的属性。来看一个使用property控制属性访问的例子。

\#!/usr/bin/python

\# — coding: utf-8 class Date(object):

def _init_(self,year,month,day): self.year - year self.month = month self.day — day

def get_date(self):

return self.year+n-M+self.month+^-^+self.day

def set_date(selfrdate_as_string):

year, month, day = date_as_string.split(•-•)

if not (2000 <= year <=2015 and 0 <= month <= 12 and 0

<=day <= 31):

print "year should be in 【2000:2015]" print "month should be in [0:12】•’ print "day should be in [0,31】" raise AssertionError

self.year = year self.month = month self.day = day

date =property(get_date,set_date)

创建一个property实际上就是将其属性的访问与特定的函数关联起来，相对于标准属性 的访问，其工作原理如图6-5所示。property的作用相当于一个分发器，对某个属性的访问并 不直接操作具体的对象，而对标准属性的访问没有中间这一层，直接访问存储属性的对象。

图6-5 property的工作原理

###### 3)代码可维护性更好。property对属性进行冉包装，以类似于接口的形式呈现给用户,

以统一的语法来访问属性，当具体实现需要改变的时候(如改变某个内部变量，或者赋值或 取值的计算发生改变)，访问的方式仍然可以保留一致。例如上述例子中，如果要更改date 的显示方式，如“2012年4月20 U”，则只需要对get_value()做对应的修改即可，外部程序 访问date的方式并不需要改变，因此代码的可维护性大大提高。

4)控制属性访问权限，提髙数据安全性。如果用户想设置某个属性为只读，我们来看 看使用property如何满足这个需求。

class PropertyTest(object): def _init_(self):

self._varl=20

@property

def x (self):

return self._var1

pt = PropertyTest () print pt.x pt.x=12

上面的程序输出如下：

20

Traceback (most recent call last):

File "tests.py”， line 11, in <module> pt.x=12

AttributeError: can * t set attribute

在前面的代码中我们只实现了 get()方法，没有实现set()方法。如果使用第一种形式的 property,也只需要设置x=property(get_value)后实现对应的get()方法即可。

值得注意的是：使用property并不能真正完全达到属性只读的目的，正如以双下划线 命令的变量并不是真正的私有变量一样，这些方法只是在直接修改属性这条道路上增加了 一些障碍。如果用户想访问私有属性，同样能够实现，如上例便可以使用pt._PrOpertyTeSt_ varl=30来修改属性。那么究竟怎样才能实现真正意义上的只读和私有变量呢？木节最后会 探讨这个问题，这里请读者先思考一下。

我们在本节开头提到property本质并不是函数，而是特殊类，既然是类的话，那么就可 以被继承，因此用户便可以根据自己的需要定义property。来看以下具体实现：

def update_meta (self, other):

self._name_ = other._name_ self._doc_ = other._doc一

self._diet_.update(other.__diet_)

return self

class UserProperty (property):

def new (clsr fqet=None/ fsec=Noner fdel=Noner doc=None):

if fget is not None:

def get (obj, objtype=None, name=fget. name ): fget = getattr(obj r name) print ••fget name : " + fget._name一 return fget()

fget = update_meta(_get_• fget)

if fset is not None:

def set (obj 9 value, name=fset. name ):

fset = getattr(obj 9 name) print f,fset name:" + fset._name_ print ’.setting value:" +str(value) return fset(value)

fset = update一meta(_set_, fset)

if fdel is not None:

def delete (obi/ name=fdel. name ):

fdel = getattr(obj, name)

print "warning: you are deleting attribute using fdel._name_”

return fdel()

fdel = update^meta(_delete_, fdel)

return property(fget, fset, fdel, doc)

class C(object):

|          | def get(self):print 1 calling C-getx to get value* return self._xdef set(self, x):print 1 calling C.setx to set value1 self._x = xdef delete(self): |                |      |      |      |      |      |
| -------- | ------------------------------------------------------------ | -------------- | ---- | ---- | ---- | ---- | ---- |
| x »      | print •calling C.delx to del self._xUserProperty(get,set,delete) | delete value * |      |      |      |      |      |
| C =      | co                                                           |                |      |      |      |      |      |
| C.X      | =1                                                           |                |      |      |      |      |      |
| print c. | .X                                                           |                |      |      |      |      |      |
| del      | C.X                                                          |                |      |      |      |      |      |

上述例子中 UserProperty 继承自 property,其构造函数 _new_(cis, fget=None, fset=None, fdel=None, doc=None)中重新定义了 fget()、fset()以及 fdel()方法以满足用户特定 的需要，最后返回的对象实际还是property的实例，因此用户能够像使用property —样使用 UserProperty。

###### 回到前面的问题：使用property并不能真正完全达到属性只读的目的，用户仍然可以绕 过阻碍来修改变量。那么要真正实现只读属性怎么做呢？我们来看一个可行的实现：

def ro_property(obj, name, value):

setattr (obj . class_, name, property (lambda ob j : ob j ._diet__•• + name]))

setattr (o^pj # ••_” + name, value)

class ROClass(object):

def _init_(self, name, available):

ro一property(self, "name", name) self.available = available

a = ROClass(”read only". True)

print a.name

a .^Article_name ="modify•’

print a._diet_

print ROClass._diet_

print a.name

###### 上述程序的输出如下：

read only

{1 available1: True, •_name1: 1 read only1, 1 Article_name1: •modify1}

{•_module_1: *_main_•, •name•: 〈property object at 0x00CA7330>, •_diet_*:

〈attribute * diet ' of fROClass• objects〉, • weakref •: 〈attribute f ■ ■ ■

_weakre

f ■ of 1ROClass1 objects〉, 1 doc 1: None, 1 init •: <function init at 0

x00D617B0>}

read only

我们发现，当用户再试图用a._ArtiCk_name来修改变量jiame的时候并没有达到目 的，而是重新创建了新的属性_ArtiC|e_name，这样就能够很好地保护可读属性不被修改， 以免造成损失了。

##### 建议62:掌握metaclass

###### 什么是元类(metaclass) ?也许我们对下面这些说法都不陌生：

□元类是关于类的类，是类的模板。

□元类是用来控制如何创建类的，正如类是创建对象的模板一样。

□元类的实例为类，正如类的实例为对象。

这些说法都没有错，在概念之外我们来进行一些更深人的探讨：元类是如何来控制类的 创建的？用户该如何定义自己的元类？在哪些情况下需要用到元类？使用元类可以解决什么 问题？

###### 我们知Python中一切皆对象，类也是对象，可以在运行的时候动态创建。当使用关键 字class的时候，Python解释器在执行的时候就会创建一个对象(这里的对象是指类而非类的 实例)。

»> def dynamic_class (name):

... if name == fAf:

...    class A(object):

..•    pass

...    return A

...    else:

•••    class B(object):

...    pass

...    return B

»>

»> UserClass = dynamic_class (f A*)

»> print UserClass

<class 1_main_. Af>

\>>> UserClass()

<_main_.A object at 0x00D67CF0>

\>>>

###### 既然类是对象，那么它就有其所属的类型，也一定还有什么东西能够控制它的生成。通 过type査看会发现UserClass的类型为type,而其对象UserClass()的类型为类A。

\>» type (UserClass)

<type •type1>

\>>> type(UserClass ())

<class 1_main_.A1>

###### 同时我们知道type还可以这样使用：

type(类名，父类的元组(针对继承的情况，可以为空)，包含屬性的字典(名称和值)>

###### 例如：

»> A=type < • A •, (object, ), { • value ■ : 2 "

»> A.value

\>» print A

<class •_main_.Af>

»> class C (A):

•    •• ps s s

###### •    •嚳

\>» print C

<class •_main_.C•>

»>

\>» print C._class一 <type 1 type1>

###### 上例中type通过接受类的描述作为参数返回一个对象，这个对象可以被继承，属性能

够被访问，它实际是一个类，其创建由type控制，由type所创建的对象的_也85_属性为 type。type实际上是Python的一个内建元类，用来直接指导类的生成。当然，除了使用内建 元类type,用户也可以通过继承type来自定义元类。我们来看一个利用元类实现强制类型检 査的例子。

class Typesetter(object):

def _init_(self,fieldtype):

print "set attribute type",fieldtype self .fieldtype = fieldtype

def is_valid(self/value):

return is instance (value, self .fieldtype)

class TypeCheckMeta(type):

def _new_(cis,name,bases, diet):

print 9-----------------------------------*

print "Allocating memory for class", name print name

print bases print diet

return super(TypeCheckMeta, cis) •_new__(cis,name,bases,diet} def _init_<cls,name,bases,diet):

cis .^fields = {}

for key,value in diet.items():

if isinstance(valuerTypesetter):

cis .—fields [key] ■ value

def sayHi (cis):

print ”Hi"

Typesetter用来设S屈性的类型，TypeCheckMeta为用户自定义的元类，覆盖丫 type元类 中的_new_()方法和_init_()方法。虽然也可以直接使用TypeCheckMeta(name,bases,diet) 这种方式来创建类，但更为常见的是在需要被生成的类中设置_metaClaSS_属性，两种用 法是等价的。

class TypeCheck(object):

_metaclass_ = TypeCheckMeta

def setattr (self,key,value):

print ’’set attribute value" if key in self .^fields:

if not self •一fields [key] . is—valid (value):

raise TypeError (' Invalid type for field1 )

super(TypeCheck,self)._setattr_(key,value)

class MetaTest(TypeCheck):

name = Typesetter(str) num = Typesetter(int)

mt = MetaTest()

mt.name = "apple”

mt.num = "test"

当类中设置了 _metaClaSS_属性的时候，所有继承自该类的子类都将使用所设置的元 类来指导类的生成，因此上述程序的输出如下：

Allocating memory for class TypeCheck

TypeCheck

（<type 1 object•〉，）

{•_module__main_•,*_metaclass_1:〈class •_main_•TypeCheckMeta•>, setattr_•: 〈function _setattr_ at 0x00D61830>|

set attribute type <type •str * >

set attribute type <type 1intf>

Allocating memory for class MetaTest

MetaTest

(<class * main.TypeCheck1>f)

_module_’：•_main_•，’num*: < main .Typesetter object at 0x00D67E70>, *n ame *: <_main_.Typesetter object at 0x00D67E50>) set attribute value

set attribute value

Traceback (most recent call last):

File "metatest.py”， line 38, in <module> mt.num = "test"

File "metatest.py", line 28, in setattr_

raise TypeError (• Invalid type for field*)

TypeError: Invalid type for field

实际上，在新式类中当一个类未设置_metaclaSS_属性的时候，它将使用默认的type 元类来生成类。而当该属性被设S时査找规则如下：

1 )如果存在dictr_metaclass_’］,则使用对应的值来构建类；否则使用其父类diet［匕 metaclaSs_*］中所指定的元类来构建类，当父类中也不存在指定的metaclass的情形下使用默 认元类type。

2)对于古典类，条件1不满足的情况下，如果存在全局变量_metaclaSS_，则使用该 变fl所对应的元类来构建类；否则使用types.ClassType。

读者可以通过将上述例子中_metaclass_=TypeCheckMeta设S为模块级别或者将 TypeCheck改为古典类来验证上述査找规则。

需要额外提醒的是，元类中所定义的方法为其所创建的类的类方法，并不属于该类的对 象。因此上例中 mt.sayHi()会抛出 AttributeError: ’MetaTesf object has no attribute 'sayHi'错误， 而凋用该方法的正确途径为MetaTest.sayHi()o

那么在什么悄况下会用到元类呢？有句话是这么说的：当你面临一个问题还在纠结要不 要使用元类的时候，往往会有其他的更为简单的解决方案。

Python界的领袖Tim Peters曾这样说过：“元类就是深度的魔法，99%的用户应该根本 不必为此操心。如果你想搞清楚究竞是否需要用到元类，那么你就不需要它。那些实际用到 元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。”

###### 我们来看几个使用元类的场景。

###### 1)利用元类来实现单例模式。

class Singleton(type):

def _init_<clsrname,bases,die):

super(Singleton,cis)._init_(name,bases,die)

cis.instance = None

def _call_(clsf *args# **kwargs):

if cis.instance is None:

print "creating a new instance"

cis.instance = super(Singleton,cis)•_call

(*args,**kwargs)

else:

print nwarning:only allowed to create one instance,minstance already exists!’.

return cis.instance

class MySingleton(object):

一metaclass_ = Singleton

###### 2 )第二个例子来源于Python的标准库string.Template.string,它提供简单的字符串替换 功能。常见的使用例子如下：

Template(1$name $age•)•substitute({1 name•admin•J, age=26)

该标准库的源代码中就用到了元类，Template的元类为TemplateMetaclass。_ TemplateMetaclass 的 _init_()方法通过査找/4性(pattern、delimiter 和 idpattem)并将其构 建为一个编译好的正则表达式存放在pattern属性中。用户如果需要自定义分隔符(delimiter) 可以通过继承Template并覆盖它的类属性delimiter来实现。string.Template的部分源代码如下:

class Template:

’""•A string class for supporting $-substitutions. _metaclass_ - ^TemplateMetaclass

delimiter = •$•

idpattern = r•[_a-z][一a-zO-9J *•

def _init_(self, template): self.template = template

class ^TemplateMetaclass(type): pattern = r"”"

% (delim)s(?:

(?P<escaped>%(delim)s) I (?P<named>%(id)s)    I

{(?P<braced>%(id)s)} I {?P<invalid>)



Escape sequence of two delimiters delimiter and a Python identifier delimiter and a braced identifier Other ill-formed delimiter exprs



def



init_(cis, name, bases, dct):

super(_TemplateMetaclass, cis)._init_(name, bases, dct)

if •pattern * in dct:

pattern = cis.pattern else:

pattern = _TemplateMetaclass.pattern % {

•delim1 : _re.escape(cis.delimiter)r • id1 : cis•idpattern,

}

cis.pattern = re•compile(pattern, _re.IGNORECASE | re.VERBOSE)

###### 另外在Django ORM、AOP编程中也有大量使用元类的情形。最后来谈谈关于元类需要 注意的几点：

1)区別类方法与元方法(定义在元类中的方法)。我们先来看一个例子：Meta和 SubMeta都为元类，其中SubMeta继承自Meta。因此fl、£2都为元方法，而Test为普通类, 其元类设置为SubMeta, f3为类方法。

»> class Meta (type):

"• def f1(cis):

…    print "This is fl()"

»> class SubMeta (Meta):

... def f2(cis):

…    print "This is f2 <) ••

• • •

»>

»> class Test (object):

"•    _metaclass_ = SubMeta

•    "    @classmethod

".    def f3(cis):

•    "    print " I am f3()M

\>»

»> t= Test ()

\>>> SubMeta.f1(Test)

This is fl ()

»> Meta . f 1 (Test)

This is fl()

\>» Test. fl ()

This is fl()

\>» SubMeta. f2 (Test)

This is f2 ()

\>» Test. f2 ()

This is f2()

»> t.f2 ()

Traceback (most recent call last):

File "<stdin>M, line 1, in <module>

AttributeError: ,Test, object has no attribute 1f21

\>» Test. f 3 ()

I am f3()

»> t.f3()

I am f3()

\>»

上面的例子说明，元方法可以从元类或者类中调用，而不能从类的实例中调用；但类方 法可以从类中调用，也可以从类的实例中调用。

2)多继承需要严格限制，否则会产生冲突。

\>>> class Ml(type):

... def _new_(meta, namef bases, atts):

...    print nMl called for " + name

...    return super(Ml, meta)._new_(meta, name, bases, atts)

\>>> class Cl(object):

•    "    _metaclass_ - Ml

•    •嚳

Ml called for Cl »>

»> class Subl (Cl) :pass

Ml called for Subl

\>〉> class M2(type):

... def _new_(meta, name, bases, atts):

...    print ”M2 called for n + name

...    return super(M2, meta)._new_(meta, name, bases, atts)

\>>> class C2 (object):

.••    _metaclass_ « M2

• • •

M2 called for C2

\>>> class Sub2(Cl, C2):

•    • • pass

•    • •

Ml called for Sub2

Traceback (most recent call last):

File "<stdin〉"， line 1, in <module>

File "<stdin>M, line 4, in _new_

TypeError: Error when calling the metaclass bases

metaclass conflict: the metaclass of a derived class must be a (non-strict)

subclass of the metaclasses of all its bases

上面的例子中当Sub2同时继承自元类Cl和C2的时候会抛出异黹，这是因为Python解 释器并不知道C1和C2是否兼容，因此会发出冲突警告。解决冲突的办法是重新定义一个派 生自Ml和M2的元类，并在C3中将其_metaClaSS_«性设置为该派生类。

»> class M3 (Ml, M2):

... def new (meta, name, bases, atts):

"•    print "M3 called for " + name

•••    return super(M3, meta)._new_(meta, name, bases, atts)

\>» class C3 (Cl, C2):

...    _metaclass_ = M3

• • •

M3 called for C3

Ml called for C3

M2 called for C3

元类用来指导类的生成，元方法可以从元类或者类中调用，不能从类的实例中调用， 而类方法既可以从类中调用也可以从类的实例中调用。

##### 建议63:熟悉Python对象协议

因为Python是一门动态语言，Duck Typing的概念遍布其中，所以其中的Concept并不 以类型的约束为载体，而另外使用称为协议的概念。所谓协议，类似你讲英语，我也讲英 语，我们就可以交流；在Python中就是我需要调用你某个方法，你正好就有这个方法。比如 在字符串格式化中，如果有占位符％^那么按照字符串转换的协议，Python会去自动地调 用相应对象的_str_()方法。

»> class Object (object):

•    " def _str_(self):

...    print 1 called _str_1

...    return super(Object, self)•_str_()

•    • •

»> o = Object ()

»> print ”％s" % o called _str_

<_main_.Object object at 0xl0277a5d0>

这倒数第二行就是明证。除了 _str_()外，还有其他的方法，比如_repr_()、_int_ ()、_long_()、_float_()、_nonzero_()等，统称类型转换协议。除了类型转换协议之外， 还有许多其他协议。

1)    用以比较大小的协议，这个协议依赖方法，与C语言库函数cmp类似， 当两者相等时，返回0,当selfkother时返回负值，反之返回正值。因为它的这种复杂性，所 以Python又有_eq_()、_ne_()、_lt_()、_gt_O等方法来实现相等、不等、小于和大于 的判定。这也就是Python对=、！=、<和> 等操作符的进行重载的支撑机制。

2)    数值类型相关的协议，这一类的函数比较多，如表6-2所示。

表6-2 Python的协议与函数对应关系表

| 类分        | 法方      | 数函作操                              | 明说     |
| ----------- | --------- | ------------------------------------- | -------- |
| 数值运裨符  | dad1      | +                                     | JII      |
| 1ubs1       | •         | 减                                    |          |
| 1mu1        | *         | 乘                                    |          |
| 1V1         | /         | 除                                    |          |
| 1VIfl1      | z/        | 赚                                    |          |
| 1Verut1     | /z        | 用调时用作起onS1Vi-Jc&.用一除调真则否 |          |
| wop         | 串拿      | 算运幂                                |          |
| 1odmo1      | %         | 余                                    |          |
| -dmoV1      | \t/moV    | 除                                    |          |
| 位运筲符    | ft• 1sh11 | <<                                    | 位移左向 |
| ftrsh-      | >>        | 位移右向                              |          |
| 1ndan1      | &         | 与                                    |          |
|             | —         | 或                                    |          |
| rlxo1       | A         |                                       |          |
| 1rteVn• n1  | J         | 非                                    |          |
| 运算赋值符  | 1dda• I1  | I                                     |          |
| 1ubs• IB1   | --        |                                       |          |
| UImu• 11    | J-        |                                       |          |
| 1V• a—id    | /=        |                                       |          |
| 1IVrdoofli  | //=       |                                       |          |
| iv_edrut-   | /=        |                                       |          |
| 1pow• IB1   | II傘傘    |                                       |          |
| od-mo • n-  | %=        |                                       |          |
| ft-lshl•服1 |           |                                       |          |
| •fthrs•11   | -         |                                       |          |
| d-ai-       | II&       |                                       |          |
| Joi         | \|=       |                                       |          |
|             | orX       | A--                                   |          |
|             | s-        | +                                     | 正       |
| -egn1       | -         | 负                                    |          |
|             | 1bsa-     | VIZbs(a                               | 偾对绝   |

基本上，只要实现了表6-2中的几个方法，基本上就能够模拟数值类型了。不过还 需要提到一个Python中特有的概念：反运算。别被吓着，其实非常简单。以加法为例， something+other，调用的是 something 的 _add_()方法，如果 something 没有 _add_()方 法怎么办呢？调用other._add_()是不对的，这时候Python有一个反运算的协议，它会去査 看other有没有_radd_()方法，如果有，则以something为参数调用之。类似_radd_()的

方法，所有的数值运算符和位运算符都是支持的，规则也是一律在前面加上前缀r即可，在 此不再细表。

3)    容器类型协议。容器的协议是非常浅显的，既然为容器，那么必然要有协议査询内 含多少对象，在Python中，就是要支持内置函数len()，通过_Jen__()来完成，一目了然。 而 _getitem_()、_setitem_()、_delitem_()则对应读、写和删除，也很好理解。_iter_() 实现了迭代器协议，而_代7灯试(1_0则提供对内®函数reversedO的支持。容器类型中鍛有 特色的是对成员关系的判断符in和not in的支持，这个方法叫_COntainS_(),只要支持这个 函数就能够使用in和not in运算符了。

4)    可调用对象协议。所谓可调用对象.即类似函数对象，能够让类实例表现得像函数 一样，这样就可以让每一个函数调用都有所不同。

\>>> class Functor(object):

... def _init_(selfz context):

...    self.一context = context

... def _call_(self):

...    print 'do something with %s• % self.^context

\>>> laifunctor = Functor(•lai1)

\>» yong f unctor = Functor ('yong*)

\>>> lai functor () do something with lai >>> yong__functor () do something with yong

5)    与可调用对象差不多的，还有一个可哈希对象，它是通过_1^811_()方法来支持 hash()这个内置函数的，这在创建自己的类型时非常有用，因为只有支持可哈希协议的类型 才能作为diet的键类型(不过只要继承自object的新式类默认就支持了)。

6)    前面的文档谈对描述符协议和属性交互协议(_getattr_()、_setattr_(). _ delattrO),那么剩下来还值得一谈的就是上下文管理器协议了，也就是对with语句的支持， 这个协议通过_enter_()和_exit_()两个方法来实现对资源的清理，确保资源无论在什么 情况下都会正常清理。

class Closer:

，• •通过with语句和一个close方法来关闭一个对象• 1 • def init (self, obj):

self.obj = obj def _enter_(self):

return self.obj # bound to target def _exit_(self, exception_typer exception_val, trace):

try:

self.obj.close()

except AttributeError:轉 obj isn * t closable print *Not closable.1

return True # exception handled successfully

对于实现了这两个方法的Closer类，我们可以如下使用它：

»> from ftplib import FTP

»> with Closer (FTP (• f tp. somesite>com*) ) as conn :

... conn.dir()

• • •

\>» conn .dir ()

»>

可以看到第二次调用conn.dir()已经没有输出，这是因为这个FTP连接会话已被关闭的 缘故。与这里Closer类似的类在标准库中已经存在，就是contextlib里的closing。

至此，常用的对象协议就讲完了，只要活学活用这些协议，就能够写出更为Pythonic的 代码。不过也要注意，协议不像O+、Java等语言中的接口，它更像是声明，没有语言上的 约束力，需要大家共同遵守。

##### 建议64:利用操作符重载实现中缀语法

可能你跟我一样，学完各种对象协议后就跃跃欲试。当年我初学Python的时候，原本 鉍熟悉的编程语言是O+，所以学会操作符重载以后，就拿来炫技了。

\>» class endl (object) :pass

\>» class Cout (object):

... def _lshift_(self, obj):

...    if obj is endl:

"•    print

"•    return

...    print obj/

...    return self

參 參 參

\>» cout = Cout ()

\>» cout << 1 << 2 << endl

12

如果你像我当年那样初学Python,你就会明白这种模拟C++的流输出让我感觉有多 炫！但是现在我知道这是一种对特性的滥用，不应提倡。不过我在这里重提旧事的原因是想 要引出一个非常棒的利用操作符重载实现更优雅的代码的例子。

熟悉Shell脚本编程朋友应该都非常熟悉“    这个符号，它表示管道，用以连接两个应

用程序的输人输出。比如按字母表反序遍历当前目录的文件与子目录，可以如下使用：

$ Is I sort -r

releases

prj

intern

doc

common

branches

art

管道的处理非常清晰，因为它是中缀语法。而我们常用的Python是前缀语法的，比如 类似的Python代码应该是sort(ls()，reverse=True),明没有那么清晰，特别是在极限情况下。

sum(select(where(take while (fib ()# lambda x: x < 1000000) lambda x: x % 2), lambda x: x * x))

像这样的代码，一堆sum、select、where混在一起，一眼看过去已经头大如斗了。管 道符号在Python中，也是或符号，那么有没有可能利用它来简化代码呢？这个想法后来由 Julien Palard开发了一个pipe库，达成了所愿。这个pipe库的核心代码只有几行，就是重载 了 _ror__()方法。

class Pipe:

def _init_(self, function): self.function - function

def _ror_(self, other):

return self.function(other)

def call (selfr *args, **kwargs):

return Pipe(lambda x: self.function(x, *args, **kwargs))

这个Pipe类可以当成函数的decorator来使用。比如在列表中筛选数据，可使用如下实现：

@Pipe

def where(iterable, predicate):

return (x for x in iterable if (predicate(x)))

###### pipe库内置了一堆这样的处理函数，上文所述的sum、select、where等函数尽在其-中， 所以马上就可以拿来改造之前的代码。

fib () | take一while (lambda x: x < 1000000) \

I where(lambda x: x % 2) \

I select(lambda x: x * x) \

I sura ()

看，现在是不是一眼就可以看出代码的意义了呢？就是找出小于1000000的斐波那契 数，并计算其中的偶数的平方之和。通过这个例子，可以看出中缀语法在这种流式数据处理 上的确是非常有优势的。

pipe已经发布到pypi，可以使用pip install pip命令安装。安装完成以后可以在Python Shell中尝试一下。

»> from pipe import *

»> 【1, 2, 3, 4, 5] I where (lambda x: x % 2) | tail (2) I select (lambda x: x * x)

I add

34

###### 此外，pipe是惰性求值的，所以我们完全可以弄一个无穷生成器而不用担心内存被用完。 比如：

»> def fib ():

• " a, b = 0, 1 ... while True:

...    yield a

...    a, b = br a + b

###### 然后来做一个题目：计算小于4 000 000的斐波那契数中的偶数之和。

»> euler2 = fib () I where (lambda x: x % 2 == 0)    | take_while (lambda x: x <

4000000) I add

»> assert euler2 == 4613732

可以看到代码非常易读，就像读自然语言一样。除了处理数值很方便，用它来处理文本 也一样简单。看看这个需求：读取文件，统计文件中每个单词出现的次数，然后按照次数从 高到低对单词排序。

from _future_ import print_function from re import split from pipe import *

with open(1testdescriptor.py1) as f: print(f.read()

I Pipe(lambda x:split(•/W+1, x))

I Pipe (lambda x: (i for i in x if i.stripO ))

I groupby(lambda x:x)

I select(lambda x:(x[0], (x[lJ I count)))

I sort(key=lambda x:x[1]z reverse=True)

)

###### 看看，非常简单吧？在我这里运行的结果如下：

[Cself \ 13), Cfoo\ 9), (•item\ 9), (•一 data.，8), Cprint1, 7), Cdef\ 5), (•return、5), (.Jeff、4), (fi\ 4), Cin\ 4), Cjeff\ 4), Cken\ 4)z (•obj\ 4)，Cval\ 4) r (.class、3)，(flai\ 3)z Cpan1, 3}, Ctmp\ 3),

(1Foo1r 2), (•XtemDescriptor•# 2), (.Wrapper•, 2)x    _iter_\ 2)# (.for’，2),

Cifz 2),「next., 2), Cobject\ 2), CO., 1), Cl., 1), ( 930\ 1), C8\ 1),

(•None* / 1), (1一class_1), (•_future_•/ 1), <•_get_1 r 1) 9 <•_init_•, 1), (•_set_•, 1)'    ('bin1/ l)z (•coding* f 1) f (fenv\ l)r (*f \ l)r (.from、1),

(•import’，1)，(•instance* 9 1), (•isinstance1, 1), (1len1, 1), ('list19 1), (•print function^ 1),    ('python1 r 1), (.type1, l)f (•usr^ 1),    1)]

##### 建议65:熟悉Python的迭代器协议

###### 其实对于大部分Python程序员而言，迭代器的概念可能并不熟悉。但这很正常，与

C++等语言不同，Python的迭代器集成在语言之中，与语言完美地无缝集成，不像C++中那 样需要专门去理解这一个概念。比如，要遍历一个容器，Python代码如下：

\>>> alist = range (2)

\>>> for i in alist:

...    print i

0

1

而C++代码如下：

using namespace std; vector<int> mylntVector;

//往容器mylntVector中添加元素的操作，略

for(vector<int>::iterator ■ mylntVector.begin();

mylntVectorIterator !■ mylntVector.end 0; mylntvectorlterator++){

cout<<*myIntVectorIterator<<H ”；

两相对比，可以看到C-H-的代码中，多了 一个vector<int>:: iterator类型，它是什么、 有什么用、什么时候用、怎么用，都是C++程序员需要理解和掌握的内容，所以可以说， 在“实现遍历容器”这一事情上，使用•要付出更多的精力去学习更多的内容，这就是 Python把迭代器内建在语言之中的好处。

但是，并非所有的时候都能够隐藏细节，特别是在写一本书向读者讲述其中的机理的时 候。所以在这里，首先需要向大家介绍一下iter()函数。iter()可以输人两个实参，但为了简 化起见，在这里忽略第二个可选参数，只介绍一个参数的形式。iter()函数返冋一个迭代器 对象，接受的参数是一个实现了 _iter_()方法的容器或迭代器(精确来说，还支持仅有_ getitem_()方法的容器)。对于容器而言，_iter_()方法返回一个迭代器对象，而对迭代器 而言，它的_iter_()方法返回其自身，所以如果我们用一个迭代器对象it，当以它为参数调 用iter(it)时，返回的是自身。

\>>> it = iter(alist)

\>>> it2 = iter (it)

\>>> assert id(it) == id(it2)

到时此，就可以跟大家讲一下迭代器协议了。前文已经说过，所谓协议，是一种松散的 约定，并没有相应的接口定义，所以把协议简单归纳如下：

1)    实现_iter_()方法，返回一个迭代器。

2)    实现next()方法，返回当前的元素，并指向下一个元素的位置，如果当前位置已无 元素，则抛出Stoplteration异常o

可以通过以下代码验证这个协议：

»> alist = range (2)

»> it = alist._iter_ ()

\>» it. next (}

0

\>» it. next ()

1

\>» it. next O

Traceback (most recent call last):

File "<stdin>", line 1, in <module>

Stoplteration

与上例使用iter()内置函数不同，这次的代码是it=alist._iter_(),可见list这一容器 确实是实现了迭代器协议中容器的部分。后续连续3次的next()方法凋用也印证了协议的 第2条。

熟悉了迭代器协议，那么我们就可以使用它来遍历所有的容器，仍然以list对象为例。

»> alist = range (2)

»> it = iter (alist)

\>» while True:

• • •    try:

...    print it.next ()

...    except Stoplteration:

."    break

0

1

可以看到输出跟最初使用for循环是一样的，对，你的灵光一闪没有错，其实for语句 就是对获取容器的迭代器、调用迭代器的next()方法以及对Stoplteration进行处理等流程进 行封装的语法糖(类似的语法糖还有in/not it语句)。

迭代器最大的好处是定义了统一的访问容器(或集合)的统一接口，所以程序员可以随 时定义自己的迭代器，只要实现了迭代器协议就可以。除此之外，迭代器还有惰性求值的特 性，它仅可以在迭代至当前元素时才计算(或读取)该元素的值，在此之前可以不存在，在 此之后可以销毁，也就是说不需要在遍历之前事先准备好整个迭代过程中的所有元素，所以 非常适合遍历无穷个元素的集合(如斐波那契数列)或巨大的事物(如文件)。

class Fib(object):

def _init_(self):

self._a - 0 self._b = 1

def _iter_(self): return self

def next(self):

self. a, self. b = self. b, self, a + self. b return self._a

for i, f in enumerate(Fib()): print f

if i > 10: break

这段代码能够打印斐波那契数列的前10项。再来看一下传统的使用容器存储整个数列 的方案。

\>>> def fib (n):

"”"返回小于指定值的斐波那契数列"”" result=[] a,b=0z1 while b<n:

result.append(b) a,b=b,a+b

return result

»> flb(10)

[1, 1, 2, 3, 5, 8' 13, 21, 34r 55, 89f 144]

与直接使用容器的代码相比，它仅使用两个成员变虽，挝而易见更省内存，并在一些 应用场景更省CPU汁算资源，所以在编写代码中应当多多使用迭代器协议，避免劣化代码。 对于这一观点，不必怀疑，从Python 2.3版本开始，itertools成为了标准库的一员已经充分印 证这个观点。

itertools的0标是提供一系列计算快速、内存高效的函数，这些函数可以单独使用，也 可以进行组合，这个模块受到了 Haskell等闲数式编程语言的启发，所以大量使用itertools 模块中的函数的代码，看起来有点像函数式编程语言写推荐，比如Sum(iinap(OperatOr.mul， vectorl,vector2))能够用来运行两个向量的对应元素乘积之和。

itertools最为人所熟知的版本，应该算是zip、map、filter、slice的替代，izip (izip_ longest)、imap(startmap)、ifilter(ifilterfalse)、islice,它们与原来的那几个内置函数有一样的 功能，只是返冋的是迭代器(在Python 3中，新的函数撤底替换掉了旧函数)。

除了对标准函数的替代，itertools还提供以下几个有用的函数：chain()用以同时连续地 迭代多个序列；compress()、dropwhile()和takewhile()能用以遴选序列元素；tee()就像同名 的UNIX应用程序，对序列作n次迭代；而groupby的效果类似SQL中相同拼写的关键字所 带的效果。

[k for k, g in groupby(•AAAABBBCCDAABBB1)] —> A B C D A B [list (g) for k, g in groupby{•AAAABBBCCD•)] --> AAAA BBB CC D

除了这些针对有限元素的迭代帮助函数之外，还有covmto、cycleO、repeatO等函数产 生无穷序列，这3个函数就分别可以产生算术递增数列、无限重复实参序列的序列和重复产 生同一个值的序列。

如果以上这些函数让你感到吃惊，那么接下来的4个组合数学的函数就会让你更加惊讶 了，如表6-3所示。

表6-3组合函数以及其意义

| product()                       | 计箅m个序列的n次箝卡尔积 |
| ------------------------------- | ------------------------ |
| pcrmutations()                  | 产生全排列               |
| combinations()                  | 产生无重复元索的组合     |
| combinations with replacement() | 产生有重复元素的组合     |

###### 下面通过例子来熟悉一下，第一行是代码，第二行是结果。

product(1ABCD1, repeat=2)

AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD

permutations(1ABCD*, 2)

AB AC AD BA BC BD CA CB CD DA DB DC

combinations(•ABCD1, 2)

AB AC AD BC BD CD

combinations_with_replacement(•ABCD、 2)

AA AB AC AD BB BC BD CC CD DD

其中product ()可以接受多个序列，如：

\>» for i in product(1ABC1r •123,, repeat=2): print ••.join⑴

###### 參 馨 籲

A1A1

A1A2

A1A3

A1B1

A1B2

A1B3

\#略去其余犄出

##### 建议66:熟悉Python的生成器

生成器，顾名思义，就是按一定的算法生成一个序列，比如产生自然数序列、斐波那 契数列等。之前讲迭代器的时候，就讲过一个生成波那契数列的例子。那么迭代器也是生成 器？其实不然。迭代器虽然在某些场景表现得像生成器，但它绝非生成器；反而是生成器实 现了迭代器协议的，可以在一定程度上看作迭代器。再把话题转回迭代器样式的斐波那契数 列实现，熟悉Python的人会觉得其实不简洁，因为还有yield表达式可以简化它。

大概是因为生成器的用处巨大，所以Python中专门有一个关键字来实现它，就是yield。 甚至生成器的定义也与这个关键字有关：如果一个函数，使用了 yield语句，那么它就是一 个生成器函数。当调用生成器函数时，它返回一个迭代器，不过这个迭代器是以生成器对象 的形式出现的。所以现在我们来重写一下之前的斐波那契数列实现。

def fib (n):

a, b = 1, 1 while a < n:

yield a

a, b = br a + b

for i, f in enumerate (fib (10)): print f

看，代码行数是不是减少了许多？这就是yield关键字的魅力。不过要掌握这个关键字 可不容易，首先来看看fib()函数返回的是什么。

\>» f = fib(10)

\>>> type(f)

<type •generator1>

»> dir (f)

[• _class_•, *_delattr_’，•_doc_•, 1_format_\ _getattribute_•,

•_hash__init_•, •_iter_•, •_name_•, •_new_•, 1_reduce_•,

•_reduce 一 ex_1 f _repr_•, •_setattr_•, •_sizeof_•, ’_str_•,

•_subclasshook_•, •close、 *gi一code1, ,gi_frame•/    •gi_running•,

1 next•9    9 send•, 1 throw1]

可以看到它返回的是一个generator类型的对象，而这个对象带有_iter_()和next()方 法，可见的确是一个迭代器。但那些next()、send()、throw()、close()等方法是怎么冋事？要 理解这些方法，需要我们重温一下手册中的例子。

»> def echo (value=None):

... print "Execution starts when 'next ()' is called for the first time."

... try:

...    while True:

•••    try:

...    value = (yield value)

...    except Exception, e:

...    value = e

". finally:

...    print 11 Don 11 forget to clean up when * close () 1 is called.11

\>» generator = echo (1)

\>>> print generator.next()

Execution starts when fnext()1 is called for the first time.

1

至此，可以看到每一个生成器函数调用之后，它的函数体并不执行，而是到第一次调用 next()的时候才开始执行。这一点未免让新手颇为费解，但目前来看除了硬记住这一点外并 无它法。要从根源上解决问题的话，可能需要约定生成器函数使用另外一个关键字，比如使 用generator而不是def,不然大家总是会往函数方面去想的。

当第一次调用next()方法时，生成器函数开始执行，执行到yield表达式为止。如例子 中的value=(yield value)语句中，只是执行了 yield value这个表达式，而赋值操作并未执行。 记住这一点很重要，只有记住了这一点，才能理解后续的内容，如sendO方法。

\>>> print generator.next()

None

###### 这个也让人有点困惑，按代码应当是返回1的，怎么返回None 了呢？这时候需要注意

的是代码中的value=(yield value)，yield是一个表达式，所以它可以作为一个表达式的右值。 当第二次调用next()时，yield表达式的值赋值给了 value，而yield表达式的默认“返冋值” 就是None,所以后续value的值就是None。现在再用自然语言来描述一次第二次调用next() 的过程，首先是value=(yield value)语句中的赋值操作得到了执行，即value被赋值为None， 然店是while条件判断，再次进人循环体，执行value=(yield value)语句，此时value的值为 None, yield出来的也是None,那么再次调用next()时返回None就顺理成章了，因为next() 的返回值就是yield表达式的右值。

»> print generator. send (2)

2

直率地说，send()方法很绕，这不是一个好名字。其实sendO是全功能版本的nextO, 或者说next()是send()的“快捷方式”，相当于send(None)。还记得yield表达式有一个“返 回值”吗？ semi()方法的作用就是控制这个返回值，使得yield表达式的“返回值”是它的 实参。

\>>> generator. throw (TypeError, Mspamt,)

TypeError(* spamf 9 )

除了能yield表达式的“返回值”之外，也可以让它抛出异常，这就是throw()方法的能 力。在本例中，yield value表达式抛出一个TypeError异常，然后被内层的except语句捕获， 并赋值给value,因此整个代码的执行流并没有离开while循环块，所以进人了下一次循环。 当再次执行yield value时，异常对象(也就是value的值)被返回到此次throw()调用中。对 于常规业务逻辑的代码来说，处理异常的情况不会像这个例子中那样，而是对特定的异常有 很好的处理(比如将异常信息写人日志后优雅地返回)，从而实现从外部影响生成器内部的控 制流。

\>>> generator.close()

Don11 forget to clean up when •close。• is called.

当调用close()方法时，yield表达式就抛出GeneratorExit异常，生成器对象会自行处理 这个异常。当调用Close()之后，再次调用next()、send()会使生成器对象抛出Stoplteration 异常，换言之，这个生成器对象已经不可再用。最后值得一提的是，当生成器对象被GC回 收时，会自动调用closeO。

除了简化前文中使用迭代器协议生成斐波那契数列的代码之外，生成器还有两个很棒的 用处，其中之一是实现with语句的上下文管理器协议，利用的是调用生成器函数时函数体并 不执行，当第一次调用next()方法时才开始执行，并执行到yield表达式后中止，直到下一 次调用next()方法这个特性；其二是实现协程，利用的是上文所述的send()、throw()、close() 等特性。在此，继续讲述第一个应用，而第二个应用留待下一小节讲述。

首先，需要我们回过头来重温一下上下文管理器协议，其实就是要求类实现_enter_()

和_exit_()方法。比如以下file对象就实现了这个协议：

»> with open <•/tmp/xxx . txt •, * w*) as f:

•••    f.write(•hello, context manager.')

• • •

但是生成器对象并没有这两个方法，所以contextlib提供了 contextmanager闲数来适配 这两种协议。

from contextlib import contextmanager

@contextmanager def tag(name):

print "<%s>n % name yield

print n</%s>” % name

\>>> with tag(Mhlw):

... print Mfoo”

• • •

<hl>

foo

</hl>

这是来自Python文档的例子，当进人with块的时候，tag()函数块的第一行执行，并 在执行到第二行的时候中止；离开with块的时候，执行print “foo”，完成后执行yield后 面的语句，也就是tag()函数块的第三行，然后整个函数执行完毕。通过contextmanager对 nextO、throw(), close()的封装，yield大大简化了上下文管理器的编程复杂度，对提髙代码 可维护性有着极大的意义。除了上面这个例子之外，yield和contextmanger也可以用以“池” 模式中对资源的管理和回收，具体的实现留给大家去思考。

##### 建议67:基于生成器的协程及greenlet

在前文中，对生成器实现协程卖了个小关子，在这一节，让我们来揭开谜底。不过在此 之前，需要先重温一下协程的概念，以及它的意义。

协程，又称微线程和纤程等，据说源于Simula和Modula-2语言，现代编程语言基本上 都支持这个特性，比如Lua和mby都有类似的概念。协程往往实现在语言的运行时库或虚拟 机中，操作系统对其存在一无所知，所以又被称为用户空间线程或绿色线程。又因为大部分 协程的实现是协作式而非抢占式的.需要用户自己去调度，所以通常无法利用多核，但用来 执行协作式多任务非常合适。用协程来做的东西，用线程或进程通常也是一样可以做的，但 往往多了许多加锁和通信的操作。下面基于生产者消费者模型，对抢占式多线程编程实现和 协程编程实现进行对比。首先来看使用以下线程的实现(伪代码)：

//队列容器

var q := new queue

//消费者线程 loop

lock(q)

get item from q unlock(q) if item

use this item

sleep

//生产者线程 loop

create some new items lock(q)

add the items to q unlock(q)

###### 由以上代码可以看到，线程实现至少有两点硬伤：

□对队列的操作需要有显式/隐式(使用线程安全的队列)的加锁操作。

□消费者线程还要通过sleep把CPU资源适时地“谦让”给生产者线程使用，其中的适

时是多久，基本上只能静态地使用经验值，效果往往不尽如人意。

而使用协程可以比较好地解决这个问题。看以下基于协程的生产者消费者模型实现(伪

代码)：

//队列容器

var q :« new queue

//生产者协程 loop

while q is not full create some new items add the items to q

yield to consume //消费者协程 loop

while q is not empty

remove some items from q use the items

yield to produce

###### 可以从以上代码看到之前的加锁和谦让CPU的硬伤不复存在，但也损失了利用多核 CPU的能力。所以选择线程还是协程，就要看应用场合了。

好，回到主题：协程这东西关Python的生成器什么事？如果你仔细看上面的伪代码， 应该留意到其中出现了两个yield!是的，因为yield能够中止当前代码的执行，相当于“让 出” CPU资源，跟协程的“协作式”理念不谋而合，所以能够实现协程。

def consumer(): while True:

line - yield

print line.upper() def producter():

with open(1/var/log/apache2/error_log1,    * r•) as f:

for i, line in enumerate(f):

yield line

print 1 processed line %d* % i c = consumer() c.next ()

for line in producter (): c.send(line)

依照上文的理念，编写了这些代码，可以看到consumerO是一个生成器函数，它接收 yield表达式的返回值，转换为全大写，并输出到标准输出，然后再次执行yield把CPU交给 主程序。它的执行结果如下(根据内容会有点不同)：

[THU OCT 31 17:49:08 2013] [WARN] INIT: SESSION CACHE IS NOT CONFIGURED [HINT: SSLSESSIONCACHE]

processed line 0

HTTPD: COULD NOT RELIABLY DETERMINE THE SERVER*S FULLY QUALIFIED DOMAIN NAME, USING APPLETEKIMACBOOK-PRO.LOCAL FOR SERVERNAME

processed line 1

[THU OCT 31 17:49:08 2013] [NOTICE] DIGEST: GENERATING SECRET FOR DIGEST AUTHENTICATION

processed line 2

[THU OCT 31 17:49:08 2013] [NOTICE] DIGEST: DONE

processed line 3

…4

可以从输出中看到，每输出一行大写的文字后都有一行来自主程序的处理信息，绝不会 像抢占式的多线程程序那样“乱序”，这就是协程的“协”字之由来。Python 2.x版本的生成 器无法实现所有的协程特性，是因为缺乏对协程之间复杂关系的支持。比如一个yield协程 依赖另一个yield协程，且需要由最外层往最内层进行传值的时候，就没有解决办法。下面 就是一个例子：为班级编写一个程序，计算每一个学生的各科总分，并计算班级总分。先尝 试编写以下函数：

\>>> def accumulate():

...    tally = 0

".    while 1:

...    tally += (yield tally)

###### 參 •鲁

###### 考虑到不同的班级有不同数量的科目，不同的班级有不同数量的学生，所以编写一个生 成器进行计算，它能根据接收到的数值进行计算，无须预先知道数量。现在想象一下你拿到

了学生的各科成绩表，可以想象出它是一个二维表，那么代码大概如下:

»> 1 =[]

\>» for s in students:

…    t = 0

...    a - accumulate ()

...    a.next()

...    for c in s:

...    t = a.send(c)

...    1.append(t)

\>» t = 0

\>>> a = accumulate ()

\>>> a.next ()

\>>> for s in 1:

"•    t = a.send(s)

325

可以看到无端多出来的对t和a的初始化操作非常刺眼，不过代码总算是可以正常工 作。如果你尝试想把它封装成一个用以计算一个学生总分的函数，会更加别扭(想象一下在 accumulate()中凋用其自身，递归生成器？)。这个问题直到Python 3.3增加了 yield from表达 式以后才得以解决，通过yield from，外层的生成器在接收到send()或throw()调用时，能够 把实参直接传人内层生成器。应用到本例当中，就不需要定义临吋容器1来保存每一个学生 的成绩，代码复杂性下降许多。下面是假定accumulate使用了 yield from后的代砰：

»> a = accumulate ()

\>» a.next 0

»> t « 0

\>» for s in students:

...    for klass in s:

•••    t +- a.send(klass)

參 參 •

看这个嵌套循环的代码是不是简单了许多？回到协程这个主题，因为Python 2.x版本对 协程的支持有限，而协程又是非常有用的特性，所以很多Pythonista就开始寻求语言之外的 解决方案，并编写了一系列的程序库，其中最受欢迎的莫过于greenlet。

greenlet是一个C语言编写的程序库，它与yield关键字没有密切的关系。greenlet这个 库里般为关键的一个类型就是PyGreenlet对象，它是一个C结构体，每一个PyGreenlet都可 以看到一个调用栈，从它的人口函数开始，所有的代码都在这个调用栈上运行。它能够随时 记录代码运行现场，并随时中止，以及恢复。看到这里，可以发现它跟yield所能够做到的 相似，但更好的是它提供从一个PyGreenlet切换到另一个PyGreenlet的机制。最后看一下来 自它帮助文件的一个例子，以便对它有个直观的印象。

from greenlet import greenlet def testl ():

print 12 gr2.switch() print 34

def test2(): print 56 grl.switch() print 78

grl = greenlet(testl) gr2 = greenlet(test2) grl.switch()

最后一行跳到testl,摘出12,跳到test2,输出56,跳回testl,输出34 ;然后testl执 行完，grl就死了。然后，最初的grl.switch()调用返回，所以永远也不会输出78。

协程虽然不能充分利用多核，但它跟异步I/O结合起来以后编写I/O密集型应用非常容 易，能够在同步的代码表面下实现异步的执行，其中的代表当属将greenlet与libevent/libev结 合起来的gevent程序库，它是当下最受欢迎的Python网络编程库。最后，以使用gevent并发 査询DNS的例子作为结束，使用它进行并发査询n个域名，能够获得几乎n倍的性能提升。

\>» import gevent

\>» from gevent import socket

»> urls = [1[www.google.com1r](http://www.google.com1r) ’www.example.com’， '[www.python.org1](http://www.python.org1)]

\>» jobs = [gevent.spawn(socket.gethostbynamer url) for url in urls]

\>>> gevent.joinall(jobs, timeout=2)

\>>> [job.value for job in jobs]

(l74.125.79.106\ 1208•77•188•166 \ •82•94•164•162•】

##### 塗议68:理解GIL的局限性

在Python多线程编程中，你有没有遇到过这种问题：多线程Python程序运行的速度比 只有一个线程的时候还要慢？除了程序本身的并行性之外，很大程度上与GIL有关。GIL在 Python巾是一个很冇争议的话题，由于它的存在，多线程编程在Python中似乎并不理想， 为什么这么说呢？先来了解一下GIL。GIL被称为为全局解释器锁(Global Interpreter Lock), 是Python虚拟机上用作互斥线程的一种机制，它的作用是保证任何情况下虚拟机中只会有一 个线程被运行，而其他线程都处于等待GIL锁被释放的状态。对于有I/O操作的多线程，其 线程执行状态如图6-6所示。不管是在单核系统还是多核系统中，始终只有一个获得了 GIL 锁的线程在运行，每次遇到I/O操作便会进行GIL锁的释放。

但如果是纯计算的程序，没有I/O操作，解释器则会根据sys.setcheckinterval的设置来 自动进行线程间的切换，默认情况下每隔100个时钟(注：这里的时钟指的是Python的内 部时钟，对应于解释器执行的指令)就会释放GIL锁从而轮换到其他线程的执行，示意图如 图6-7所示。

團6-6 Python虚拟机中I/O操作中GIL的变换过程



阁6-7无I/O操作时GIL的变换过程



在单核CPU中，GIL对多线程的执行并没有太大影响，因为单核上的多线程本质上就是 顺序执行的。似对于多核CPU,多线程并不能真正发挥优势带来效率上明显的提升，甚至在 频繁I/O操作的情况下由于存在需要多次释放和申请GIL的情形，效率反而会下降。那么，有 人不禁会问：Python解释器中为什么要引人GIL呢？来思考这样一个情形：我们知道Python 中对象的管理与引用计数器密切相关，当计数器变为0的时候，该对象便会被垃圾回收器回 收。当撤销对一个对象的引用时，Python解释器对对象以及其计数器的管理分为以下两步：

1）    使引用计数值减1。

2）    判断该计数值是否为0,如果为0,则销毁该对象。

假设线程A和B同时引用同一个对象obj，这时obj的引用计数值为2。如果现在线程 A打算撤销对obj的引用。当执行完第一步的时候，由于存在多线程调度机制，A恰好在这 个关键点被挂起，而B进人执行状态，如图6-8所示。但不幸的是B也同样做了撤销对obj 的引用的动作，并顺利完成了所有两个步骤，这个时候由于obj的引用计数器为0,因此对

|线程A

线程B



Obj.ref num —

\#线程A执行，obj.ref_num=l #A挂起



\#B挂起

obj.refjmm-#线程B被唤醒进入执行状态 If obj.refjium=0:#此时条件成立 destory obj#obj 被销毁

lfob>f_nun^~0蛾程A恢复，进入执行状态ErCe memory#内存释放

destory obj#此时obj并不存在，执行结果未知 Free memory

图6-8无GIL存在时线程的同步

象被销毁，内存被释放。但如果此时A再次被唤醒去执行第二步操作的时候会发现已经面目 全非，则其操作结果完全未知。

鉴于此，在Python解释器中引入了 GIL,以保证对虚拟机内部共享资源访问的互斥性。 GIL的引人确实使得多线程不能在多核系统中发挥优势，但它也带来了一些好处：大大简化 了 Python线程中共享资源的管理，在单核CPU上，由于其本质是顺序执行的，一般情况下 多线程能够获得较好的性能。此外，对于扩展的C程序的外部调用，即使其不是线程安全 的，但由于GIL的存在，线程会阻塞直到外部调用函数返回，线程安全不再是一个问题。

多核CPU已经成为一个常见的现象，GIL的局限性限制了其在多核CPU上发挥优势， 因此对于GIL的去留也曾引发过激烈的讨论。Guido以及Python的开发人员都有一个很明确 的解释，那就是去掉GIL并不容易。实际上在1999年，针对Pythonl.5, Greg Stein发布了 一个补丁，该补丁中GIL被完全移除，使用髙粒度的锁来代替。然而这种解决方案并没有带 来理想的效果，多核多线程速度的提升并没有随着核数的增加而线性增长，反而给单线程程 序的执行速度带来了一定的代价，当用单线程执行时，速度大约降低了 40%。因此，这种方 案最终也被放弃。在Python3.2中重新实现了 GIL，其实现机制主要集中在两个方面：一方 面是使用固定的时间而不是固定数量的操作指令来进行线程的强制切换；另一个方面是在线 程释放GIL后，开始等待，直到某个其他线程获取GIL后，再开始去尝试获取GIL，这样虽 然可以避免此前获得GIL的线程，不会立即再次获取GIL,但仍然无法保证优先级髙的线程 优先获取GIL。这种方式只能解决部分问题，并未改变GIL的本质，GIL本质上的改观目前 并没有非常明朗的前景。不过也不需要那么悲观，Python提供了其他方式可以绕过GIL的局 限，比如使用多进程multiprocessing模块或者采用C语言扩展的方式，以及通过ctypes和C 动态库来充分利用物理内核的计算能力。

##### 建议69: •对象的管理与垃圾回收

通常来说Python并不需要用户自己来管理内存，它与Ped、Ruby等很多动态语言一样 具备垃圾回收功能，可以自动管理内存的分配与回收，而不需要编程人员的介人。那么这样 是不是意味着用户可以高枕无忧了呢？我们来看下面一个例子：

class Leak(object):

def _init_(self):

print "object with id %d was born1' %id (self)

while(True):

A = Leak() B = Leak()

A.    b = B

B.    a = A A =

None

None



运行上述程序我们会发现，Python进程的内存消耗量一直在持续增长，到最后出现内存 耗光的情况。这是什么原因造成的呢？

我们先来简单谈谈Python中内存管理的方式：Python使用引用计数器(Reference counting)的方法来管理内存中的对象，即针对每一个对象维护一个引用计数值来表示该对象 当前有多少个引用。当其他对象引用该对象时，其引用计数会增加1，而删除一个对当前对 象的引用，其引用计数会减1。只有当引用计数的值为0的时候该对象才会被垃圾收集器回 收，因为它表示这个对象不再被其他对象引用，是个不可达对象。引用计数算法最明显的缺 点是无法解决循环引用的问题，即两个对象相互引用。上述代码中正是由于形成了 A、B对 象之间的循环引用而造成了内存泄露的情况，因为两个对象的引用计数器都不为0,该对象 并不会被垃圾收集器回收，而无限循环导致一直在申请内存而没有释放，所以最后出现了内 存耗光的情况。

循环引用常常会在列表、元组、字典、实例以及函数使用时出现。对于由循环引用而导 致的内存泄露的情况，有没有办法进行控制和管理呢？实际上Python自带了一个gc模块， 它可以用来跟踪对象的“人引用(incoming reference)”和“出引用(outgoing reference)”，并 找出复杂数据结构之间的循环引用，同时回收内存垃圾。有两种方式可以触发垃圾回收：一 种是通过显式地调用gc.collectO进行垃圾回收；还有一种是在创建新的对象为其分配内存的 时候，检査threshold阈值，当对象的数量超过threshold的时候便自动进行垃圾回收。默认 情况下阀值设为(700，10，10)，并且gc的自动回收功能是开启的，这些可以通过gc.isenabled() 査看。下而是gc模块使用的简单例子：

»> import gc

\>〉〉print gc.isenabled()

True

»> gc. isenabled ()

True

»> gc. get threshold ()

(700, 10z 10)

对于本节开头的例子，我们使用gc模块来进行垃圾回收，代码如下： def main():

collected = gc.collect()

print "Garbage collector before running: collected %d objects." % (collected) print ’.Creating reference cycles. .

A = Leak ()

B = Leak ()

A.    b = B

B.    a = A A - None B = None

collected = gc.collect() pprint.pprint( gc.garbage)

print "Garbage collector after running: collected %d objects." % (collected)

if _name_ == ••_main_": ret = main() sys.exit(ret)

运行程序输出结果如下：

Garbage collector before running: collected 0 objects.

Creating reference cycles... object with id 14109584 was born object with id 14109648 was born (]

Garbage collector after running: collected 4 objects.

gc.garbage返回的是由于循环引用而产生的不可达的垃圾对象的列表，输出为空表示内 存中此吋不存在垃圾对象。gc.collectO显示所有收集和销毁的对象的数目，此处为4 (2个对 象A、B,以及其实例属性diet)。

我们再来考虑一个问题：如果我们在类Leak中添加析构方法_心1_0,对象的销毁形 式和内存回收的情况是否有所不同。示例代码如下：

def _del_(self):

print "object with id %d was destoryed" %id(self)

当加入了析构方法_del_()在运行程序的时候会发现gc.garbage的输出不再为空，而 是对象A、B的内存地址，也就是说这两个对象在内存中仍然以“垃圾”的形式存在。 gc.garbag()输出如下：

[<_main_.Leak object at 0x00D72BF0>, <_main_.Leak object at 0x00D72C30>]

这是什么原因造成的呢？实际上当存在循环引用并且当这个环中存在多个析构方法时， 垃圾回收器不能确定对象析构的顺序，所以为了安全起见仍然保持这些对象不被销毁C而当 环被打破时，gc在回收对象的时候便会再次自动调用_心1_()方法。读者可以自行试验。

gc模块同时支持DEBUG模式，当设置DEBUG模式之后，对于循环引用造成的内存泄 露，gc并不释放内存，而是输出更为详细的诊断信息为发现内存泄露提供便利，从而方便程 序员进行修复。更多gc模块的使用方法读者可以参考文档：http://docs.python.org/2Zlibrary/ gc.htmlo
